{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tell-me-a-story_gpt2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"iDSf-xiaqutb","colab_type":"text"},"source":["#Tell Me a Story\n","Children's story generator using a [GPT-2](https://openai.com/blog/better-language-models/) network fine-tuned on children's stories from the Guttenberg project (via [bAbI](https://research.fb.com/downloads/babi/)). This notebook will only work in full on [colab](colab.research.google.com), as it saves the resultant model to the user's google drive."]},{"cell_type":"code","metadata":{"id":"mjXZ9EcYk_Qy","colab_type":"code","outputId":"2aa966df-1759-4ffd-b766-b8b2803774ed","executionInfo":{"status":"ok","timestamp":1574793112973,"user_tz":300,"elapsed":10510,"user":{"displayName":"Randy West","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDIuiLm_tLYhXcxAUMOdxogEndwhWVgfR12ND5xrw=s64","userId":"12093252501908892059"}},"colab":{"base_uri":"https://localhost:8080/","height":632}},"source":["! pip install transformers"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/f9/51824e40f0a23a49eab4fcaa45c1c797cbf9761adedd0b558dab7c958b34/transformers-2.1.1-py3-none-any.whl (311kB)\n","\u001b[K     |████████████████████████████████| 317kB 2.8MB/s \n","\u001b[?25hCollecting regex\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/8e/cbf2295643d7265e7883326fb4654e643bfc93b3a8a8274d8010a39d8804/regex-2019.11.1-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n","\u001b[K     |████████████████████████████████| 645kB 53.1MB/s \n","\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.18)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n","\u001b[K     |████████████████████████████████| 860kB 47.0MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.4)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 41.5MB/s \n","\u001b[?25hRequirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n","Requirement already satisfied: botocore<1.14.0,>=1.13.18 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.18)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.9.11)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.0)\n","Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.18->boto3->transformers) (2.6.1)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.18->boto3->transformers) (0.15.2)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=506f1c42c68372e6244e2e51b928d71ad9b8efb6fddda26e229d7760033d652a\n","  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n","Successfully built sacremoses\n","Installing collected packages: regex, sacremoses, sentencepiece, transformers\n","Successfully installed regex-2019.11.1 sacremoses-0.0.35 sentencepiece-0.1.83 transformers-2.1.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"adVRYBGrlI8E","colab_type":"code","outputId":"333e37a7-23c2-447a-8073-c923d24668ac","executionInfo":{"status":"ok","timestamp":1574793119284,"user_tz":300,"elapsed":11686,"user":{"displayName":"Randy West","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDIuiLm_tLYhXcxAUMOdxogEndwhWVgfR12ND5xrw=s64","userId":"12093252501908892059"}},"colab":{"base_uri":"https://localhost:8080/","height":323}},"source":["! rm -rf transformers\n","! git clone https://github.com/huggingface/transformers.git"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Cloning into 'transformers'...\n","remote: Enumerating objects: 221, done.\u001b[K\n","remote: Counting objects: 100% (221/221), done.\u001b[K\n","remote: Compressing objects: 100% (117/117), done.\u001b[K\n","remote: Total 12628 (delta 133), reused 154 (delta 104), pack-reused 12407\u001b[K\n","Receiving objects: 100% (12628/12628), 6.63 MiB | 5.71 MiB/s, done.\n","Resolving deltas: 100% (9221/9221), done.\n","Note: checking out '3ddce1d74cda5be47704381e657ee22ce5a5fc7b'.\n","\n","You are in 'detached HEAD' state. You can look around, make experimental\n","changes and commit them, and you can discard any commits you make in this\n","state without impacting any branches by performing another checkout.\n","\n","If you want to create a new branch to retain commits you create, you may\n","do so (now or later) by using -b with the checkout command again. Example:\n","\n","  git checkout -b <new-branch-name>\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2OjoMAt8lNCz","colab_type":"code","colab":{}},"source":["# get the data\n","import re\n","from requests import get\n","\n","url = \"http://www.thespermwhale.com/jaseweston/babi/CBTest.tgz\"\n","fn = re.search(\"[^/]+$\", url).group(0)\n","response = get(url)\n","with open(fn, \"wb\") as f:\n","  f.write(response.content)\n","\n","! tar xfz {fn} 2> /dev/null"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Qk8WRnPlUyb","colab_type":"code","outputId":"7b8ed0c1-db6c-43e8-cfb7-c8af81cee14f","executionInfo":{"status":"ok","timestamp":1574793813469,"user_tz":300,"elapsed":7210,"user":{"displayName":"Randy West","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDIuiLm_tLYhXcxAUMOdxogEndwhWVgfR12ND5xrw=s64","userId":"12093252501908892059"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["# munge it\n","from pathlib import PosixPath\n","from os import makedirs\n","\n","data_path = PosixPath(\"/content/CBTest/data\")\n","makedirs(data_path/\"train\", exist_ok=True)\n","makedirs(data_path/\"valid\", exist_ok=True)\n","cbt_train_file = data_path/\"train/cbt_train_cleaned.txt\"\n","cbt_valid_file = data_path/\"valid/cbt_valid_cleaned.txt\"\n","# we don't care about test, so add it to the train set\n","! echo \"Cleaning training data\"\n","! cat {data_path}/cbt_train.txt {data_path}/cbt_test.txt | tqdm | grep -v _BOOK_TITLE | \\\n","perl -pe 's/-L[CS]B-.*?-R[CS]B-//g; s/-L[CS]B-.*$// if ! /-R[CS]B-/; s/^.*-R[CS]B-// if ! /-L[CS]B-/; s/-LRB-/(/g; s/-RRB-/)/g;' \\\n","> {cbt_train_file}\n","! echo \"Cleaning validation data\"\n","! grep -v _BOOK_TITLE {data_path}/cbt_valid.txt | tqdm | \\\n","perl -pe 's/-L[CS]B-.*?-R[CS]B-//g; s/-L[CS]B-.*$// if ! /-R[CS]B-/; s/^.*-R[CS]B-// if ! /-L[CS]B-/; s/-LRB-/(/g; s/-RRB-/)/g;' \\\n"," > {cbt_valid_file}"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Cleaning training data\n","280165it [00:00, 494072.12it/s]\n","Cleaning validation data\n","12742it [00:00, 408201.81it/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ALlkuOc7lmk5","colab_type":"code","outputId":"57a967c4-7c5b-44f1-f357-6a43a7f15002","executionInfo":{"status":"ok","timestamp":1574798732484,"user_tz":300,"elapsed":4893888,"user":{"displayName":"Randy West","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDIuiLm_tLYhXcxAUMOdxogEndwhWVgfR12ND5xrw=s64","userId":"12093252501908892059"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["! python transformers/examples/run_lm_finetuning.py \\\n","    --output_dir=model \\\n","    --model_type=gpt2 \\\n","    --model_name_or_path=gpt2 \\\n","    --do_train \\\n","    --train_data_file={cbt_train_file} \\\n","    --do_eval \\\n","    --eval_data_file={cbt_valid_file} \\\n","    --per_gpu_train_batch_size=2 \\\n","    --per_gpu_eval_batch_size=2"],"execution_count":0,"outputs":[{"output_type":"stream","text":["11/26/2019 18:44:03 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","11/26/2019 18:44:04 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json not found in cache or force_download set to True, downloading to /tmp/tmpcb9b66ei\n","100% 176/176 [00:00<00:00, 135822.91B/s]\n","11/26/2019 18:44:04 - INFO - transformers.file_utils -   copying /tmp/tmpcb9b66ei to cache at /root/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.085d5f6a8e7812ea05ff0e6ed0645ab2e75d80387ad55c1ad9806ee70d272f80\n","11/26/2019 18:44:04 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.085d5f6a8e7812ea05ff0e6ed0645ab2e75d80387ad55c1ad9806ee70d272f80\n","11/26/2019 18:44:04 - INFO - transformers.file_utils -   removing temp file /tmp/tmpcb9b66ei\n","11/26/2019 18:44:04 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /root/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.085d5f6a8e7812ea05ff0e6ed0645ab2e75d80387ad55c1ad9806ee70d272f80\n","11/26/2019 18:44:04 - INFO - transformers.configuration_utils -   Model config {\n","  \"attn_pdrop\": 0.1,\n","  \"embd_pdrop\": 0.1,\n","  \"finetuning_task\": null,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"num_labels\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pruned_heads\": {},\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"torchscript\": false,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 50257\n","}\n","\n","11/26/2019 18:44:05 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json not found in cache or force_download set to True, downloading to /tmp/tmpnn8b6vo5\n","100% 1042301/1042301 [00:01<00:00, 930833.65B/s]\n","11/26/2019 18:44:07 - INFO - transformers.file_utils -   copying /tmp/tmpnn8b6vo5 to cache at /root/.cache/torch/transformers/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n","11/26/2019 18:44:07 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n","11/26/2019 18:44:07 - INFO - transformers.file_utils -   removing temp file /tmp/tmpnn8b6vo5\n","11/26/2019 18:44:08 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt not found in cache or force_download set to True, downloading to /tmp/tmpgnniycqi\n","100% 456318/456318 [00:00<00:00, 623506.80B/s]\n","11/26/2019 18:44:10 - INFO - transformers.file_utils -   copying /tmp/tmpgnniycqi to cache at /root/.cache/torch/transformers/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","11/26/2019 18:44:10 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","11/26/2019 18:44:10 - INFO - transformers.file_utils -   removing temp file /tmp/tmpgnniycqi\n","11/26/2019 18:44:10 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at /root/.cache/torch/transformers/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n","11/26/2019 18:44:10 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at /root/.cache/torch/transformers/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","11/26/2019 18:44:10 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmphrw2lbzq\n","100% 548118077/548118077 [00:39<00:00, 14023599.74B/s]\n","11/26/2019 18:44:50 - INFO - transformers.file_utils -   copying /tmp/tmphrw2lbzq to cache at /root/.cache/torch/transformers/4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n","11/26/2019 18:44:52 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n","11/26/2019 18:44:52 - INFO - transformers.file_utils -   removing temp file /tmp/tmphrw2lbzq\n","11/26/2019 18:44:52 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at /root/.cache/torch/transformers/4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n","11/26/2019 18:45:02 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=1024, cache_dir='', config_name='', device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=True, eval_all_checkpoints=False, eval_data_file='/content/CBTest/data/valid/cbt_valid_cleaned.txt', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_grad_norm=1.0, max_steps=-1, mlm=False, mlm_probability=0.15, model_name_or_path='gpt2', model_type='gpt2', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='model', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=2, per_gpu_train_batch_size=2, save_steps=50, save_total_limit=None, seed=42, server_ip='', server_port='', tokenizer_name='', train_data_file='/content/CBTest/data/train/cbt_train_cleaned.txt', warmup_steps=0, weight_decay=0.0)\n","11/26/2019 18:45:02 - INFO - __main__ -   Creating features from dataset file at /content/CBTest/data/train\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (6665868 > 1024). Running this sequence through the model will result in indexing errors\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:30 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:31 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 18:45:32 - INFO - __main__ -   Saving features into cached file /content/CBTest/data/train/cached_lm_1024_cbt_train_cleaned.txt\n","11/26/2019 18:45:32 - INFO - __main__ -   ***** Running training *****\n","11/26/2019 18:45:32 - INFO - __main__ -     Num examples = 6509\n","11/26/2019 18:45:32 - INFO - __main__ -     Num Epochs = 1\n","11/26/2019 18:45:32 - INFO - __main__ -     Instantaneous batch size per GPU = 2\n","11/26/2019 18:45:32 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 2\n","11/26/2019 18:45:32 - INFO - __main__ -     Gradient Accumulation steps = 1\n","11/26/2019 18:45:32 - INFO - __main__ -     Total optimization steps = 3255\n","Epoch:   0% 0/1 [00:00<?, ?it/s]\n","Iteration:   0% 0/3255 [00:00<?, ?it/s]\u001b[A\n","Iteration:   0% 1/3255 [00:01<1:20:30,  1.48s/it]\u001b[A\n","Iteration:   0% 2/3255 [00:02<1:19:36,  1.47s/it]\u001b[A\n","Iteration:   0% 3/3255 [00:04<1:18:56,  1.46s/it]\u001b[A\n","Iteration:   0% 4/3255 [00:05<1:18:36,  1.45s/it]\u001b[A\n","Iteration:   0% 5/3255 [00:07<1:18:09,  1.44s/it]\u001b[A\n","Iteration:   0% 6/3255 [00:08<1:17:57,  1.44s/it]\u001b[A\n","Iteration:   0% 7/3255 [00:10<1:17:45,  1.44s/it]\u001b[A\n","Iteration:   0% 8/3255 [00:11<1:17:52,  1.44s/it]\u001b[A\n","Iteration:   0% 9/3255 [00:12<1:17:45,  1.44s/it]\u001b[A\n","Iteration:   0% 10/3255 [00:14<1:17:51,  1.44s/it]\u001b[A\n","Iteration:   0% 11/3255 [00:15<1:17:42,  1.44s/it]\u001b[A\n","Iteration:   0% 12/3255 [00:17<1:17:21,  1.43s/it]\u001b[A\n","Iteration:   0% 13/3255 [00:18<1:17:13,  1.43s/it]\u001b[A\n","Iteration:   0% 14/3255 [00:20<1:17:24,  1.43s/it]\u001b[A\n","Iteration:   0% 15/3255 [00:21<1:17:18,  1.43s/it]\u001b[A\n","Iteration:   0% 16/3255 [00:22<1:17:08,  1.43s/it]\u001b[A\n","Iteration:   1% 17/3255 [00:24<1:16:58,  1.43s/it]\u001b[A\n","Iteration:   1% 18/3255 [00:25<1:16:54,  1.43s/it]\u001b[A\n","Iteration:   1% 19/3255 [00:27<1:16:53,  1.43s/it]\u001b[A\n","Iteration:   1% 20/3255 [00:28<1:17:01,  1.43s/it]\u001b[A\n","Iteration:   1% 21/3255 [00:30<1:16:53,  1.43s/it]\u001b[A\n","Iteration:   1% 22/3255 [00:31<1:16:55,  1.43s/it]\u001b[A\n","Iteration:   1% 23/3255 [00:32<1:16:46,  1.43s/it]\u001b[A\n","Iteration:   1% 24/3255 [00:34<1:16:51,  1.43s/it]\u001b[A\n","Iteration:   1% 25/3255 [00:35<1:16:45,  1.43s/it]\u001b[A\n","Iteration:   1% 26/3255 [00:37<1:16:33,  1.42s/it]\u001b[A\n","Iteration:   1% 27/3255 [00:38<1:16:24,  1.42s/it]\u001b[A\n","Iteration:   1% 28/3255 [00:40<1:16:22,  1.42s/it]\u001b[A\n","Iteration:   1% 29/3255 [00:41<1:16:27,  1.42s/it]\u001b[A\n","Iteration:   1% 30/3255 [00:42<1:16:27,  1.42s/it]\u001b[A\n","Iteration:   1% 31/3255 [00:44<1:16:38,  1.43s/it]\u001b[A\n","Iteration:   1% 32/3255 [00:45<1:16:34,  1.43s/it]\u001b[A\n","Iteration:   1% 33/3255 [00:47<1:16:18,  1.42s/it]\u001b[A\n","Iteration:   1% 34/3255 [00:48<1:16:34,  1.43s/it]\u001b[A\n","Iteration:   1% 35/3255 [00:50<1:16:21,  1.42s/it]\u001b[A\n","Iteration:   1% 36/3255 [00:51<1:16:19,  1.42s/it]\u001b[A\n","Iteration:   1% 37/3255 [00:52<1:16:20,  1.42s/it]\u001b[A\n","Iteration:   1% 38/3255 [00:54<1:16:18,  1.42s/it]\u001b[A\n","Iteration:   1% 39/3255 [00:55<1:15:59,  1.42s/it]\u001b[A\n","Iteration:   1% 40/3255 [00:57<1:16:05,  1.42s/it]\u001b[A\n","Iteration:   1% 41/3255 [00:58<1:16:07,  1.42s/it]\u001b[A\n","Iteration:   1% 42/3255 [00:59<1:16:07,  1.42s/it]\u001b[A\n","Iteration:   1% 43/3255 [01:01<1:16:16,  1.42s/it]\u001b[A\n","Iteration:   1% 44/3255 [01:02<1:16:10,  1.42s/it]\u001b[A\n","Iteration:   1% 45/3255 [01:04<1:15:54,  1.42s/it]\u001b[A\n","Iteration:   1% 46/3255 [01:05<1:16:12,  1.42s/it]\u001b[A\n","Iteration:   1% 47/3255 [01:07<1:16:01,  1.42s/it]\u001b[A\n","Iteration:   1% 48/3255 [01:08<1:15:53,  1.42s/it]\u001b[A\n","Iteration:   2% 49/3255 [01:09<1:16:10,  1.43s/it]\u001b[A11/26/2019 18:46:44 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-50/config.json\n","11/26/2019 18:46:45 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-50/pytorch_model.bin\n","11/26/2019 18:46:45 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-50\n","\n","Iteration:   2% 50/3255 [01:12<1:41:25,  1.90s/it]\u001b[A\n","Iteration:   2% 51/3255 [01:14<1:32:59,  1.74s/it]\u001b[A\n","Iteration:   2% 52/3255 [01:15<1:27:44,  1.64s/it]\u001b[A\n","Iteration:   2% 53/3255 [01:17<1:24:08,  1.58s/it]\u001b[A\n","Iteration:   2% 54/3255 [01:18<1:21:41,  1.53s/it]\u001b[A\n","Iteration:   2% 55/3255 [01:19<1:19:50,  1.50s/it]\u001b[A\n","Iteration:   2% 56/3255 [01:21<1:18:44,  1.48s/it]\u001b[A\n","Iteration:   2% 57/3255 [01:22<1:17:41,  1.46s/it]\u001b[A\n","Iteration:   2% 58/3255 [01:24<1:16:56,  1.44s/it]\u001b[A\n","Iteration:   2% 59/3255 [01:25<1:16:31,  1.44s/it]\u001b[A\n","Iteration:   2% 60/3255 [01:27<1:16:14,  1.43s/it]\u001b[A\n","Iteration:   2% 61/3255 [01:28<1:15:49,  1.42s/it]\u001b[A\n","Iteration:   2% 62/3255 [01:29<1:15:53,  1.43s/it]\u001b[A\n","Iteration:   2% 63/3255 [01:31<1:15:52,  1.43s/it]\u001b[A\n","Iteration:   2% 64/3255 [01:32<1:15:36,  1.42s/it]\u001b[A\n","Iteration:   2% 65/3255 [01:34<1:15:18,  1.42s/it]\u001b[A\n","Iteration:   2% 66/3255 [01:35<1:15:19,  1.42s/it]\u001b[A\n","Iteration:   2% 67/3255 [01:36<1:15:15,  1.42s/it]\u001b[A\n","Iteration:   2% 68/3255 [01:38<1:15:25,  1.42s/it]\u001b[A\n","Iteration:   2% 69/3255 [01:39<1:15:21,  1.42s/it]\u001b[A\n","Iteration:   2% 70/3255 [01:41<1:15:31,  1.42s/it]\u001b[A\n","Iteration:   2% 71/3255 [01:42<1:15:27,  1.42s/it]\u001b[A\n","Iteration:   2% 72/3255 [01:44<1:15:20,  1.42s/it]\u001b[A\n","Iteration:   2% 73/3255 [01:45<1:15:16,  1.42s/it]\u001b[A\n","Iteration:   2% 74/3255 [01:46<1:15:16,  1.42s/it]\u001b[A\n","Iteration:   2% 75/3255 [01:48<1:15:07,  1.42s/it]\u001b[A\n","Iteration:   2% 76/3255 [01:49<1:14:52,  1.41s/it]\u001b[A\n","Iteration:   2% 77/3255 [01:51<1:14:58,  1.42s/it]\u001b[A\n","Iteration:   2% 78/3255 [01:52<1:15:04,  1.42s/it]\u001b[A\n","Iteration:   2% 79/3255 [01:54<1:15:04,  1.42s/it]\u001b[A\n","Iteration:   2% 80/3255 [01:55<1:15:13,  1.42s/it]\u001b[A\n","Iteration:   2% 81/3255 [01:56<1:15:12,  1.42s/it]\u001b[A\n","Iteration:   3% 82/3255 [01:58<1:15:06,  1.42s/it]\u001b[A\n","Iteration:   3% 83/3255 [01:59<1:14:59,  1.42s/it]\u001b[A\n","Iteration:   3% 84/3255 [02:01<1:14:56,  1.42s/it]\u001b[A\n","Iteration:   3% 85/3255 [02:02<1:14:55,  1.42s/it]\u001b[A\n","Iteration:   3% 86/3255 [02:03<1:14:45,  1.42s/it]\u001b[A\n","Iteration:   3% 87/3255 [02:05<1:14:40,  1.41s/it]\u001b[A\n","Iteration:   3% 88/3255 [02:06<1:14:54,  1.42s/it]\u001b[A\n","Iteration:   3% 89/3255 [02:08<1:15:00,  1.42s/it]\u001b[A\n","Iteration:   3% 90/3255 [02:09<1:14:46,  1.42s/it]\u001b[A\n","Iteration:   3% 91/3255 [02:11<1:14:58,  1.42s/it]\u001b[A\n","Iteration:   3% 92/3255 [02:12<1:14:54,  1.42s/it]\u001b[A\n","Iteration:   3% 93/3255 [02:13<1:15:07,  1.43s/it]\u001b[A\n","Iteration:   3% 94/3255 [02:15<1:14:57,  1.42s/it]\u001b[A\n","Iteration:   3% 95/3255 [02:16<1:14:58,  1.42s/it]\u001b[A\n","Iteration:   3% 96/3255 [02:18<1:14:44,  1.42s/it]\u001b[A\n","Iteration:   3% 97/3255 [02:19<1:14:38,  1.42s/it]\u001b[A\n","Iteration:   3% 98/3255 [02:20<1:14:35,  1.42s/it]\u001b[A\n","Iteration:   3% 99/3255 [02:22<1:14:20,  1.41s/it]\u001b[A11/26/2019 18:47:56 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-100/config.json\n","11/26/2019 18:47:58 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-100/pytorch_model.bin\n","11/26/2019 18:47:58 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-100\n","\n","Iteration:   3% 100/3255 [02:25<1:39:42,  1.90s/it]\u001b[A\n","Iteration:   3% 101/3255 [02:26<1:31:30,  1.74s/it]\u001b[A\n","Iteration:   3% 102/3255 [02:28<1:26:12,  1.64s/it]\u001b[A\n","Iteration:   3% 103/3255 [02:29<1:22:39,  1.57s/it]\u001b[A\n","Iteration:   3% 104/3255 [02:31<1:20:05,  1.53s/it]\u001b[A\n","Iteration:   3% 105/3255 [02:32<1:18:27,  1.49s/it]\u001b[A\n","Iteration:   3% 106/3255 [02:33<1:17:25,  1.48s/it]\u001b[A\n","Iteration:   3% 107/3255 [02:35<1:16:29,  1.46s/it]\u001b[A\n","Iteration:   3% 108/3255 [02:36<1:15:56,  1.45s/it]\u001b[A\n","Iteration:   3% 109/3255 [02:38<1:15:08,  1.43s/it]\u001b[A\n","Iteration:   3% 110/3255 [02:39<1:14:54,  1.43s/it]\u001b[A\n","Iteration:   3% 111/3255 [02:40<1:14:46,  1.43s/it]\u001b[A\n","Iteration:   3% 112/3255 [02:42<1:14:36,  1.42s/it]\u001b[A\n","Iteration:   3% 113/3255 [02:43<1:14:44,  1.43s/it]\u001b[A\n","Iteration:   4% 114/3255 [02:45<1:14:27,  1.42s/it]\u001b[A\n","Iteration:   4% 115/3255 [02:46<1:14:36,  1.43s/it]\u001b[A\n","Iteration:   4% 116/3255 [02:48<1:14:18,  1.42s/it]\u001b[A\n","Iteration:   4% 117/3255 [02:49<1:14:20,  1.42s/it]\u001b[A\n","Iteration:   4% 118/3255 [02:50<1:14:07,  1.42s/it]\u001b[A\n","Iteration:   4% 119/3255 [02:52<1:14:14,  1.42s/it]\u001b[A\n","Iteration:   4% 120/3255 [02:53<1:14:17,  1.42s/it]\u001b[A\n","Iteration:   4% 121/3255 [02:55<1:14:02,  1.42s/it]\u001b[A\n","Iteration:   4% 122/3255 [02:56<1:14:00,  1.42s/it]\u001b[A\n","Iteration:   4% 123/3255 [02:57<1:13:53,  1.42s/it]\u001b[A\n","Iteration:   4% 124/3255 [02:59<1:13:56,  1.42s/it]\u001b[A\n","Iteration:   4% 125/3255 [03:00<1:14:00,  1.42s/it]\u001b[A\n","Iteration:   4% 126/3255 [03:02<1:13:48,  1.42s/it]\u001b[A\n","Iteration:   4% 127/3255 [03:03<1:13:41,  1.41s/it]\u001b[A\n","Iteration:   4% 128/3255 [03:05<1:13:50,  1.42s/it]\u001b[A\n","Iteration:   4% 129/3255 [03:06<1:13:50,  1.42s/it]\u001b[A\n","Iteration:   4% 130/3255 [03:07<1:13:41,  1.41s/it]\u001b[A\n","Iteration:   4% 131/3255 [03:09<1:13:53,  1.42s/it]\u001b[A\n","Iteration:   4% 132/3255 [03:10<1:13:47,  1.42s/it]\u001b[A\n","Iteration:   4% 133/3255 [03:12<1:13:43,  1.42s/it]\u001b[A\n","Iteration:   4% 134/3255 [03:13<1:14:00,  1.42s/it]\u001b[A\n","Iteration:   4% 135/3255 [03:15<1:13:46,  1.42s/it]\u001b[A\n","Iteration:   4% 136/3255 [03:16<1:13:47,  1.42s/it]\u001b[A\n","Iteration:   4% 137/3255 [03:17<1:13:37,  1.42s/it]\u001b[A\n","Iteration:   4% 138/3255 [03:19<1:13:30,  1.42s/it]\u001b[A\n","Iteration:   4% 139/3255 [03:20<1:13:39,  1.42s/it]\u001b[A\n","Iteration:   4% 140/3255 [03:22<1:13:37,  1.42s/it]\u001b[A\n","Iteration:   4% 141/3255 [03:23<1:13:41,  1.42s/it]\u001b[A\n","Iteration:   4% 142/3255 [03:24<1:13:32,  1.42s/it]\u001b[A\n","Iteration:   4% 143/3255 [03:26<1:13:45,  1.42s/it]\u001b[A\n","Iteration:   4% 144/3255 [03:27<1:13:45,  1.42s/it]\u001b[A\n","Iteration:   4% 145/3255 [03:29<1:13:28,  1.42s/it]\u001b[A\n","Iteration:   4% 146/3255 [03:30<1:13:38,  1.42s/it]\u001b[A\n","Iteration:   5% 147/3255 [03:32<1:13:40,  1.42s/it]\u001b[A\n","Iteration:   5% 148/3255 [03:33<1:13:46,  1.42s/it]\u001b[A\n","Iteration:   5% 149/3255 [03:34<1:13:59,  1.43s/it]\u001b[A11/26/2019 18:49:09 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-150/config.json\n","11/26/2019 18:49:10 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-150/pytorch_model.bin\n","11/26/2019 18:49:10 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-150\n","\n","Iteration:   5% 150/3255 [03:37<1:37:55,  1.89s/it]\u001b[A\n","Iteration:   5% 151/3255 [03:39<1:29:32,  1.73s/it]\u001b[A\n","Iteration:   5% 152/3255 [03:40<1:24:48,  1.64s/it]\u001b[A\n","Iteration:   5% 153/3255 [03:42<1:21:30,  1.58s/it]\u001b[A\n","Iteration:   5% 154/3255 [03:43<1:18:53,  1.53s/it]\u001b[A\n","Iteration:   5% 155/3255 [03:44<1:17:14,  1.49s/it]\u001b[A\n","Iteration:   5% 156/3255 [03:46<1:16:04,  1.47s/it]\u001b[A\n","Iteration:   5% 157/3255 [03:47<1:14:59,  1.45s/it]\u001b[A\n","Iteration:   5% 158/3255 [03:49<1:14:15,  1.44s/it]\u001b[A\n","Iteration:   5% 159/3255 [03:50<1:14:05,  1.44s/it]\u001b[A\n","Iteration:   5% 160/3255 [03:52<1:13:38,  1.43s/it]\u001b[A\n","Iteration:   5% 161/3255 [03:53<1:13:26,  1.42s/it]\u001b[A\n","Iteration:   5% 162/3255 [03:54<1:13:26,  1.42s/it]\u001b[A\n","Iteration:   5% 163/3255 [03:56<1:13:25,  1.42s/it]\u001b[A\n","Iteration:   5% 164/3255 [03:57<1:13:27,  1.43s/it]\u001b[A\n","Iteration:   5% 165/3255 [03:59<1:13:07,  1.42s/it]\u001b[A\n","Iteration:   5% 166/3255 [04:00<1:13:01,  1.42s/it]\u001b[A\n","Iteration:   5% 167/3255 [04:01<1:12:44,  1.41s/it]\u001b[A\n","Iteration:   5% 168/3255 [04:03<1:12:43,  1.41s/it]\u001b[A\n","Iteration:   5% 169/3255 [04:04<1:12:36,  1.41s/it]\u001b[A\n","Iteration:   5% 170/3255 [04:06<1:12:45,  1.42s/it]\u001b[A\n","Iteration:   5% 171/3255 [04:07<1:12:52,  1.42s/it]\u001b[A\n","Iteration:   5% 172/3255 [04:09<1:13:01,  1.42s/it]\u001b[A\n","Iteration:   5% 173/3255 [04:10<1:13:08,  1.42s/it]\u001b[A\n","Iteration:   5% 174/3255 [04:11<1:13:12,  1.43s/it]\u001b[A\n","Iteration:   5% 175/3255 [04:13<1:12:59,  1.42s/it]\u001b[A\n","Iteration:   5% 176/3255 [04:14<1:12:57,  1.42s/it]\u001b[A\n","Iteration:   5% 177/3255 [04:16<1:12:47,  1.42s/it]\u001b[A\n","Iteration:   5% 178/3255 [04:17<1:12:50,  1.42s/it]\u001b[A\n","Iteration:   5% 179/3255 [04:18<1:12:46,  1.42s/it]\u001b[A\n","Iteration:   6% 180/3255 [04:20<1:12:38,  1.42s/it]\u001b[A\n","Iteration:   6% 181/3255 [04:21<1:12:39,  1.42s/it]\u001b[A\n","Iteration:   6% 182/3255 [04:23<1:12:52,  1.42s/it]\u001b[A\n","Iteration:   6% 183/3255 [04:24<1:12:53,  1.42s/it]\u001b[A\n","Iteration:   6% 184/3255 [04:26<1:12:39,  1.42s/it]\u001b[A\n","Iteration:   6% 185/3255 [04:27<1:12:47,  1.42s/it]\u001b[A\n","Iteration:   6% 186/3255 [04:28<1:12:52,  1.42s/it]\u001b[A\n","Iteration:   6% 187/3255 [04:30<1:12:31,  1.42s/it]\u001b[A\n","Iteration:   6% 188/3255 [04:31<1:12:49,  1.42s/it]\u001b[A\n","Iteration:   6% 189/3255 [04:33<1:12:42,  1.42s/it]\u001b[A\n","Iteration:   6% 190/3255 [04:34<1:12:28,  1.42s/it]\u001b[A\n","Iteration:   6% 191/3255 [04:36<1:12:32,  1.42s/it]\u001b[A\n","Iteration:   6% 192/3255 [04:37<1:12:47,  1.43s/it]\u001b[A\n","Iteration:   6% 193/3255 [04:38<1:12:43,  1.42s/it]\u001b[A\n","Iteration:   6% 194/3255 [04:40<1:12:41,  1.42s/it]\u001b[A\n","Iteration:   6% 195/3255 [04:41<1:12:20,  1.42s/it]\u001b[A\n","Iteration:   6% 196/3255 [04:43<1:12:20,  1.42s/it]\u001b[A\n","Iteration:   6% 197/3255 [04:44<1:12:26,  1.42s/it]\u001b[A\n","Iteration:   6% 198/3255 [04:45<1:12:29,  1.42s/it]\u001b[A\n","Iteration:   6% 199/3255 [04:47<1:12:27,  1.42s/it]\u001b[A11/26/2019 18:50:21 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-200/config.json\n","11/26/2019 18:50:23 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-200/pytorch_model.bin\n","11/26/2019 18:50:23 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-200\n","\n","Iteration:   6% 200/3255 [04:50<1:35:28,  1.88s/it]\u001b[A\n","Iteration:   6% 201/3255 [04:51<1:27:43,  1.72s/it]\u001b[A\n","Iteration:   6% 202/3255 [04:53<1:22:53,  1.63s/it]\u001b[A\n","Iteration:   6% 203/3255 [04:54<1:19:39,  1.57s/it]\u001b[A\n","Iteration:   6% 204/3255 [04:55<1:17:25,  1.52s/it]\u001b[A\n","Iteration:   6% 205/3255 [04:57<1:15:47,  1.49s/it]\u001b[A\n","Iteration:   6% 206/3255 [04:58<1:14:49,  1.47s/it]\u001b[A\n","Iteration:   6% 207/3255 [05:00<1:14:01,  1.46s/it]\u001b[A\n","Iteration:   6% 208/3255 [05:01<1:13:22,  1.44s/it]\u001b[A\n","Iteration:   6% 209/3255 [05:03<1:13:05,  1.44s/it]\u001b[A\n","Iteration:   6% 210/3255 [05:04<1:12:35,  1.43s/it]\u001b[A\n","Iteration:   6% 211/3255 [05:05<1:12:16,  1.42s/it]\u001b[A\n","Iteration:   7% 212/3255 [05:07<1:12:08,  1.42s/it]\u001b[A\n","Iteration:   7% 213/3255 [05:08<1:12:03,  1.42s/it]\u001b[A\n","Iteration:   7% 214/3255 [05:10<1:11:43,  1.42s/it]\u001b[A\n","Iteration:   7% 215/3255 [05:11<1:11:58,  1.42s/it]\u001b[A\n","Iteration:   7% 216/3255 [05:12<1:12:05,  1.42s/it]\u001b[A\n","Iteration:   7% 217/3255 [05:14<1:12:05,  1.42s/it]\u001b[A\n","Iteration:   7% 218/3255 [05:15<1:11:58,  1.42s/it]\u001b[A\n","Iteration:   7% 219/3255 [05:17<1:11:58,  1.42s/it]\u001b[A\n","Iteration:   7% 220/3255 [05:18<1:11:57,  1.42s/it]\u001b[A\n","Iteration:   7% 221/3255 [05:20<1:11:50,  1.42s/it]\u001b[A\n","Iteration:   7% 222/3255 [05:21<1:12:01,  1.42s/it]\u001b[A\n","Iteration:   7% 223/3255 [05:22<1:11:48,  1.42s/it]\u001b[A\n","Iteration:   7% 224/3255 [05:24<1:11:48,  1.42s/it]\u001b[A\n","Iteration:   7% 225/3255 [05:25<1:12:04,  1.43s/it]\u001b[A\n","Iteration:   7% 226/3255 [05:27<1:11:56,  1.43s/it]\u001b[A\n","Iteration:   7% 227/3255 [05:28<1:11:49,  1.42s/it]\u001b[A\n","Iteration:   7% 228/3255 [05:30<1:11:22,  1.41s/it]\u001b[A\n","Iteration:   7% 229/3255 [05:31<1:11:35,  1.42s/it]\u001b[A\n","Iteration:   7% 230/3255 [05:32<1:11:19,  1.41s/it]\u001b[A\n","Iteration:   7% 231/3255 [05:34<1:11:29,  1.42s/it]\u001b[A\n","Iteration:   7% 232/3255 [05:35<1:11:42,  1.42s/it]\u001b[A\n","Iteration:   7% 233/3255 [05:37<1:11:36,  1.42s/it]\u001b[A\n","Iteration:   7% 234/3255 [05:38<1:11:43,  1.42s/it]\u001b[A\n","Iteration:   7% 235/3255 [05:40<1:11:36,  1.42s/it]\u001b[A\n","Iteration:   7% 236/3255 [05:41<1:11:37,  1.42s/it]\u001b[A\n","Iteration:   7% 237/3255 [05:42<1:11:48,  1.43s/it]\u001b[A\n","Iteration:   7% 238/3255 [05:44<1:11:27,  1.42s/it]\u001b[A\n","Iteration:   7% 239/3255 [05:45<1:11:21,  1.42s/it]\u001b[A\n","Iteration:   7% 240/3255 [05:47<1:11:20,  1.42s/it]\u001b[A\n","Iteration:   7% 241/3255 [05:48<1:11:15,  1.42s/it]\u001b[A\n","Iteration:   7% 242/3255 [05:49<1:11:10,  1.42s/it]\u001b[A\n","Iteration:   7% 243/3255 [05:51<1:11:12,  1.42s/it]\u001b[A\n","Iteration:   7% 244/3255 [05:52<1:10:59,  1.41s/it]\u001b[A\n","Iteration:   8% 245/3255 [05:54<1:11:12,  1.42s/it]\u001b[A\n","Iteration:   8% 246/3255 [05:55<1:11:25,  1.42s/it]\u001b[A\n","Iteration:   8% 247/3255 [05:57<1:11:14,  1.42s/it]\u001b[A\n","Iteration:   8% 248/3255 [05:58<1:11:04,  1.42s/it]\u001b[A\n","Iteration:   8% 249/3255 [05:59<1:11:12,  1.42s/it]\u001b[A11/26/2019 18:51:34 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-250/config.json\n","11/26/2019 18:51:35 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-250/pytorch_model.bin\n","11/26/2019 18:51:35 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-250\n","\n","Iteration:   8% 250/3255 [06:02<1:35:15,  1.90s/it]\u001b[A\n","Iteration:   8% 251/3255 [06:04<1:27:14,  1.74s/it]\u001b[A\n","Iteration:   8% 252/3255 [06:05<1:22:20,  1.65s/it]\u001b[A\n","Iteration:   8% 253/3255 [06:07<1:18:54,  1.58s/it]\u001b[A\n","Iteration:   8% 254/3255 [06:08<1:16:32,  1.53s/it]\u001b[A\n","Iteration:   8% 255/3255 [06:09<1:14:56,  1.50s/it]\u001b[A\n","Iteration:   8% 256/3255 [06:11<1:13:51,  1.48s/it]\u001b[A\n","Iteration:   8% 257/3255 [06:12<1:12:48,  1.46s/it]\u001b[A\n","Iteration:   8% 258/3255 [06:14<1:12:19,  1.45s/it]\u001b[A\n","Iteration:   8% 259/3255 [06:15<1:12:02,  1.44s/it]\u001b[A\n","Iteration:   8% 260/3255 [06:17<1:11:31,  1.43s/it]\u001b[A\n","Iteration:   8% 261/3255 [06:18<1:11:11,  1.43s/it]\u001b[A\n","Iteration:   8% 262/3255 [06:19<1:11:20,  1.43s/it]\u001b[A\n","Iteration:   8% 263/3255 [06:21<1:11:11,  1.43s/it]\u001b[A\n","Iteration:   8% 264/3255 [06:22<1:11:06,  1.43s/it]\u001b[A\n","Iteration:   8% 265/3255 [06:24<1:10:51,  1.42s/it]\u001b[A\n","Iteration:   8% 266/3255 [06:25<1:10:38,  1.42s/it]\u001b[A\n","Iteration:   8% 267/3255 [06:27<1:10:42,  1.42s/it]\u001b[A\n","Iteration:   8% 268/3255 [06:28<1:10:43,  1.42s/it]\u001b[A\n","Iteration:   8% 269/3255 [06:29<1:10:56,  1.43s/it]\u001b[A\n","Iteration:   8% 270/3255 [06:31<1:10:54,  1.43s/it]\u001b[A\n","Iteration:   8% 271/3255 [06:32<1:10:57,  1.43s/it]\u001b[A\n","Iteration:   8% 272/3255 [06:34<1:10:42,  1.42s/it]\u001b[A\n","Iteration:   8% 273/3255 [06:35<1:10:31,  1.42s/it]\u001b[A\n","Iteration:   8% 274/3255 [06:36<1:10:25,  1.42s/it]\u001b[A\n","Iteration:   8% 275/3255 [06:38<1:10:18,  1.42s/it]\u001b[A\n","Iteration:   8% 276/3255 [06:39<1:10:17,  1.42s/it]\u001b[A\n","Iteration:   9% 277/3255 [06:41<1:10:20,  1.42s/it]\u001b[A\n","Iteration:   9% 278/3255 [06:42<1:10:31,  1.42s/it]\u001b[A\n","Iteration:   9% 279/3255 [06:44<1:10:19,  1.42s/it]\u001b[A\n","Iteration:   9% 280/3255 [06:45<1:10:09,  1.42s/it]\u001b[A\n","Iteration:   9% 281/3255 [06:46<1:10:18,  1.42s/it]\u001b[A\n","Iteration:   9% 282/3255 [06:48<1:10:04,  1.41s/it]\u001b[A\n","Iteration:   9% 283/3255 [06:49<1:10:13,  1.42s/it]\u001b[A\n","Iteration:   9% 284/3255 [06:51<1:10:06,  1.42s/it]\u001b[A\n","Iteration:   9% 285/3255 [06:52<1:10:02,  1.41s/it]\u001b[A\n","Iteration:   9% 286/3255 [06:53<1:10:03,  1.42s/it]\u001b[A\n","Iteration:   9% 287/3255 [06:55<1:10:05,  1.42s/it]\u001b[A\n","Iteration:   9% 288/3255 [06:56<1:10:08,  1.42s/it]\u001b[A\n","Iteration:   9% 289/3255 [06:58<1:10:23,  1.42s/it]\u001b[A\n","Iteration:   9% 290/3255 [06:59<1:10:07,  1.42s/it]\u001b[A\n","Iteration:   9% 291/3255 [07:01<1:10:02,  1.42s/it]\u001b[A\n","Iteration:   9% 292/3255 [07:02<1:09:52,  1.41s/it]\u001b[A\n","Iteration:   9% 293/3255 [07:03<1:09:54,  1.42s/it]\u001b[A\n","Iteration:   9% 294/3255 [07:05<1:10:01,  1.42s/it]\u001b[A\n","Iteration:   9% 295/3255 [07:06<1:10:20,  1.43s/it]\u001b[A\n","Iteration:   9% 296/3255 [07:08<1:10:07,  1.42s/it]\u001b[A\n","Iteration:   9% 297/3255 [07:09<1:10:00,  1.42s/it]\u001b[A\n","Iteration:   9% 298/3255 [07:11<1:09:59,  1.42s/it]\u001b[A\n","Iteration:   9% 299/3255 [07:12<1:10:02,  1.42s/it]\u001b[A11/26/2019 18:52:46 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-300/config.json\n","11/26/2019 18:52:48 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-300/pytorch_model.bin\n","11/26/2019 18:52:48 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-300\n","\n","Iteration:   9% 300/3255 [07:15<1:33:52,  1.91s/it]\u001b[A\n","Iteration:   9% 301/3255 [07:16<1:25:57,  1.75s/it]\u001b[A\n","Iteration:   9% 302/3255 [07:18<1:21:06,  1.65s/it]\u001b[A\n","Iteration:   9% 303/3255 [07:19<1:17:38,  1.58s/it]\u001b[A\n","Iteration:   9% 304/3255 [07:21<1:15:16,  1.53s/it]\u001b[A\n","Iteration:   9% 305/3255 [07:22<1:13:38,  1.50s/it]\u001b[A\n","Iteration:   9% 306/3255 [07:23<1:12:19,  1.47s/it]\u001b[A\n","Iteration:   9% 307/3255 [07:25<1:11:27,  1.45s/it]\u001b[A\n","Iteration:   9% 308/3255 [07:26<1:10:52,  1.44s/it]\u001b[A\n","Iteration:   9% 309/3255 [07:28<1:10:24,  1.43s/it]\u001b[A\n","Iteration:  10% 310/3255 [07:29<1:10:13,  1.43s/it]\u001b[A\n","Iteration:  10% 311/3255 [07:31<1:09:56,  1.43s/it]\u001b[A\n","Iteration:  10% 312/3255 [07:32<1:09:51,  1.42s/it]\u001b[A\n","Iteration:  10% 313/3255 [07:33<1:09:37,  1.42s/it]\u001b[A\n","Iteration:  10% 314/3255 [07:35<1:09:39,  1.42s/it]\u001b[A\n","Iteration:  10% 315/3255 [07:36<1:09:37,  1.42s/it]\u001b[A\n","Iteration:  10% 316/3255 [07:38<1:09:34,  1.42s/it]\u001b[A\n","Iteration:  10% 317/3255 [07:39<1:09:36,  1.42s/it]\u001b[A\n","Iteration:  10% 318/3255 [07:40<1:09:37,  1.42s/it]\u001b[A\n","Iteration:  10% 319/3255 [07:42<1:09:34,  1.42s/it]\u001b[A\n","Iteration:  10% 320/3255 [07:43<1:09:22,  1.42s/it]\u001b[A\n","Iteration:  10% 321/3255 [07:45<1:09:30,  1.42s/it]\u001b[A\n","Iteration:  10% 322/3255 [07:46<1:09:30,  1.42s/it]\u001b[A\n","Iteration:  10% 323/3255 [07:48<1:09:16,  1.42s/it]\u001b[A\n","Iteration:  10% 324/3255 [07:49<1:09:08,  1.42s/it]\u001b[A\n","Iteration:  10% 325/3255 [07:50<1:09:04,  1.41s/it]\u001b[A\n","Iteration:  10% 326/3255 [07:52<1:08:51,  1.41s/it]\u001b[A\n","Iteration:  10% 327/3255 [07:53<1:08:59,  1.41s/it]\u001b[A\n","Iteration:  10% 328/3255 [07:55<1:09:05,  1.42s/it]\u001b[A\n","Iteration:  10% 329/3255 [07:56<1:09:07,  1.42s/it]\u001b[A\n","Iteration:  10% 330/3255 [07:57<1:09:21,  1.42s/it]\u001b[A\n","Iteration:  10% 331/3255 [07:59<1:09:21,  1.42s/it]\u001b[A\n","Iteration:  10% 332/3255 [08:00<1:09:25,  1.43s/it]\u001b[A\n","Iteration:  10% 333/3255 [08:02<1:09:29,  1.43s/it]\u001b[A\n","Iteration:  10% 334/3255 [08:03<1:09:19,  1.42s/it]\u001b[A\n","Iteration:  10% 335/3255 [08:05<1:09:16,  1.42s/it]\u001b[A\n","Iteration:  10% 336/3255 [08:06<1:09:38,  1.43s/it]\u001b[A\n","Iteration:  10% 337/3255 [08:07<1:09:18,  1.42s/it]\u001b[A\n","Iteration:  10% 338/3255 [08:09<1:09:07,  1.42s/it]\u001b[A\n","Iteration:  10% 339/3255 [08:10<1:08:59,  1.42s/it]\u001b[A\n","Iteration:  10% 340/3255 [08:12<1:08:44,  1.41s/it]\u001b[A\n","Iteration:  10% 341/3255 [08:13<1:08:49,  1.42s/it]\u001b[A\n","Iteration:  11% 342/3255 [08:15<1:09:06,  1.42s/it]\u001b[A\n","Iteration:  11% 343/3255 [08:16<1:09:04,  1.42s/it]\u001b[A\n","Iteration:  11% 344/3255 [08:17<1:08:55,  1.42s/it]\u001b[A\n","Iteration:  11% 345/3255 [08:19<1:09:05,  1.42s/it]\u001b[A\n","Iteration:  11% 346/3255 [08:20<1:08:57,  1.42s/it]\u001b[A\n","Iteration:  11% 347/3255 [08:22<1:08:52,  1.42s/it]\u001b[A\n","Iteration:  11% 348/3255 [08:23<1:08:56,  1.42s/it]\u001b[A\n","Iteration:  11% 349/3255 [08:24<1:08:55,  1.42s/it]\u001b[A11/26/2019 18:53:59 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-350/config.json\n","11/26/2019 18:54:00 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-350/pytorch_model.bin\n","11/26/2019 18:54:00 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-350\n","\n","Iteration:  11% 350/3255 [08:27<1:31:15,  1.88s/it]\u001b[A\n","Iteration:  11% 351/3255 [08:29<1:23:43,  1.73s/it]\u001b[A\n","Iteration:  11% 352/3255 [08:30<1:19:22,  1.64s/it]\u001b[A\n","Iteration:  11% 353/3255 [08:32<1:16:06,  1.57s/it]\u001b[A\n","Iteration:  11% 354/3255 [08:33<1:13:58,  1.53s/it]\u001b[A\n","Iteration:  11% 355/3255 [08:35<1:12:16,  1.50s/it]\u001b[A\n","Iteration:  11% 356/3255 [08:36<1:11:10,  1.47s/it]\u001b[A\n","Iteration:  11% 357/3255 [08:37<1:10:29,  1.46s/it]\u001b[A\n","Iteration:  11% 358/3255 [08:39<1:09:57,  1.45s/it]\u001b[A\n","Iteration:  11% 359/3255 [08:40<1:09:34,  1.44s/it]\u001b[A\n","Iteration:  11% 360/3255 [08:42<1:09:20,  1.44s/it]\u001b[A\n","Iteration:  11% 361/3255 [08:43<1:09:09,  1.43s/it]\u001b[A\n","Iteration:  11% 362/3255 [08:45<1:09:10,  1.43s/it]\u001b[A\n","Iteration:  11% 363/3255 [08:46<1:08:50,  1.43s/it]\u001b[A\n","Iteration:  11% 364/3255 [08:47<1:08:42,  1.43s/it]\u001b[A\n","Iteration:  11% 365/3255 [08:49<1:08:25,  1.42s/it]\u001b[A\n","Iteration:  11% 366/3255 [08:50<1:08:31,  1.42s/it]\u001b[A\n","Iteration:  11% 367/3255 [08:52<1:08:23,  1.42s/it]\u001b[A\n","Iteration:  11% 368/3255 [08:53<1:08:12,  1.42s/it]\u001b[A\n","Iteration:  11% 369/3255 [08:54<1:08:20,  1.42s/it]\u001b[A\n","Iteration:  11% 370/3255 [08:56<1:08:18,  1.42s/it]\u001b[A\n","Iteration:  11% 371/3255 [08:57<1:08:12,  1.42s/it]\u001b[A\n","Iteration:  11% 372/3255 [08:59<1:08:11,  1.42s/it]\u001b[A\n","Iteration:  11% 373/3255 [09:00<1:08:20,  1.42s/it]\u001b[A\n","Iteration:  11% 374/3255 [09:02<1:08:05,  1.42s/it]\u001b[A\n","Iteration:  12% 375/3255 [09:03<1:08:06,  1.42s/it]\u001b[A\n","Iteration:  12% 376/3255 [09:04<1:08:08,  1.42s/it]\u001b[A\n","Iteration:  12% 377/3255 [09:06<1:08:06,  1.42s/it]\u001b[A\n","Iteration:  12% 378/3255 [09:07<1:08:16,  1.42s/it]\u001b[A\n","Iteration:  12% 379/3255 [09:09<1:08:08,  1.42s/it]\u001b[A\n","Iteration:  12% 380/3255 [09:10<1:07:55,  1.42s/it]\u001b[A\n","Iteration:  12% 381/3255 [09:11<1:07:45,  1.41s/it]\u001b[A\n","Iteration:  12% 382/3255 [09:13<1:07:55,  1.42s/it]\u001b[A\n","Iteration:  12% 383/3255 [09:14<1:07:56,  1.42s/it]\u001b[A\n","Iteration:  12% 384/3255 [09:16<1:07:53,  1.42s/it]\u001b[A\n","Iteration:  12% 385/3255 [09:17<1:08:07,  1.42s/it]\u001b[A\n","Iteration:  12% 386/3255 [09:19<1:07:57,  1.42s/it]\u001b[A\n","Iteration:  12% 387/3255 [09:20<1:07:56,  1.42s/it]\u001b[A\n","Iteration:  12% 388/3255 [09:21<1:08:02,  1.42s/it]\u001b[A\n","Iteration:  12% 389/3255 [09:23<1:07:50,  1.42s/it]\u001b[A\n","Iteration:  12% 390/3255 [09:24<1:07:56,  1.42s/it]\u001b[A\n","Iteration:  12% 391/3255 [09:26<1:08:01,  1.42s/it]\u001b[A\n","Iteration:  12% 392/3255 [09:27<1:07:55,  1.42s/it]\u001b[A\n","Iteration:  12% 393/3255 [09:29<1:07:41,  1.42s/it]\u001b[A\n","Iteration:  12% 394/3255 [09:30<1:07:44,  1.42s/it]\u001b[A\n","Iteration:  12% 395/3255 [09:31<1:07:57,  1.43s/it]\u001b[A\n","Iteration:  12% 396/3255 [09:33<1:07:38,  1.42s/it]\u001b[A\n","Iteration:  12% 397/3255 [09:34<1:08:01,  1.43s/it]\u001b[A\n","Iteration:  12% 398/3255 [09:36<1:07:38,  1.42s/it]\u001b[A\n","Iteration:  12% 399/3255 [09:37<1:07:41,  1.42s/it]\u001b[A11/26/2019 18:55:11 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-400/config.json\n","11/26/2019 18:55:13 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-400/pytorch_model.bin\n","11/26/2019 18:55:13 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-400\n","\n","Iteration:  12% 400/3255 [09:40<1:29:48,  1.89s/it]\u001b[A\n","Iteration:  12% 401/3255 [09:41<1:22:21,  1.73s/it]\u001b[A\n","Iteration:  12% 402/3255 [09:43<1:17:38,  1.63s/it]\u001b[A\n","Iteration:  12% 403/3255 [09:44<1:14:45,  1.57s/it]\u001b[A\n","Iteration:  12% 404/3255 [09:46<1:12:35,  1.53s/it]\u001b[A\n","Iteration:  12% 405/3255 [09:47<1:11:02,  1.50s/it]\u001b[A\n","Iteration:  12% 406/3255 [09:49<1:10:06,  1.48s/it]\u001b[A\n","Iteration:  13% 407/3255 [09:50<1:09:15,  1.46s/it]\u001b[A\n","Iteration:  13% 408/3255 [09:51<1:08:52,  1.45s/it]\u001b[A\n","Iteration:  13% 409/3255 [09:53<1:08:29,  1.44s/it]\u001b[A\n","Iteration:  13% 410/3255 [09:54<1:07:57,  1.43s/it]\u001b[A\n","Iteration:  13% 411/3255 [09:56<1:07:39,  1.43s/it]\u001b[A\n","Iteration:  13% 412/3255 [09:57<1:07:31,  1.43s/it]\u001b[A\n","Iteration:  13% 413/3255 [09:58<1:07:21,  1.42s/it]\u001b[A\n","Iteration:  13% 414/3255 [10:00<1:07:10,  1.42s/it]\u001b[A\n","Iteration:  13% 415/3255 [10:01<1:07:07,  1.42s/it]\u001b[A\n","Iteration:  13% 416/3255 [10:03<1:07:09,  1.42s/it]\u001b[A\n","Iteration:  13% 417/3255 [10:04<1:07:01,  1.42s/it]\u001b[A\n","Iteration:  13% 418/3255 [10:06<1:06:59,  1.42s/it]\u001b[A\n","Iteration:  13% 419/3255 [10:07<1:07:06,  1.42s/it]\u001b[A\n","Iteration:  13% 420/3255 [10:08<1:07:04,  1.42s/it]\u001b[A\n","Iteration:  13% 421/3255 [10:10<1:06:56,  1.42s/it]\u001b[A\n","Iteration:  13% 422/3255 [10:11<1:07:02,  1.42s/it]\u001b[A\n","Iteration:  13% 423/3255 [10:13<1:06:50,  1.42s/it]\u001b[A\n","Iteration:  13% 424/3255 [10:14<1:07:03,  1.42s/it]\u001b[A\n","Iteration:  13% 425/3255 [10:15<1:06:58,  1.42s/it]\u001b[A\n","Iteration:  13% 426/3255 [10:17<1:07:00,  1.42s/it]\u001b[A\n","Iteration:  13% 427/3255 [10:18<1:07:00,  1.42s/it]\u001b[A\n","Iteration:  13% 428/3255 [10:20<1:07:01,  1.42s/it]\u001b[A\n","Iteration:  13% 429/3255 [10:21<1:07:01,  1.42s/it]\u001b[A\n","Iteration:  13% 430/3255 [10:23<1:06:56,  1.42s/it]\u001b[A\n","Iteration:  13% 431/3255 [10:24<1:06:58,  1.42s/it]\u001b[A\n","Iteration:  13% 432/3255 [10:25<1:06:51,  1.42s/it]\u001b[A\n","Iteration:  13% 433/3255 [10:27<1:06:58,  1.42s/it]\u001b[A\n","Iteration:  13% 434/3255 [10:28<1:07:00,  1.43s/it]\u001b[A\n","Iteration:  13% 435/3255 [10:30<1:06:49,  1.42s/it]\u001b[A\n","Iteration:  13% 436/3255 [10:31<1:06:44,  1.42s/it]\u001b[A\n","Iteration:  13% 437/3255 [10:33<1:06:31,  1.42s/it]\u001b[A\n","Iteration:  13% 438/3255 [10:34<1:06:42,  1.42s/it]\u001b[A\n","Iteration:  13% 439/3255 [10:35<1:06:48,  1.42s/it]\u001b[A\n","Iteration:  14% 440/3255 [10:37<1:06:48,  1.42s/it]\u001b[A\n","Iteration:  14% 441/3255 [10:38<1:06:50,  1.43s/it]\u001b[A\n","Iteration:  14% 442/3255 [10:40<1:06:31,  1.42s/it]\u001b[A\n","Iteration:  14% 443/3255 [10:41<1:06:25,  1.42s/it]\u001b[A\n","Iteration:  14% 444/3255 [10:42<1:06:19,  1.42s/it]\u001b[A\n","Iteration:  14% 445/3255 [10:44<1:06:30,  1.42s/it]\u001b[A\n","Iteration:  14% 446/3255 [10:45<1:06:34,  1.42s/it]\u001b[A\n","Iteration:  14% 447/3255 [10:47<1:06:23,  1.42s/it]\u001b[A\n","Iteration:  14% 448/3255 [10:48<1:06:21,  1.42s/it]\u001b[A\n","Iteration:  14% 449/3255 [10:50<1:06:07,  1.41s/it]\u001b[A11/26/2019 18:56:24 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-450/config.json\n","11/26/2019 18:56:25 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-450/pytorch_model.bin\n","11/26/2019 18:56:25 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-450\n","\n","Iteration:  14% 450/3255 [10:52<1:25:12,  1.82s/it]\u001b[A\n","Iteration:  14% 451/3255 [10:54<1:18:44,  1.68s/it]\u001b[A\n","Iteration:  14% 452/3255 [10:55<1:14:44,  1.60s/it]\u001b[A\n","Iteration:  14% 453/3255 [10:57<1:12:17,  1.55s/it]\u001b[A\n","Iteration:  14% 454/3255 [10:58<1:10:21,  1.51s/it]\u001b[A\n","Iteration:  14% 455/3255 [10:59<1:09:14,  1.48s/it]\u001b[A\n","Iteration:  14% 456/3255 [11:01<1:08:27,  1.47s/it]\u001b[A\n","Iteration:  14% 457/3255 [11:02<1:07:47,  1.45s/it]\u001b[A\n","Iteration:  14% 458/3255 [11:04<1:07:22,  1.45s/it]\u001b[A\n","Iteration:  14% 459/3255 [11:05<1:07:07,  1.44s/it]\u001b[A\n","Iteration:  14% 460/3255 [11:06<1:06:37,  1.43s/it]\u001b[A\n","Iteration:  14% 461/3255 [11:08<1:06:30,  1.43s/it]\u001b[A\n","Iteration:  14% 462/3255 [11:09<1:06:22,  1.43s/it]\u001b[A\n","Iteration:  14% 463/3255 [11:11<1:06:19,  1.43s/it]\u001b[A\n","Iteration:  14% 464/3255 [11:12<1:06:13,  1.42s/it]\u001b[A\n","Iteration:  14% 465/3255 [11:14<1:06:00,  1.42s/it]\u001b[A\n","Iteration:  14% 466/3255 [11:15<1:05:57,  1.42s/it]\u001b[A\n","Iteration:  14% 467/3255 [11:16<1:05:50,  1.42s/it]\u001b[A\n","Iteration:  14% 468/3255 [11:18<1:05:58,  1.42s/it]\u001b[A\n","Iteration:  14% 469/3255 [11:19<1:05:48,  1.42s/it]\u001b[A\n","Iteration:  14% 470/3255 [11:21<1:05:57,  1.42s/it]\u001b[A\n","Iteration:  14% 471/3255 [11:22<1:06:05,  1.42s/it]\u001b[A\n","Iteration:  15% 472/3255 [11:24<1:05:55,  1.42s/it]\u001b[A\n","Iteration:  15% 473/3255 [11:25<1:05:52,  1.42s/it]\u001b[A\n","Iteration:  15% 474/3255 [11:26<1:05:47,  1.42s/it]\u001b[A\n","Iteration:  15% 475/3255 [11:28<1:05:38,  1.42s/it]\u001b[A\n","Iteration:  15% 476/3255 [11:29<1:05:50,  1.42s/it]\u001b[A\n","Iteration:  15% 477/3255 [11:31<1:05:46,  1.42s/it]\u001b[A\n","Iteration:  15% 478/3255 [11:32<1:05:53,  1.42s/it]\u001b[A\n","Iteration:  15% 479/3255 [11:33<1:05:50,  1.42s/it]\u001b[A\n","Iteration:  15% 480/3255 [11:35<1:05:37,  1.42s/it]\u001b[A\n","Iteration:  15% 481/3255 [11:36<1:05:32,  1.42s/it]\u001b[A\n","Iteration:  15% 482/3255 [11:38<1:05:23,  1.41s/it]\u001b[A\n","Iteration:  15% 483/3255 [11:39<1:05:25,  1.42s/it]\u001b[A\n","Iteration:  15% 484/3255 [11:41<1:05:36,  1.42s/it]\u001b[A\n","Iteration:  15% 485/3255 [11:42<1:05:37,  1.42s/it]\u001b[A\n","Iteration:  15% 486/3255 [11:43<1:05:44,  1.42s/it]\u001b[A\n","Iteration:  15% 487/3255 [11:45<1:05:51,  1.43s/it]\u001b[A\n","Iteration:  15% 488/3255 [11:46<1:05:39,  1.42s/it]\u001b[A\n","Iteration:  15% 489/3255 [11:48<1:05:37,  1.42s/it]\u001b[A\n","Iteration:  15% 490/3255 [11:49<1:05:47,  1.43s/it]\u001b[A\n","Iteration:  15% 491/3255 [11:51<1:05:45,  1.43s/it]\u001b[A\n","Iteration:  15% 492/3255 [11:52<1:05:36,  1.42s/it]\u001b[A\n","Iteration:  15% 493/3255 [11:53<1:05:34,  1.42s/it]\u001b[A\n","Iteration:  15% 494/3255 [11:55<1:05:20,  1.42s/it]\u001b[A\n","Iteration:  15% 495/3255 [11:56<1:05:25,  1.42s/it]\u001b[A\n","Iteration:  15% 496/3255 [11:58<1:05:39,  1.43s/it]\u001b[A\n","Iteration:  15% 497/3255 [11:59<1:05:23,  1.42s/it]\u001b[A\n","Iteration:  15% 498/3255 [12:00<1:05:23,  1.42s/it]\u001b[A\n","Iteration:  15% 499/3255 [12:02<1:05:33,  1.43s/it]\u001b[A11/26/2019 18:57:36 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-500/config.json\n","11/26/2019 18:57:38 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-500/pytorch_model.bin\n","11/26/2019 18:57:38 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-500\n","\n","Iteration:  15% 500/3255 [12:06<1:36:16,  2.10s/it]\u001b[A\n","Iteration:  15% 501/3255 [12:07<1:26:03,  1.87s/it]\u001b[A\n","Iteration:  15% 502/3255 [12:08<1:19:43,  1.74s/it]\u001b[A\n","Iteration:  15% 503/3255 [12:10<1:15:04,  1.64s/it]\u001b[A\n","Iteration:  15% 504/3255 [12:11<1:12:09,  1.57s/it]\u001b[A\n","Iteration:  16% 505/3255 [12:13<1:10:01,  1.53s/it]\u001b[A\n","Iteration:  16% 506/3255 [12:14<1:08:38,  1.50s/it]\u001b[A\n","Iteration:  16% 507/3255 [12:15<1:07:29,  1.47s/it]\u001b[A\n","Iteration:  16% 508/3255 [12:17<1:06:39,  1.46s/it]\u001b[A\n","Iteration:  16% 509/3255 [12:18<1:06:10,  1.45s/it]\u001b[A\n","Iteration:  16% 510/3255 [12:20<1:05:58,  1.44s/it]\u001b[A\n","Iteration:  16% 511/3255 [12:21<1:05:43,  1.44s/it]\u001b[A\n","Iteration:  16% 512/3255 [12:23<1:05:39,  1.44s/it]\u001b[A\n","Iteration:  16% 513/3255 [12:24<1:05:14,  1.43s/it]\u001b[A\n","Iteration:  16% 514/3255 [12:25<1:05:12,  1.43s/it]\u001b[A\n","Iteration:  16% 515/3255 [12:27<1:05:01,  1.42s/it]\u001b[A\n","Iteration:  16% 516/3255 [12:28<1:05:02,  1.42s/it]\u001b[A\n","Iteration:  16% 517/3255 [12:30<1:05:02,  1.43s/it]\u001b[A\n","Iteration:  16% 518/3255 [12:31<1:05:07,  1.43s/it]\u001b[A\n","Iteration:  16% 519/3255 [12:33<1:04:51,  1.42s/it]\u001b[A\n","Iteration:  16% 520/3255 [12:34<1:04:45,  1.42s/it]\u001b[A\n","Iteration:  16% 521/3255 [12:35<1:04:36,  1.42s/it]\u001b[A\n","Iteration:  16% 522/3255 [12:37<1:04:46,  1.42s/it]\u001b[A\n","Iteration:  16% 523/3255 [12:38<1:04:35,  1.42s/it]\u001b[A\n","Iteration:  16% 524/3255 [12:40<1:04:35,  1.42s/it]\u001b[A\n","Iteration:  16% 525/3255 [12:41<1:04:39,  1.42s/it]\u001b[A\n","Iteration:  16% 526/3255 [12:42<1:04:28,  1.42s/it]\u001b[A\n","Iteration:  16% 527/3255 [12:44<1:04:23,  1.42s/it]\u001b[A\n","Iteration:  16% 528/3255 [12:45<1:04:28,  1.42s/it]\u001b[A\n","Iteration:  16% 529/3255 [12:47<1:04:21,  1.42s/it]\u001b[A\n","Iteration:  16% 530/3255 [12:48<1:04:26,  1.42s/it]\u001b[A\n","Iteration:  16% 531/3255 [12:50<1:04:26,  1.42s/it]\u001b[A\n","Iteration:  16% 532/3255 [12:51<1:04:31,  1.42s/it]\u001b[A\n","Iteration:  16% 533/3255 [12:52<1:04:18,  1.42s/it]\u001b[A\n","Iteration:  16% 534/3255 [12:54<1:04:36,  1.42s/it]\u001b[A\n","Iteration:  16% 535/3255 [12:55<1:04:34,  1.42s/it]\u001b[A\n","Iteration:  16% 536/3255 [12:57<1:04:30,  1.42s/it]\u001b[A\n","Iteration:  16% 537/3255 [12:58<1:04:21,  1.42s/it]\u001b[A\n","Iteration:  17% 538/3255 [13:00<1:04:20,  1.42s/it]\u001b[A\n","Iteration:  17% 539/3255 [13:01<1:04:16,  1.42s/it]\u001b[A\n","Iteration:  17% 540/3255 [13:02<1:04:24,  1.42s/it]\u001b[A\n","Iteration:  17% 541/3255 [13:04<1:04:26,  1.42s/it]\u001b[A\n","Iteration:  17% 542/3255 [13:05<1:04:15,  1.42s/it]\u001b[A\n","Iteration:  17% 543/3255 [13:07<1:04:22,  1.42s/it]\u001b[A\n","Iteration:  17% 544/3255 [13:08<1:04:22,  1.42s/it]\u001b[A\n","Iteration:  17% 545/3255 [13:09<1:04:17,  1.42s/it]\u001b[A\n","Iteration:  17% 546/3255 [13:11<1:04:13,  1.42s/it]\u001b[A\n","Iteration:  17% 547/3255 [13:12<1:04:13,  1.42s/it]\u001b[A\n","Iteration:  17% 548/3255 [13:14<1:04:16,  1.42s/it]\u001b[A\n","Iteration:  17% 549/3255 [13:15<1:04:05,  1.42s/it]\u001b[A11/26/2019 18:58:49 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-550/config.json\n","11/26/2019 18:58:51 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-550/pytorch_model.bin\n","11/26/2019 18:58:51 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-550\n","\n","Iteration:  17% 550/3255 [13:18<1:23:34,  1.85s/it]\u001b[A\n","Iteration:  17% 551/3255 [13:19<1:17:01,  1.71s/it]\u001b[A\n","Iteration:  17% 552/3255 [13:21<1:13:00,  1.62s/it]\u001b[A\n","Iteration:  17% 553/3255 [13:22<1:10:10,  1.56s/it]\u001b[A\n","Iteration:  17% 554/3255 [13:24<1:08:27,  1.52s/it]\u001b[A\n","Iteration:  17% 555/3255 [13:25<1:06:54,  1.49s/it]\u001b[A\n","Iteration:  17% 556/3255 [13:26<1:05:54,  1.47s/it]\u001b[A\n","Iteration:  17% 557/3255 [13:28<1:05:11,  1.45s/it]\u001b[A\n","Iteration:  17% 558/3255 [13:29<1:04:36,  1.44s/it]\u001b[A\n","Iteration:  17% 559/3255 [13:31<1:04:17,  1.43s/it]\u001b[A\n","Iteration:  17% 560/3255 [13:32<1:03:57,  1.42s/it]\u001b[A\n","Iteration:  17% 561/3255 [13:34<1:03:52,  1.42s/it]\u001b[A\n","Iteration:  17% 562/3255 [13:35<1:03:46,  1.42s/it]\u001b[A\n","Iteration:  17% 563/3255 [13:36<1:03:53,  1.42s/it]\u001b[A\n","Iteration:  17% 564/3255 [13:38<1:03:37,  1.42s/it]\u001b[A\n","Iteration:  17% 565/3255 [13:39<1:03:37,  1.42s/it]\u001b[A\n","Iteration:  17% 566/3255 [13:41<1:03:35,  1.42s/it]\u001b[A\n","Iteration:  17% 567/3255 [13:42<1:03:34,  1.42s/it]\u001b[A\n","Iteration:  17% 568/3255 [13:43<1:03:31,  1.42s/it]\u001b[A\n","Iteration:  17% 569/3255 [13:45<1:03:27,  1.42s/it]\u001b[A\n","Iteration:  18% 570/3255 [13:46<1:03:36,  1.42s/it]\u001b[A\n","Iteration:  18% 571/3255 [13:48<1:03:30,  1.42s/it]\u001b[A\n","Iteration:  18% 572/3255 [13:49<1:03:42,  1.42s/it]\u001b[A\n","Iteration:  18% 573/3255 [13:51<1:03:38,  1.42s/it]\u001b[A\n","Iteration:  18% 574/3255 [13:52<1:03:31,  1.42s/it]\u001b[A\n","Iteration:  18% 575/3255 [13:53<1:03:33,  1.42s/it]\u001b[A\n","Iteration:  18% 576/3255 [13:55<1:03:23,  1.42s/it]\u001b[A\n","Iteration:  18% 577/3255 [13:56<1:03:23,  1.42s/it]\u001b[A\n","Iteration:  18% 578/3255 [13:58<1:03:17,  1.42s/it]\u001b[A\n","Iteration:  18% 579/3255 [13:59<1:03:07,  1.42s/it]\u001b[A\n","Iteration:  18% 580/3255 [14:01<1:03:04,  1.41s/it]\u001b[A\n","Iteration:  18% 581/3255 [14:02<1:03:12,  1.42s/it]\u001b[A\n","Iteration:  18% 582/3255 [14:03<1:03:01,  1.41s/it]\u001b[A\n","Iteration:  18% 583/3255 [14:05<1:03:00,  1.42s/it]\u001b[A\n","Iteration:  18% 584/3255 [14:06<1:03:11,  1.42s/it]\u001b[A\n","Iteration:  18% 585/3255 [14:08<1:03:01,  1.42s/it]\u001b[A\n","Iteration:  18% 586/3255 [14:09<1:03:02,  1.42s/it]\u001b[A\n","Iteration:  18% 587/3255 [14:10<1:03:02,  1.42s/it]\u001b[A\n","Iteration:  18% 588/3255 [14:12<1:03:03,  1.42s/it]\u001b[A\n","Iteration:  18% 589/3255 [14:13<1:02:54,  1.42s/it]\u001b[A\n","Iteration:  18% 590/3255 [14:15<1:02:44,  1.41s/it]\u001b[A\n","Iteration:  18% 591/3255 [14:16<1:03:02,  1.42s/it]\u001b[A\n","Iteration:  18% 592/3255 [14:18<1:02:47,  1.41s/it]\u001b[A\n","Iteration:  18% 593/3255 [14:19<1:02:58,  1.42s/it]\u001b[A\n","Iteration:  18% 594/3255 [14:20<1:02:54,  1.42s/it]\u001b[A\n","Iteration:  18% 595/3255 [14:22<1:02:57,  1.42s/it]\u001b[A\n","Iteration:  18% 596/3255 [14:23<1:02:52,  1.42s/it]\u001b[A\n","Iteration:  18% 597/3255 [14:25<1:02:52,  1.42s/it]\u001b[A\n","Iteration:  18% 598/3255 [14:26<1:02:57,  1.42s/it]\u001b[A\n","Iteration:  18% 599/3255 [14:27<1:02:51,  1.42s/it]\u001b[A11/26/2019 19:00:02 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-600/config.json\n","11/26/2019 19:00:03 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-600/pytorch_model.bin\n","11/26/2019 19:00:03 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-600\n","\n","Iteration:  18% 600/3255 [14:30<1:22:51,  1.87s/it]\u001b[A\n","Iteration:  18% 601/3255 [14:32<1:16:08,  1.72s/it]\u001b[A\n","Iteration:  18% 602/3255 [14:33<1:12:07,  1.63s/it]\u001b[A\n","Iteration:  19% 603/3255 [14:35<1:09:12,  1.57s/it]\u001b[A\n","Iteration:  19% 604/3255 [14:36<1:07:20,  1.52s/it]\u001b[A\n","Iteration:  19% 605/3255 [14:37<1:05:58,  1.49s/it]\u001b[A\n","Iteration:  19% 606/3255 [14:39<1:05:10,  1.48s/it]\u001b[A\n","Iteration:  19% 607/3255 [14:40<1:04:11,  1.45s/it]\u001b[A\n","Iteration:  19% 608/3255 [14:42<1:03:37,  1.44s/it]\u001b[A\n","Iteration:  19% 609/3255 [14:43<1:03:21,  1.44s/it]\u001b[A\n","Iteration:  19% 610/3255 [14:45<1:03:19,  1.44s/it]\u001b[A\n","Iteration:  19% 611/3255 [14:46<1:02:56,  1.43s/it]\u001b[A\n","Iteration:  19% 612/3255 [14:47<1:02:42,  1.42s/it]\u001b[A\n","Iteration:  19% 613/3255 [14:49<1:02:42,  1.42s/it]\u001b[A\n","Iteration:  19% 614/3255 [14:50<1:02:42,  1.42s/it]\u001b[A\n","Iteration:  19% 615/3255 [14:52<1:02:38,  1.42s/it]\u001b[A\n","Iteration:  19% 616/3255 [14:53<1:02:29,  1.42s/it]\u001b[A\n","Iteration:  19% 617/3255 [14:54<1:02:32,  1.42s/it]\u001b[A\n","Iteration:  19% 618/3255 [14:56<1:02:34,  1.42s/it]\u001b[A\n","Iteration:  19% 619/3255 [14:57<1:02:33,  1.42s/it]\u001b[A\n","Iteration:  19% 620/3255 [14:59<1:02:28,  1.42s/it]\u001b[A\n","Iteration:  19% 621/3255 [15:00<1:02:43,  1.43s/it]\u001b[A\n","Iteration:  19% 622/3255 [15:02<1:02:33,  1.43s/it]\u001b[A\n","Iteration:  19% 623/3255 [15:03<1:02:22,  1.42s/it]\u001b[A\n","Iteration:  19% 624/3255 [15:04<1:02:21,  1.42s/it]\u001b[A\n","Iteration:  19% 625/3255 [15:06<1:02:07,  1.42s/it]\u001b[A\n","Iteration:  19% 626/3255 [15:07<1:02:11,  1.42s/it]\u001b[A\n","Iteration:  19% 627/3255 [15:09<1:02:15,  1.42s/it]\u001b[A\n","Iteration:  19% 628/3255 [15:10<1:02:06,  1.42s/it]\u001b[A\n","Iteration:  19% 629/3255 [15:12<1:02:21,  1.42s/it]\u001b[A\n","Iteration:  19% 630/3255 [15:13<1:02:19,  1.42s/it]\u001b[A\n","Iteration:  19% 631/3255 [15:14<1:02:14,  1.42s/it]\u001b[A\n","Iteration:  19% 632/3255 [15:16<1:01:58,  1.42s/it]\u001b[A\n","Iteration:  19% 633/3255 [15:17<1:02:05,  1.42s/it]\u001b[A\n","Iteration:  19% 634/3255 [15:19<1:02:04,  1.42s/it]\u001b[A\n","Iteration:  20% 635/3255 [15:20<1:01:57,  1.42s/it]\u001b[A\n","Iteration:  20% 636/3255 [15:21<1:01:45,  1.41s/it]\u001b[A\n","Iteration:  20% 637/3255 [15:23<1:01:38,  1.41s/it]\u001b[A\n","Iteration:  20% 638/3255 [15:24<1:01:38,  1.41s/it]\u001b[A\n","Iteration:  20% 639/3255 [15:26<1:01:52,  1.42s/it]\u001b[A\n","Iteration:  20% 640/3255 [15:27<1:02:01,  1.42s/it]\u001b[A\n","Iteration:  20% 641/3255 [15:29<1:01:55,  1.42s/it]\u001b[A\n","Iteration:  20% 642/3255 [15:30<1:01:42,  1.42s/it]\u001b[A\n","Iteration:  20% 643/3255 [15:31<1:01:55,  1.42s/it]\u001b[A\n","Iteration:  20% 644/3255 [15:33<1:01:38,  1.42s/it]\u001b[A\n","Iteration:  20% 645/3255 [15:34<1:01:43,  1.42s/it]\u001b[A\n","Iteration:  20% 646/3255 [15:36<1:01:40,  1.42s/it]\u001b[A\n","Iteration:  20% 647/3255 [15:37<1:01:29,  1.41s/it]\u001b[A\n","Iteration:  20% 648/3255 [15:39<1:01:39,  1.42s/it]\u001b[A\n","Iteration:  20% 649/3255 [15:40<1:01:48,  1.42s/it]\u001b[A11/26/2019 19:01:14 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-650/config.json\n","11/26/2019 19:01:16 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-650/pytorch_model.bin\n","11/26/2019 19:01:16 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-650\n","\n","Iteration:  20% 650/3255 [15:43<1:20:10,  1.85s/it]\u001b[A\n","Iteration:  20% 651/3255 [15:44<1:14:04,  1.71s/it]\u001b[A\n","Iteration:  20% 652/3255 [15:46<1:10:24,  1.62s/it]\u001b[A\n","Iteration:  20% 653/3255 [15:47<1:07:50,  1.56s/it]\u001b[A\n","Iteration:  20% 654/3255 [15:48<1:05:51,  1.52s/it]\u001b[A\n","Iteration:  20% 655/3255 [15:50<1:04:29,  1.49s/it]\u001b[A\n","Iteration:  20% 656/3255 [15:51<1:03:36,  1.47s/it]\u001b[A\n","Iteration:  20% 657/3255 [15:53<1:02:51,  1.45s/it]\u001b[A\n","Iteration:  20% 658/3255 [15:54<1:02:27,  1.44s/it]\u001b[A\n","Iteration:  20% 659/3255 [15:56<1:02:13,  1.44s/it]\u001b[A\n","Iteration:  20% 660/3255 [15:57<1:02:13,  1.44s/it]\u001b[A\n","Iteration:  20% 661/3255 [15:58<1:01:42,  1.43s/it]\u001b[A\n","Iteration:  20% 662/3255 [16:00<1:01:33,  1.42s/it]\u001b[A\n","Iteration:  20% 663/3255 [16:01<1:01:23,  1.42s/it]\u001b[A\n","Iteration:  20% 664/3255 [16:03<1:01:16,  1.42s/it]\u001b[A\n","Iteration:  20% 665/3255 [16:04<1:01:15,  1.42s/it]\u001b[A\n","Iteration:  20% 666/3255 [16:05<1:01:21,  1.42s/it]\u001b[A\n","Iteration:  20% 667/3255 [16:07<1:01:16,  1.42s/it]\u001b[A\n","Iteration:  21% 668/3255 [16:08<1:01:22,  1.42s/it]\u001b[A\n","Iteration:  21% 669/3255 [16:10<1:00:57,  1.41s/it]\u001b[A\n","Iteration:  21% 670/3255 [16:11<1:01:03,  1.42s/it]\u001b[A\n","Iteration:  21% 671/3255 [16:13<1:01:03,  1.42s/it]\u001b[A\n","Iteration:  21% 672/3255 [16:14<1:01:01,  1.42s/it]\u001b[A\n","Iteration:  21% 673/3255 [16:15<1:01:17,  1.42s/it]\u001b[A\n","Iteration:  21% 674/3255 [16:17<1:01:08,  1.42s/it]\u001b[A\n","Iteration:  21% 675/3255 [16:18<1:01:02,  1.42s/it]\u001b[A\n","Iteration:  21% 676/3255 [16:20<1:01:01,  1.42s/it]\u001b[A\n","Iteration:  21% 677/3255 [16:21<1:00:57,  1.42s/it]\u001b[A\n","Iteration:  21% 678/3255 [16:22<1:00:53,  1.42s/it]\u001b[A\n","Iteration:  21% 679/3255 [16:24<1:00:51,  1.42s/it]\u001b[A\n","Iteration:  21% 680/3255 [16:25<1:01:03,  1.42s/it]\u001b[A\n","Iteration:  21% 681/3255 [16:27<1:00:57,  1.42s/it]\u001b[A\n","Iteration:  21% 682/3255 [16:28<1:00:54,  1.42s/it]\u001b[A\n","Iteration:  21% 683/3255 [16:30<1:01:10,  1.43s/it]\u001b[A\n","Iteration:  21% 684/3255 [16:31<1:00:52,  1.42s/it]\u001b[A\n","Iteration:  21% 685/3255 [16:32<1:00:48,  1.42s/it]\u001b[A\n","Iteration:  21% 686/3255 [16:34<1:00:59,  1.42s/it]\u001b[A\n","Iteration:  21% 687/3255 [16:35<1:01:07,  1.43s/it]\u001b[A\n","Iteration:  21% 688/3255 [16:37<1:01:00,  1.43s/it]\u001b[A\n","Iteration:  21% 689/3255 [16:38<1:00:54,  1.42s/it]\u001b[A\n","Iteration:  21% 690/3255 [16:40<1:00:46,  1.42s/it]\u001b[A\n","Iteration:  21% 691/3255 [16:41<1:00:45,  1.42s/it]\u001b[A\n","Iteration:  21% 692/3255 [16:42<1:00:50,  1.42s/it]\u001b[A\n","Iteration:  21% 693/3255 [16:44<1:00:48,  1.42s/it]\u001b[A\n","Iteration:  21% 694/3255 [16:45<1:00:31,  1.42s/it]\u001b[A\n","Iteration:  21% 695/3255 [16:47<1:00:38,  1.42s/it]\u001b[A\n","Iteration:  21% 696/3255 [16:48<1:00:33,  1.42s/it]\u001b[A\n","Iteration:  21% 697/3255 [16:49<1:00:23,  1.42s/it]\u001b[A\n","Iteration:  21% 698/3255 [16:51<1:00:28,  1.42s/it]\u001b[A\n","Iteration:  21% 699/3255 [16:52<1:00:32,  1.42s/it]\u001b[A11/26/2019 19:02:27 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-700/config.json\n","11/26/2019 19:02:28 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-700/pytorch_model.bin\n","11/26/2019 19:02:28 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-700\n","\n","Iteration:  22% 700/3255 [16:55<1:19:05,  1.86s/it]\u001b[A\n","Iteration:  22% 701/3255 [16:57<1:12:55,  1.71s/it]\u001b[A\n","Iteration:  22% 702/3255 [16:58<1:09:10,  1.63s/it]\u001b[A\n","Iteration:  22% 703/3255 [16:59<1:06:20,  1.56s/it]\u001b[A\n","Iteration:  22% 704/3255 [17:01<1:04:34,  1.52s/it]\u001b[A\n","Iteration:  22% 705/3255 [17:02<1:03:09,  1.49s/it]\u001b[A\n","Iteration:  22% 706/3255 [17:04<1:02:30,  1.47s/it]\u001b[A\n","Iteration:  22% 707/3255 [17:05<1:01:56,  1.46s/it]\u001b[A\n","Iteration:  22% 708/3255 [17:07<1:01:23,  1.45s/it]\u001b[A\n","Iteration:  22% 709/3255 [17:08<1:01:01,  1.44s/it]\u001b[A\n","Iteration:  22% 710/3255 [17:09<1:00:45,  1.43s/it]\u001b[A\n","Iteration:  22% 711/3255 [17:11<1:00:33,  1.43s/it]\u001b[A\n","Iteration:  22% 712/3255 [17:12<1:00:30,  1.43s/it]\u001b[A\n","Iteration:  22% 713/3255 [17:14<1:00:33,  1.43s/it]\u001b[A\n","Iteration:  22% 714/3255 [17:15<1:00:31,  1.43s/it]\u001b[A\n","Iteration:  22% 715/3255 [17:16<1:00:12,  1.42s/it]\u001b[A\n","Iteration:  22% 716/3255 [17:18<1:00:00,  1.42s/it]\u001b[A\n","Iteration:  22% 717/3255 [17:19<59:56,  1.42s/it]  \u001b[A\n","Iteration:  22% 718/3255 [17:21<59:58,  1.42s/it]\u001b[A\n","Iteration:  22% 719/3255 [17:22<59:54,  1.42s/it]\u001b[A\n","Iteration:  22% 720/3255 [17:24<59:53,  1.42s/it]\u001b[A\n","Iteration:  22% 721/3255 [17:25<1:00:04,  1.42s/it]\u001b[A\n","Iteration:  22% 722/3255 [17:26<1:00:17,  1.43s/it]\u001b[A\n","Iteration:  22% 723/3255 [17:28<1:00:10,  1.43s/it]\u001b[A\n","Iteration:  22% 724/3255 [17:29<1:00:15,  1.43s/it]\u001b[A\n","Iteration:  22% 725/3255 [17:31<1:00:04,  1.42s/it]\u001b[A\n","Iteration:  22% 726/3255 [17:32<1:00:06,  1.43s/it]\u001b[A\n","Iteration:  22% 727/3255 [17:34<59:57,  1.42s/it]  \u001b[A\n","Iteration:  22% 728/3255 [17:35<59:47,  1.42s/it]\u001b[A\n","Iteration:  22% 729/3255 [17:36<59:49,  1.42s/it]\u001b[A\n","Iteration:  22% 730/3255 [17:38<59:42,  1.42s/it]\u001b[A\n","Iteration:  22% 731/3255 [17:39<59:40,  1.42s/it]\u001b[A\n","Iteration:  22% 732/3255 [17:41<59:42,  1.42s/it]\u001b[A\n","Iteration:  23% 733/3255 [17:42<59:53,  1.42s/it]\u001b[A\n","Iteration:  23% 734/3255 [17:44<1:00:05,  1.43s/it]\u001b[A\n","Iteration:  23% 735/3255 [17:45<59:54,  1.43s/it]  \u001b[A\n","Iteration:  23% 736/3255 [17:46<59:52,  1.43s/it]\u001b[A\n","Iteration:  23% 737/3255 [17:48<59:52,  1.43s/it]\u001b[A\n","Iteration:  23% 738/3255 [17:49<59:43,  1.42s/it]\u001b[A\n","Iteration:  23% 739/3255 [17:51<59:51,  1.43s/it]\u001b[A\n","Iteration:  23% 740/3255 [17:52<59:44,  1.43s/it]\u001b[A\n","Iteration:  23% 741/3255 [17:53<59:33,  1.42s/it]\u001b[A\n","Iteration:  23% 742/3255 [17:55<59:20,  1.42s/it]\u001b[A\n","Iteration:  23% 743/3255 [17:56<59:24,  1.42s/it]\u001b[A\n","Iteration:  23% 744/3255 [17:58<59:23,  1.42s/it]\u001b[A\n","Iteration:  23% 745/3255 [17:59<59:22,  1.42s/it]\u001b[A\n","Iteration:  23% 746/3255 [18:01<59:23,  1.42s/it]\u001b[A\n","Iteration:  23% 747/3255 [18:02<59:43,  1.43s/it]\u001b[A\n","Iteration:  23% 748/3255 [18:03<59:31,  1.42s/it]\u001b[A\n","Iteration:  23% 749/3255 [18:05<59:27,  1.42s/it]\u001b[A11/26/2019 19:03:39 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-750/config.json\n","11/26/2019 19:03:40 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-750/pytorch_model.bin\n","11/26/2019 19:03:40 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-750\n","\n","Iteration:  23% 750/3255 [18:08<1:17:43,  1.86s/it]\u001b[A\n","Iteration:  23% 751/3255 [18:09<1:11:40,  1.72s/it]\u001b[A\n","Iteration:  23% 752/3255 [18:11<1:07:42,  1.62s/it]\u001b[A\n","Iteration:  23% 753/3255 [18:12<1:05:09,  1.56s/it]\u001b[A\n","Iteration:  23% 754/3255 [18:13<1:03:16,  1.52s/it]\u001b[A\n","Iteration:  23% 755/3255 [18:15<1:01:50,  1.48s/it]\u001b[A\n","Iteration:  23% 756/3255 [18:16<1:00:58,  1.46s/it]\u001b[A\n","Iteration:  23% 757/3255 [18:18<1:00:21,  1.45s/it]\u001b[A\n","Iteration:  23% 758/3255 [18:19<59:56,  1.44s/it]  \u001b[A\n","Iteration:  23% 759/3255 [18:20<59:45,  1.44s/it]\u001b[A\n","Iteration:  23% 760/3255 [18:22<59:41,  1.44s/it]\u001b[A\n","Iteration:  23% 761/3255 [18:23<59:20,  1.43s/it]\u001b[A\n","Iteration:  23% 762/3255 [18:25<59:04,  1.42s/it]\u001b[A\n","Iteration:  23% 763/3255 [18:26<58:59,  1.42s/it]\u001b[A\n","Iteration:  23% 764/3255 [18:28<58:46,  1.42s/it]\u001b[A\n","Iteration:  24% 765/3255 [18:29<58:50,  1.42s/it]\u001b[A\n","Iteration:  24% 766/3255 [18:30<58:56,  1.42s/it]\u001b[A\n","Iteration:  24% 767/3255 [18:32<58:50,  1.42s/it]\u001b[A\n","Iteration:  24% 768/3255 [18:33<58:45,  1.42s/it]\u001b[A\n","Iteration:  24% 769/3255 [18:35<58:54,  1.42s/it]\u001b[A\n","Iteration:  24% 770/3255 [18:36<59:04,  1.43s/it]\u001b[A\n","Iteration:  24% 771/3255 [18:37<58:47,  1.42s/it]\u001b[A\n","Iteration:  24% 772/3255 [18:39<58:35,  1.42s/it]\u001b[A\n","Iteration:  24% 773/3255 [18:40<58:30,  1.41s/it]\u001b[A\n","Iteration:  24% 774/3255 [18:42<58:29,  1.41s/it]\u001b[A\n","Iteration:  24% 775/3255 [18:43<58:35,  1.42s/it]\u001b[A\n","Iteration:  24% 776/3255 [18:45<58:32,  1.42s/it]\u001b[A\n","Iteration:  24% 777/3255 [18:46<58:35,  1.42s/it]\u001b[A\n","Iteration:  24% 778/3255 [18:47<58:37,  1.42s/it]\u001b[A\n","Iteration:  24% 779/3255 [18:49<58:34,  1.42s/it]\u001b[A\n","Iteration:  24% 780/3255 [18:50<58:30,  1.42s/it]\u001b[A\n","Iteration:  24% 781/3255 [18:52<58:33,  1.42s/it]\u001b[A\n","Iteration:  24% 782/3255 [18:53<58:41,  1.42s/it]\u001b[A\n","Iteration:  24% 783/3255 [18:55<58:30,  1.42s/it]\u001b[A\n","Iteration:  24% 784/3255 [18:56<58:36,  1.42s/it]\u001b[A\n","Iteration:  24% 785/3255 [18:57<58:43,  1.43s/it]\u001b[A\n","Iteration:  24% 786/3255 [18:59<58:33,  1.42s/it]\u001b[A\n","Iteration:  24% 787/3255 [19:00<58:15,  1.42s/it]\u001b[A\n","Iteration:  24% 788/3255 [19:02<58:11,  1.42s/it]\u001b[A\n","Iteration:  24% 789/3255 [19:03<58:19,  1.42s/it]\u001b[A\n","Iteration:  24% 790/3255 [19:04<58:10,  1.42s/it]\u001b[A\n","Iteration:  24% 791/3255 [19:06<58:10,  1.42s/it]\u001b[A\n","Iteration:  24% 792/3255 [19:07<58:18,  1.42s/it]\u001b[A\n","Iteration:  24% 793/3255 [19:09<58:11,  1.42s/it]\u001b[A\n","Iteration:  24% 794/3255 [19:10<58:17,  1.42s/it]\u001b[A\n","Iteration:  24% 795/3255 [19:12<58:18,  1.42s/it]\u001b[A\n","Iteration:  24% 796/3255 [19:13<58:08,  1.42s/it]\u001b[A\n","Iteration:  24% 797/3255 [19:14<58:12,  1.42s/it]\u001b[A\n","Iteration:  25% 798/3255 [19:16<58:05,  1.42s/it]\u001b[A\n","Iteration:  25% 799/3255 [19:17<58:00,  1.42s/it]\u001b[A11/26/2019 19:04:51 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-800/config.json\n","11/26/2019 19:04:53 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-800/pytorch_model.bin\n","11/26/2019 19:04:53 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-800\n","\n","Iteration:  25% 800/3255 [19:20<1:16:42,  1.87s/it]\u001b[A\n","Iteration:  25% 801/3255 [19:22<1:10:22,  1.72s/it]\u001b[A\n","Iteration:  25% 802/3255 [19:23<1:06:47,  1.63s/it]\u001b[A\n","Iteration:  25% 803/3255 [19:24<1:04:14,  1.57s/it]\u001b[A\n","Iteration:  25% 804/3255 [19:26<1:02:19,  1.53s/it]\u001b[A\n","Iteration:  25% 805/3255 [19:27<1:00:59,  1.49s/it]\u001b[A\n","Iteration:  25% 806/3255 [19:29<1:00:00,  1.47s/it]\u001b[A\n","Iteration:  25% 807/3255 [19:30<59:20,  1.45s/it]  \u001b[A\n","Iteration:  25% 808/3255 [19:31<58:58,  1.45s/it]\u001b[A\n","Iteration:  25% 809/3255 [19:33<58:51,  1.44s/it]\u001b[A\n","Iteration:  25% 810/3255 [19:34<58:19,  1.43s/it]\u001b[A\n","Iteration:  25% 811/3255 [19:36<58:16,  1.43s/it]\u001b[A\n","Iteration:  25% 812/3255 [19:37<58:03,  1.43s/it]\u001b[A\n","Iteration:  25% 813/3255 [19:39<57:54,  1.42s/it]\u001b[A\n","Iteration:  25% 814/3255 [19:40<58:03,  1.43s/it]\u001b[A\n","Iteration:  25% 815/3255 [19:41<57:58,  1.43s/it]\u001b[A\n","Iteration:  25% 816/3255 [19:43<57:54,  1.42s/it]\u001b[A\n","Iteration:  25% 817/3255 [19:44<57:59,  1.43s/it]\u001b[A\n","Iteration:  25% 818/3255 [19:46<58:01,  1.43s/it]\u001b[A\n","Iteration:  25% 819/3255 [19:47<57:49,  1.42s/it]\u001b[A\n","Iteration:  25% 820/3255 [19:49<57:52,  1.43s/it]\u001b[A\n","Iteration:  25% 821/3255 [19:50<57:39,  1.42s/it]\u001b[A\n","Iteration:  25% 822/3255 [19:51<57:52,  1.43s/it]\u001b[A\n","Iteration:  25% 823/3255 [19:53<57:41,  1.42s/it]\u001b[A\n","Iteration:  25% 824/3255 [19:54<57:32,  1.42s/it]\u001b[A\n","Iteration:  25% 825/3255 [19:56<57:24,  1.42s/it]\u001b[A\n","Iteration:  25% 826/3255 [19:57<57:22,  1.42s/it]\u001b[A\n","Iteration:  25% 827/3255 [19:58<57:15,  1.41s/it]\u001b[A\n","Iteration:  25% 828/3255 [20:00<57:20,  1.42s/it]\u001b[A\n","Iteration:  25% 829/3255 [20:01<57:15,  1.42s/it]\u001b[A\n","Iteration:  25% 830/3255 [20:03<57:20,  1.42s/it]\u001b[A\n","Iteration:  26% 831/3255 [20:04<57:25,  1.42s/it]\u001b[A\n","Iteration:  26% 832/3255 [20:06<57:21,  1.42s/it]\u001b[A\n","Iteration:  26% 833/3255 [20:07<57:14,  1.42s/it]\u001b[A\n","Iteration:  26% 834/3255 [20:08<57:16,  1.42s/it]\u001b[A\n","Iteration:  26% 835/3255 [20:10<57:04,  1.42s/it]\u001b[A\n","Iteration:  26% 836/3255 [20:11<57:02,  1.41s/it]\u001b[A\n","Iteration:  26% 837/3255 [20:13<57:22,  1.42s/it]\u001b[A\n","Iteration:  26% 838/3255 [20:14<57:17,  1.42s/it]\u001b[A\n","Iteration:  26% 839/3255 [20:16<57:15,  1.42s/it]\u001b[A\n","Iteration:  26% 840/3255 [20:17<57:19,  1.42s/it]\u001b[A\n","Iteration:  26% 841/3255 [20:18<57:15,  1.42s/it]\u001b[A\n","Iteration:  26% 842/3255 [20:20<57:18,  1.42s/it]\u001b[A\n","Iteration:  26% 843/3255 [20:21<57:20,  1.43s/it]\u001b[A\n","Iteration:  26% 844/3255 [20:23<57:14,  1.42s/it]\u001b[A\n","Iteration:  26% 845/3255 [20:24<57:07,  1.42s/it]\u001b[A\n","Iteration:  26% 846/3255 [20:26<57:14,  1.43s/it]\u001b[A\n","Iteration:  26% 847/3255 [20:27<57:07,  1.42s/it]\u001b[A\n","Iteration:  26% 848/3255 [20:28<57:06,  1.42s/it]\u001b[A\n","Iteration:  26% 849/3255 [20:30<57:18,  1.43s/it]\u001b[A11/26/2019 19:06:04 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-850/config.json\n","11/26/2019 19:06:05 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-850/pytorch_model.bin\n","11/26/2019 19:06:05 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-850\n","\n","Iteration:  26% 850/3255 [20:33<1:15:03,  1.87s/it]\u001b[A\n","Iteration:  26% 851/3255 [20:34<1:09:06,  1.72s/it]\u001b[A\n","Iteration:  26% 852/3255 [20:35<1:05:23,  1.63s/it]\u001b[A\n","Iteration:  26% 853/3255 [20:37<1:02:40,  1.57s/it]\u001b[A\n","Iteration:  26% 854/3255 [20:38<1:00:56,  1.52s/it]\u001b[A\n","Iteration:  26% 855/3255 [20:40<59:46,  1.49s/it]  \u001b[A\n","Iteration:  26% 856/3255 [20:41<58:42,  1.47s/it]\u001b[A\n","Iteration:  26% 857/3255 [20:43<57:54,  1.45s/it]\u001b[A\n","Iteration:  26% 858/3255 [20:44<57:35,  1.44s/it]\u001b[A\n","Iteration:  26% 859/3255 [20:45<57:15,  1.43s/it]\u001b[A\n","Iteration:  26% 860/3255 [20:47<57:12,  1.43s/it]\u001b[A\n","Iteration:  26% 861/3255 [20:48<57:17,  1.44s/it]\u001b[A\n","Iteration:  26% 862/3255 [20:50<56:49,  1.42s/it]\u001b[A\n","Iteration:  27% 863/3255 [20:51<56:41,  1.42s/it]\u001b[A\n","Iteration:  27% 864/3255 [20:53<56:37,  1.42s/it]\u001b[A\n","Iteration:  27% 865/3255 [20:54<56:28,  1.42s/it]\u001b[A\n","Iteration:  27% 866/3255 [20:55<56:28,  1.42s/it]\u001b[A\n","Iteration:  27% 867/3255 [20:57<56:32,  1.42s/it]\u001b[A\n","Iteration:  27% 868/3255 [20:58<56:30,  1.42s/it]\u001b[A\n","Iteration:  27% 869/3255 [21:00<56:28,  1.42s/it]\u001b[A\n","Iteration:  27% 870/3255 [21:01<56:20,  1.42s/it]\u001b[A\n","Iteration:  27% 871/3255 [21:02<56:12,  1.41s/it]\u001b[A\n","Iteration:  27% 872/3255 [21:04<56:16,  1.42s/it]\u001b[A\n","Iteration:  27% 873/3255 [21:05<56:08,  1.41s/it]\u001b[A\n","Iteration:  27% 874/3255 [21:07<56:02,  1.41s/it]\u001b[A\n","Iteration:  27% 875/3255 [21:08<56:06,  1.41s/it]\u001b[A\n","Iteration:  27% 876/3255 [21:09<56:08,  1.42s/it]\u001b[A\n","Iteration:  27% 877/3255 [21:11<56:19,  1.42s/it]\u001b[A\n","Iteration:  27% 878/3255 [21:12<56:17,  1.42s/it]\u001b[A\n","Iteration:  27% 879/3255 [21:14<56:21,  1.42s/it]\u001b[A\n","Iteration:  27% 880/3255 [21:15<56:12,  1.42s/it]\u001b[A\n","Iteration:  27% 881/3255 [21:17<56:15,  1.42s/it]\u001b[A\n","Iteration:  27% 882/3255 [21:18<56:17,  1.42s/it]\u001b[A\n","Iteration:  27% 883/3255 [21:19<56:24,  1.43s/it]\u001b[A\n","Iteration:  27% 884/3255 [21:21<56:23,  1.43s/it]\u001b[A\n","Iteration:  27% 885/3255 [21:22<56:12,  1.42s/it]\u001b[A\n","Iteration:  27% 886/3255 [21:24<56:02,  1.42s/it]\u001b[A\n","Iteration:  27% 887/3255 [21:25<56:00,  1.42s/it]\u001b[A\n","Iteration:  27% 888/3255 [21:27<56:06,  1.42s/it]\u001b[A\n","Iteration:  27% 889/3255 [21:28<56:02,  1.42s/it]\u001b[A\n","Iteration:  27% 890/3255 [21:29<56:05,  1.42s/it]\u001b[A\n","Iteration:  27% 891/3255 [21:31<56:03,  1.42s/it]\u001b[A\n","Iteration:  27% 892/3255 [21:32<56:05,  1.42s/it]\u001b[A\n","Iteration:  27% 893/3255 [21:34<55:46,  1.42s/it]\u001b[A\n","Iteration:  27% 894/3255 [21:35<55:44,  1.42s/it]\u001b[A\n","Iteration:  27% 895/3255 [21:37<55:40,  1.42s/it]\u001b[A\n","Iteration:  28% 896/3255 [21:38<55:43,  1.42s/it]\u001b[A\n","Iteration:  28% 897/3255 [21:39<55:44,  1.42s/it]\u001b[A\n","Iteration:  28% 898/3255 [21:41<55:50,  1.42s/it]\u001b[A\n","Iteration:  28% 899/3255 [21:42<55:53,  1.42s/it]\u001b[A11/26/2019 19:07:16 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-900/config.json\n","11/26/2019 19:07:18 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-900/pytorch_model.bin\n","11/26/2019 19:07:18 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-900\n","\n","Iteration:  28% 900/3255 [21:45<1:14:23,  1.90s/it]\u001b[A\n","Iteration:  28% 901/3255 [21:47<1:08:07,  1.74s/it]\u001b[A\n","Iteration:  28% 902/3255 [21:48<1:04:23,  1.64s/it]\u001b[A\n","Iteration:  28% 903/3255 [21:49<1:01:54,  1.58s/it]\u001b[A\n","Iteration:  28% 904/3255 [21:51<1:00:01,  1.53s/it]\u001b[A\n","Iteration:  28% 905/3255 [21:52<58:25,  1.49s/it]  \u001b[A\n","Iteration:  28% 906/3255 [21:54<57:28,  1.47s/it]\u001b[A\n","Iteration:  28% 907/3255 [21:55<56:52,  1.45s/it]\u001b[A\n","Iteration:  28% 908/3255 [21:57<56:32,  1.45s/it]\u001b[A\n","Iteration:  28% 909/3255 [21:58<56:13,  1.44s/it]\u001b[A\n","Iteration:  28% 910/3255 [21:59<56:05,  1.44s/it]\u001b[A\n","Iteration:  28% 911/3255 [22:01<55:56,  1.43s/it]\u001b[A\n","Iteration:  28% 912/3255 [22:02<55:55,  1.43s/it]\u001b[A\n","Iteration:  28% 913/3255 [22:04<55:40,  1.43s/it]\u001b[A\n","Iteration:  28% 914/3255 [22:05<55:37,  1.43s/it]\u001b[A\n","Iteration:  28% 915/3255 [22:06<55:27,  1.42s/it]\u001b[A\n","Iteration:  28% 916/3255 [22:08<55:28,  1.42s/it]\u001b[A\n","Iteration:  28% 917/3255 [22:09<55:29,  1.42s/it]\u001b[A\n","Iteration:  28% 918/3255 [22:11<55:28,  1.42s/it]\u001b[A\n","Iteration:  28% 919/3255 [22:12<55:14,  1.42s/it]\u001b[A\n","Iteration:  28% 920/3255 [22:14<55:15,  1.42s/it]\u001b[A\n","Iteration:  28% 921/3255 [22:15<55:06,  1.42s/it]\u001b[A\n","Iteration:  28% 922/3255 [22:16<55:13,  1.42s/it]\u001b[A\n","Iteration:  28% 923/3255 [22:18<55:14,  1.42s/it]\u001b[A\n","Iteration:  28% 924/3255 [22:19<55:22,  1.43s/it]\u001b[A\n","Iteration:  28% 925/3255 [22:21<55:18,  1.42s/it]\u001b[A\n","Iteration:  28% 926/3255 [22:22<55:21,  1.43s/it]\u001b[A\n","Iteration:  28% 927/3255 [22:24<55:05,  1.42s/it]\u001b[A\n","Iteration:  29% 928/3255 [22:25<55:08,  1.42s/it]\u001b[A\n","Iteration:  29% 929/3255 [22:26<55:23,  1.43s/it]\u001b[A\n","Iteration:  29% 930/3255 [22:28<55:03,  1.42s/it]\u001b[A\n","Iteration:  29% 931/3255 [22:29<55:12,  1.43s/it]\u001b[A\n","Iteration:  29% 932/3255 [22:31<55:05,  1.42s/it]\u001b[A\n","Iteration:  29% 933/3255 [22:32<54:57,  1.42s/it]\u001b[A\n","Iteration:  29% 934/3255 [22:33<55:08,  1.43s/it]\u001b[A\n","Iteration:  29% 935/3255 [22:35<55:08,  1.43s/it]\u001b[A\n","Iteration:  29% 936/3255 [22:36<55:13,  1.43s/it]\u001b[A\n","Iteration:  29% 937/3255 [22:38<55:03,  1.43s/it]\u001b[A\n","Iteration:  29% 938/3255 [22:39<55:02,  1.43s/it]\u001b[A\n","Iteration:  29% 939/3255 [22:41<54:46,  1.42s/it]\u001b[A\n","Iteration:  29% 940/3255 [22:42<54:45,  1.42s/it]\u001b[A\n","Iteration:  29% 941/3255 [22:43<54:45,  1.42s/it]\u001b[A\n","Iteration:  29% 942/3255 [22:45<54:43,  1.42s/it]\u001b[A\n","Iteration:  29% 943/3255 [22:46<54:43,  1.42s/it]\u001b[A\n","Iteration:  29% 944/3255 [22:48<54:32,  1.42s/it]\u001b[A\n","Iteration:  29% 945/3255 [22:49<54:35,  1.42s/it]\u001b[A\n","Iteration:  29% 946/3255 [22:51<54:37,  1.42s/it]\u001b[A\n","Iteration:  29% 947/3255 [22:52<54:35,  1.42s/it]\u001b[A\n","Iteration:  29% 948/3255 [22:53<54:37,  1.42s/it]\u001b[A\n","Iteration:  29% 949/3255 [22:55<54:36,  1.42s/it]\u001b[A11/26/2019 19:08:29 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-950/config.json\n","11/26/2019 19:08:30 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-950/pytorch_model.bin\n","11/26/2019 19:08:30 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-950\n","\n","Iteration:  29% 950/3255 [22:58<1:11:50,  1.87s/it]\u001b[A\n","Iteration:  29% 951/3255 [22:59<1:06:06,  1.72s/it]\u001b[A\n","Iteration:  29% 952/3255 [23:01<1:02:35,  1.63s/it]\u001b[A\n","Iteration:  29% 953/3255 [23:02<1:00:02,  1.56s/it]\u001b[A\n","Iteration:  29% 954/3255 [23:03<58:18,  1.52s/it]  \u001b[A\n","Iteration:  29% 955/3255 [23:05<57:02,  1.49s/it]\u001b[A\n","Iteration:  29% 956/3255 [23:06<56:15,  1.47s/it]\u001b[A\n","Iteration:  29% 957/3255 [23:08<55:39,  1.45s/it]\u001b[A\n","Iteration:  29% 958/3255 [23:09<55:16,  1.44s/it]\u001b[A\n","Iteration:  29% 959/3255 [23:10<55:09,  1.44s/it]\u001b[A\n","Iteration:  29% 960/3255 [23:12<54:42,  1.43s/it]\u001b[A\n","Iteration:  30% 961/3255 [23:13<54:53,  1.44s/it]\u001b[A\n","Iteration:  30% 962/3255 [23:15<54:35,  1.43s/it]\u001b[A\n","Iteration:  30% 963/3255 [23:16<54:30,  1.43s/it]\u001b[A\n","Iteration:  30% 964/3255 [23:18<54:11,  1.42s/it]\u001b[A\n","Iteration:  30% 965/3255 [23:19<54:15,  1.42s/it]\u001b[A\n","Iteration:  30% 966/3255 [23:20<54:08,  1.42s/it]\u001b[A\n","Iteration:  30% 967/3255 [23:22<54:02,  1.42s/it]\u001b[A\n","Iteration:  30% 968/3255 [23:23<54:10,  1.42s/it]\u001b[A\n","Iteration:  30% 969/3255 [23:25<54:05,  1.42s/it]\u001b[A\n","Iteration:  30% 970/3255 [23:26<54:18,  1.43s/it]\u001b[A\n","Iteration:  30% 971/3255 [23:27<54:11,  1.42s/it]\u001b[A\n","Iteration:  30% 972/3255 [23:29<54:09,  1.42s/it]\u001b[A\n","Iteration:  30% 973/3255 [23:30<53:57,  1.42s/it]\u001b[A\n","Iteration:  30% 974/3255 [23:32<53:52,  1.42s/it]\u001b[A\n","Iteration:  30% 975/3255 [23:33<53:53,  1.42s/it]\u001b[A\n","Iteration:  30% 976/3255 [23:35<53:58,  1.42s/it]\u001b[A\n","Iteration:  30% 977/3255 [23:36<53:53,  1.42s/it]\u001b[A\n","Iteration:  30% 978/3255 [23:37<53:58,  1.42s/it]\u001b[A\n","Iteration:  30% 979/3255 [23:39<53:42,  1.42s/it]\u001b[A\n","Iteration:  30% 980/3255 [23:40<53:45,  1.42s/it]\u001b[A\n","Iteration:  30% 981/3255 [23:42<53:38,  1.42s/it]\u001b[A\n","Iteration:  30% 982/3255 [23:43<53:39,  1.42s/it]\u001b[A\n","Iteration:  30% 983/3255 [23:45<53:46,  1.42s/it]\u001b[A\n","Iteration:  30% 984/3255 [23:46<53:50,  1.42s/it]\u001b[A\n","Iteration:  30% 985/3255 [23:47<53:39,  1.42s/it]\u001b[A\n","Iteration:  30% 986/3255 [23:49<53:42,  1.42s/it]\u001b[A\n","Iteration:  30% 987/3255 [23:50<53:37,  1.42s/it]\u001b[A\n","Iteration:  30% 988/3255 [23:52<53:32,  1.42s/it]\u001b[A\n","Iteration:  30% 989/3255 [23:53<53:29,  1.42s/it]\u001b[A\n","Iteration:  30% 990/3255 [23:54<53:34,  1.42s/it]\u001b[A\n","Iteration:  30% 991/3255 [23:56<53:39,  1.42s/it]\u001b[A\n","Iteration:  30% 992/3255 [23:57<53:39,  1.42s/it]\u001b[A\n","Iteration:  31% 993/3255 [23:59<53:27,  1.42s/it]\u001b[A\n","Iteration:  31% 994/3255 [24:00<53:34,  1.42s/it]\u001b[A\n","Iteration:  31% 995/3255 [24:02<53:25,  1.42s/it]\u001b[A\n","Iteration:  31% 996/3255 [24:03<53:22,  1.42s/it]\u001b[A\n","Iteration:  31% 997/3255 [24:04<53:30,  1.42s/it]\u001b[A\n","Iteration:  31% 998/3255 [24:06<53:25,  1.42s/it]\u001b[A\n","Iteration:  31% 999/3255 [24:07<53:24,  1.42s/it]\u001b[A11/26/2019 19:09:41 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-1000/config.json\n","11/26/2019 19:09:43 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-1000/pytorch_model.bin\n","11/26/2019 19:09:43 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-1000\n","\n","Iteration:  31% 1000/3255 [24:10<1:09:17,  1.84s/it]\u001b[A\n","Iteration:  31% 1001/3255 [24:11<1:03:50,  1.70s/it]\u001b[A\n","Iteration:  31% 1002/3255 [24:13<1:00:50,  1.62s/it]\u001b[A\n","Iteration:  31% 1003/3255 [24:14<58:30,  1.56s/it]  \u001b[A\n","Iteration:  31% 1004/3255 [24:16<56:56,  1.52s/it]\u001b[A\n","Iteration:  31% 1005/3255 [24:17<55:44,  1.49s/it]\u001b[A\n","Iteration:  31% 1006/3255 [24:19<54:59,  1.47s/it]\u001b[A\n","Iteration:  31% 1007/3255 [24:20<54:28,  1.45s/it]\u001b[A\n","Iteration:  31% 1008/3255 [24:21<54:10,  1.45s/it]\u001b[A\n","Iteration:  31% 1009/3255 [24:23<53:49,  1.44s/it]\u001b[A\n","Iteration:  31% 1010/3255 [24:24<53:35,  1.43s/it]\u001b[A\n","Iteration:  31% 1011/3255 [24:26<53:18,  1.43s/it]\u001b[A\n","Iteration:  31% 1012/3255 [24:27<53:23,  1.43s/it]\u001b[A\n","Iteration:  31% 1013/3255 [24:28<53:12,  1.42s/it]\u001b[A\n","Iteration:  31% 1014/3255 [24:30<53:09,  1.42s/it]\u001b[A\n","Iteration:  31% 1015/3255 [24:31<53:06,  1.42s/it]\u001b[A\n","Iteration:  31% 1016/3255 [24:33<52:57,  1.42s/it]\u001b[A\n","Iteration:  31% 1017/3255 [24:34<53:04,  1.42s/it]\u001b[A\n","Iteration:  31% 1018/3255 [24:36<52:53,  1.42s/it]\u001b[A\n","Iteration:  31% 1019/3255 [24:37<52:53,  1.42s/it]\u001b[A\n","Iteration:  31% 1020/3255 [24:38<52:53,  1.42s/it]\u001b[A\n","Iteration:  31% 1021/3255 [24:40<52:53,  1.42s/it]\u001b[A\n","Iteration:  31% 1022/3255 [24:41<52:50,  1.42s/it]\u001b[A\n","Iteration:  31% 1023/3255 [24:43<52:47,  1.42s/it]\u001b[A\n","Iteration:  31% 1024/3255 [24:44<52:50,  1.42s/it]\u001b[A\n","Iteration:  31% 1025/3255 [24:46<52:46,  1.42s/it]\u001b[A\n","Iteration:  32% 1026/3255 [24:47<52:53,  1.42s/it]\u001b[A\n","Iteration:  32% 1027/3255 [24:48<52:49,  1.42s/it]\u001b[A\n","Iteration:  32% 1028/3255 [24:50<52:39,  1.42s/it]\u001b[A\n","Iteration:  32% 1029/3255 [24:51<52:38,  1.42s/it]\u001b[A\n","Iteration:  32% 1030/3255 [24:53<52:33,  1.42s/it]\u001b[A\n","Iteration:  32% 1031/3255 [24:54<52:39,  1.42s/it]\u001b[A\n","Iteration:  32% 1032/3255 [24:55<52:40,  1.42s/it]\u001b[A\n","Iteration:  32% 1033/3255 [24:57<52:43,  1.42s/it]\u001b[A\n","Iteration:  32% 1034/3255 [24:58<52:33,  1.42s/it]\u001b[A\n","Iteration:  32% 1035/3255 [25:00<52:21,  1.42s/it]\u001b[A\n","Iteration:  32% 1036/3255 [25:01<52:28,  1.42s/it]\u001b[A\n","Iteration:  32% 1037/3255 [25:03<52:29,  1.42s/it]\u001b[A\n","Iteration:  32% 1038/3255 [25:04<52:34,  1.42s/it]\u001b[A\n","Iteration:  32% 1039/3255 [25:05<52:29,  1.42s/it]\u001b[A\n","Iteration:  32% 1040/3255 [25:07<52:31,  1.42s/it]\u001b[A\n","Iteration:  32% 1041/3255 [25:08<52:31,  1.42s/it]\u001b[A\n","Iteration:  32% 1042/3255 [25:10<52:21,  1.42s/it]\u001b[A\n","Iteration:  32% 1043/3255 [25:11<52:22,  1.42s/it]\u001b[A\n","Iteration:  32% 1044/3255 [25:13<52:21,  1.42s/it]\u001b[A\n","Iteration:  32% 1045/3255 [25:14<52:36,  1.43s/it]\u001b[A\n","Iteration:  32% 1046/3255 [25:15<52:25,  1.42s/it]\u001b[A\n","Iteration:  32% 1047/3255 [25:17<52:13,  1.42s/it]\u001b[A\n","Iteration:  32% 1048/3255 [25:18<52:12,  1.42s/it]\u001b[A\n","Iteration:  32% 1049/3255 [25:20<52:02,  1.42s/it]\u001b[A11/26/2019 19:10:54 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-1050/config.json\n","11/26/2019 19:10:55 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-1050/pytorch_model.bin\n","11/26/2019 19:10:55 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-1050\n","\n","Iteration:  32% 1050/3255 [25:23<1:08:37,  1.87s/it]\u001b[A\n","Iteration:  32% 1051/3255 [25:24<1:03:13,  1.72s/it]\u001b[A\n","Iteration:  32% 1052/3255 [25:25<59:46,  1.63s/it]  \u001b[A\n","Iteration:  32% 1053/3255 [25:27<57:27,  1.57s/it]\u001b[A\n","Iteration:  32% 1054/3255 [25:28<55:49,  1.52s/it]\u001b[A\n","Iteration:  32% 1055/3255 [25:30<54:37,  1.49s/it]\u001b[A\n","Iteration:  32% 1056/3255 [25:31<53:56,  1.47s/it]\u001b[A\n","Iteration:  32% 1057/3255 [25:32<53:28,  1.46s/it]\u001b[A\n","Iteration:  33% 1058/3255 [25:34<52:58,  1.45s/it]\u001b[A\n","Iteration:  33% 1059/3255 [25:35<52:42,  1.44s/it]\u001b[A\n","Iteration:  33% 1060/3255 [25:37<52:31,  1.44s/it]\u001b[A\n","Iteration:  33% 1061/3255 [25:38<52:15,  1.43s/it]\u001b[A\n","Iteration:  33% 1062/3255 [25:40<52:10,  1.43s/it]\u001b[A\n","Iteration:  33% 1063/3255 [25:41<52:18,  1.43s/it]\u001b[A\n","Iteration:  33% 1064/3255 [25:42<51:54,  1.42s/it]\u001b[A\n","Iteration:  33% 1065/3255 [25:44<51:50,  1.42s/it]\u001b[A\n","Iteration:  33% 1066/3255 [25:45<51:50,  1.42s/it]\u001b[A\n","Iteration:  33% 1067/3255 [25:47<51:39,  1.42s/it]\u001b[A\n","Iteration:  33% 1068/3255 [25:48<51:35,  1.42s/it]\u001b[A\n","Iteration:  33% 1069/3255 [25:49<51:41,  1.42s/it]\u001b[A\n","Iteration:  33% 1070/3255 [25:51<51:39,  1.42s/it]\u001b[A\n","Iteration:  33% 1071/3255 [25:52<51:43,  1.42s/it]\u001b[A\n","Iteration:  33% 1072/3255 [25:54<51:49,  1.42s/it]\u001b[A\n","Iteration:  33% 1073/3255 [25:55<51:35,  1.42s/it]\u001b[A\n","Iteration:  33% 1074/3255 [25:57<51:30,  1.42s/it]\u001b[A\n","Iteration:  33% 1075/3255 [25:58<51:30,  1.42s/it]\u001b[A\n","Iteration:  33% 1076/3255 [25:59<51:21,  1.41s/it]\u001b[A\n","Iteration:  33% 1077/3255 [26:01<51:23,  1.42s/it]\u001b[A\n","Iteration:  33% 1078/3255 [26:02<51:31,  1.42s/it]\u001b[A\n","Iteration:  33% 1079/3255 [26:04<51:24,  1.42s/it]\u001b[A\n","Iteration:  33% 1080/3255 [26:05<51:38,  1.42s/it]\u001b[A\n","Iteration:  33% 1081/3255 [26:07<51:29,  1.42s/it]\u001b[A\n","Iteration:  33% 1082/3255 [26:08<51:24,  1.42s/it]\u001b[A\n","Iteration:  33% 1083/3255 [26:09<51:21,  1.42s/it]\u001b[A\n","Iteration:  33% 1084/3255 [26:11<51:23,  1.42s/it]\u001b[A\n","Iteration:  33% 1085/3255 [26:12<51:16,  1.42s/it]\u001b[A\n","Iteration:  33% 1086/3255 [26:14<51:18,  1.42s/it]\u001b[A\n","Iteration:  33% 1087/3255 [26:15<51:27,  1.42s/it]\u001b[A\n","Iteration:  33% 1088/3255 [26:16<51:24,  1.42s/it]\u001b[A\n","Iteration:  33% 1089/3255 [26:18<51:24,  1.42s/it]\u001b[A\n","Iteration:  33% 1090/3255 [26:19<51:22,  1.42s/it]\u001b[A\n","Iteration:  34% 1091/3255 [26:21<51:13,  1.42s/it]\u001b[A\n","Iteration:  34% 1092/3255 [26:22<51:21,  1.42s/it]\u001b[A\n","Iteration:  34% 1093/3255 [26:24<51:11,  1.42s/it]\u001b[A\n","Iteration:  34% 1094/3255 [26:25<51:03,  1.42s/it]\u001b[A\n","Iteration:  34% 1095/3255 [26:26<51:05,  1.42s/it]\u001b[A\n","Iteration:  34% 1096/3255 [26:28<50:59,  1.42s/it]\u001b[A\n","Iteration:  34% 1097/3255 [26:29<50:57,  1.42s/it]\u001b[A\n","Iteration:  34% 1098/3255 [26:31<51:04,  1.42s/it]\u001b[A\n","Iteration:  34% 1099/3255 [26:32<51:10,  1.42s/it]\u001b[A11/26/2019 19:12:06 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-1100/config.json\n","11/26/2019 19:12:08 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-1100/pytorch_model.bin\n","11/26/2019 19:12:08 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-1100\n","\n","Iteration:  34% 1100/3255 [26:35<1:09:11,  1.93s/it]\u001b[A\n","Iteration:  34% 1101/3255 [26:37<1:03:03,  1.76s/it]\u001b[A\n","Iteration:  34% 1102/3255 [26:38<59:22,  1.65s/it]  \u001b[A\n","Iteration:  34% 1103/3255 [26:39<56:50,  1.58s/it]\u001b[A\n","Iteration:  34% 1104/3255 [26:41<54:56,  1.53s/it]\u001b[A\n","Iteration:  34% 1105/3255 [26:42<53:39,  1.50s/it]\u001b[A\n","Iteration:  34% 1106/3255 [26:44<52:46,  1.47s/it]\u001b[A\n","Iteration:  34% 1107/3255 [26:45<52:15,  1.46s/it]\u001b[A\n","Iteration:  34% 1108/3255 [26:46<51:53,  1.45s/it]\u001b[A\n","Iteration:  34% 1109/3255 [26:48<51:41,  1.45s/it]\u001b[A\n","Iteration:  34% 1110/3255 [26:49<51:22,  1.44s/it]\u001b[A\n","Iteration:  34% 1111/3255 [26:51<51:12,  1.43s/it]\u001b[A\n","Iteration:  34% 1112/3255 [26:52<51:08,  1.43s/it]\u001b[A\n","Iteration:  34% 1113/3255 [26:54<51:01,  1.43s/it]\u001b[A\n","Iteration:  34% 1114/3255 [26:55<50:43,  1.42s/it]\u001b[A\n","Iteration:  34% 1115/3255 [26:56<50:50,  1.43s/it]\u001b[A\n","Iteration:  34% 1116/3255 [26:58<50:41,  1.42s/it]\u001b[A\n","Iteration:  34% 1117/3255 [26:59<50:31,  1.42s/it]\u001b[A\n","Iteration:  34% 1118/3255 [27:01<50:35,  1.42s/it]\u001b[A\n","Iteration:  34% 1119/3255 [27:02<50:47,  1.43s/it]\u001b[A\n","Iteration:  34% 1120/3255 [27:04<50:41,  1.42s/it]\u001b[A\n","Iteration:  34% 1121/3255 [27:05<50:29,  1.42s/it]\u001b[A\n","Iteration:  34% 1122/3255 [27:06<50:36,  1.42s/it]\u001b[A\n","Iteration:  35% 1123/3255 [27:08<50:26,  1.42s/it]\u001b[A\n","Iteration:  35% 1124/3255 [27:09<50:19,  1.42s/it]\u001b[A\n","Iteration:  35% 1125/3255 [27:11<50:29,  1.42s/it]\u001b[A\n","Iteration:  35% 1126/3255 [27:12<50:28,  1.42s/it]\u001b[A\n","Iteration:  35% 1127/3255 [27:13<50:23,  1.42s/it]\u001b[A\n","Iteration:  35% 1128/3255 [27:15<50:28,  1.42s/it]\u001b[A\n","Iteration:  35% 1129/3255 [27:16<50:18,  1.42s/it]\u001b[A\n","Iteration:  35% 1130/3255 [27:18<50:09,  1.42s/it]\u001b[A\n","Iteration:  35% 1131/3255 [27:19<50:06,  1.42s/it]\u001b[A\n","Iteration:  35% 1132/3255 [27:21<50:09,  1.42s/it]\u001b[A\n","Iteration:  35% 1133/3255 [27:22<49:59,  1.41s/it]\u001b[A\n","Iteration:  35% 1134/3255 [27:23<50:06,  1.42s/it]\u001b[A\n","Iteration:  35% 1135/3255 [27:25<50:03,  1.42s/it]\u001b[A\n","Iteration:  35% 1136/3255 [27:26<50:05,  1.42s/it]\u001b[A\n","Iteration:  35% 1137/3255 [27:28<49:54,  1.41s/it]\u001b[A\n","Iteration:  35% 1138/3255 [27:29<49:54,  1.41s/it]\u001b[A\n","Iteration:  35% 1139/3255 [27:30<49:55,  1.42s/it]\u001b[A\n","Iteration:  35% 1140/3255 [27:32<49:59,  1.42s/it]\u001b[A\n","Iteration:  35% 1141/3255 [27:33<49:58,  1.42s/it]\u001b[A\n","Iteration:  35% 1142/3255 [27:35<49:51,  1.42s/it]\u001b[A\n","Iteration:  35% 1143/3255 [27:36<49:52,  1.42s/it]\u001b[A\n","Iteration:  35% 1144/3255 [27:38<49:45,  1.41s/it]\u001b[A\n","Iteration:  35% 1145/3255 [27:39<49:53,  1.42s/it]\u001b[A\n","Iteration:  35% 1146/3255 [27:40<49:50,  1.42s/it]\u001b[A\n","Iteration:  35% 1147/3255 [27:42<49:40,  1.41s/it]\u001b[A\n","Iteration:  35% 1148/3255 [27:43<49:45,  1.42s/it]\u001b[A\n","Iteration:  35% 1149/3255 [27:45<49:52,  1.42s/it]\u001b[A11/26/2019 19:13:19 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-1150/config.json\n","11/26/2019 19:13:20 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-1150/pytorch_model.bin\n","11/26/2019 19:13:20 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-1150\n","\n","Iteration:  35% 1150/3255 [27:48<1:06:07,  1.88s/it]\u001b[A\n","Iteration:  35% 1151/3255 [27:49<1:00:48,  1.73s/it]\u001b[A\n","Iteration:  35% 1152/3255 [27:50<57:21,  1.64s/it]  \u001b[A\n","Iteration:  35% 1153/3255 [27:52<55:03,  1.57s/it]\u001b[A\n","Iteration:  35% 1154/3255 [27:53<53:24,  1.53s/it]\u001b[A\n","Iteration:  35% 1155/3255 [27:55<52:05,  1.49s/it]\u001b[A\n","Iteration:  36% 1156/3255 [27:56<51:24,  1.47s/it]\u001b[A\n","Iteration:  36% 1157/3255 [27:57<50:44,  1.45s/it]\u001b[A\n","Iteration:  36% 1158/3255 [27:59<50:20,  1.44s/it]\u001b[A\n","Iteration:  36% 1159/3255 [28:00<50:04,  1.43s/it]\u001b[A\n","Iteration:  36% 1160/3255 [28:02<49:52,  1.43s/it]\u001b[A\n","Iteration:  36% 1161/3255 [28:03<49:35,  1.42s/it]\u001b[A\n","Iteration:  36% 1162/3255 [28:05<49:31,  1.42s/it]\u001b[A\n","Iteration:  36% 1163/3255 [28:06<49:44,  1.43s/it]\u001b[A\n","Iteration:  36% 1164/3255 [28:07<49:46,  1.43s/it]\u001b[A\n","Iteration:  36% 1165/3255 [28:09<49:39,  1.43s/it]\u001b[A\n","Iteration:  36% 1166/3255 [28:10<49:35,  1.42s/it]\u001b[A\n","Iteration:  36% 1167/3255 [28:12<49:24,  1.42s/it]\u001b[A\n","Iteration:  36% 1168/3255 [28:13<49:20,  1.42s/it]\u001b[A\n","Iteration:  36% 1169/3255 [28:15<49:28,  1.42s/it]\u001b[A\n","Iteration:  36% 1170/3255 [28:16<49:24,  1.42s/it]\u001b[A\n","Iteration:  36% 1171/3255 [28:17<49:21,  1.42s/it]\u001b[A\n","Iteration:  36% 1172/3255 [28:19<49:17,  1.42s/it]\u001b[A\n","Iteration:  36% 1173/3255 [28:20<49:14,  1.42s/it]\u001b[A\n","Iteration:  36% 1174/3255 [28:22<49:11,  1.42s/it]\u001b[A\n","Iteration:  36% 1175/3255 [28:23<49:14,  1.42s/it]\u001b[A\n","Iteration:  36% 1176/3255 [28:24<49:21,  1.42s/it]\u001b[A\n","Iteration:  36% 1177/3255 [28:26<49:20,  1.42s/it]\u001b[A\n","Iteration:  36% 1178/3255 [28:27<49:06,  1.42s/it]\u001b[A\n","Iteration:  36% 1179/3255 [28:29<49:10,  1.42s/it]\u001b[A\n","Iteration:  36% 1180/3255 [28:30<49:06,  1.42s/it]\u001b[A\n","Iteration:  36% 1181/3255 [28:32<48:53,  1.41s/it]\u001b[A\n","Iteration:  36% 1182/3255 [28:33<48:49,  1.41s/it]\u001b[A\n","Iteration:  36% 1183/3255 [28:34<48:53,  1.42s/it]\u001b[A\n","Iteration:  36% 1184/3255 [28:36<48:54,  1.42s/it]\u001b[A\n","Iteration:  36% 1185/3255 [28:37<48:53,  1.42s/it]\u001b[A\n","Iteration:  36% 1186/3255 [28:39<48:53,  1.42s/it]\u001b[A\n","Iteration:  36% 1187/3255 [28:40<48:52,  1.42s/it]\u001b[A\n","Iteration:  36% 1188/3255 [28:41<48:50,  1.42s/it]\u001b[A\n","Iteration:  37% 1189/3255 [28:43<48:49,  1.42s/it]\u001b[A\n","Iteration:  37% 1190/3255 [28:44<48:44,  1.42s/it]\u001b[A\n","Iteration:  37% 1191/3255 [28:46<48:40,  1.41s/it]\u001b[A\n","Iteration:  37% 1192/3255 [28:47<48:35,  1.41s/it]\u001b[A\n","Iteration:  37% 1193/3255 [28:49<48:33,  1.41s/it]\u001b[A\n","Iteration:  37% 1194/3255 [28:50<48:36,  1.42s/it]\u001b[A\n","Iteration:  37% 1195/3255 [28:51<48:53,  1.42s/it]\u001b[A\n","Iteration:  37% 1196/3255 [28:53<48:42,  1.42s/it]\u001b[A\n","Iteration:  37% 1197/3255 [28:54<48:43,  1.42s/it]\u001b[A\n","Iteration:  37% 1198/3255 [28:56<48:30,  1.41s/it]\u001b[A\n","Iteration:  37% 1199/3255 [28:57<48:33,  1.42s/it]\u001b[A11/26/2019 19:14:31 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-1200/config.json\n","11/26/2019 19:14:33 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-1200/pytorch_model.bin\n","11/26/2019 19:14:33 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-1200\n","\n","Iteration:  37% 1200/3255 [29:00<1:04:18,  1.88s/it]\u001b[A\n","Iteration:  37% 1201/3255 [29:01<58:56,  1.72s/it]  \u001b[A\n","Iteration:  37% 1202/3255 [29:03<55:53,  1.63s/it]\u001b[A\n","Iteration:  37% 1203/3255 [29:04<53:34,  1.57s/it]\u001b[A\n","Iteration:  37% 1204/3255 [29:06<52:05,  1.52s/it]\u001b[A\n","Iteration:  37% 1205/3255 [29:07<51:10,  1.50s/it]\u001b[A\n","Iteration:  37% 1206/3255 [29:08<50:15,  1.47s/it]\u001b[A\n","Iteration:  37% 1207/3255 [29:10<49:33,  1.45s/it]\u001b[A\n","Iteration:  37% 1208/3255 [29:11<49:22,  1.45s/it]\u001b[A\n","Iteration:  37% 1209/3255 [29:13<49:02,  1.44s/it]\u001b[A\n","Iteration:  37% 1210/3255 [29:14<48:46,  1.43s/it]\u001b[A\n","Iteration:  37% 1211/3255 [29:16<48:35,  1.43s/it]\u001b[A\n","Iteration:  37% 1212/3255 [29:17<48:32,  1.43s/it]\u001b[A\n","Iteration:  37% 1213/3255 [29:18<48:16,  1.42s/it]\u001b[A\n","Iteration:  37% 1214/3255 [29:20<48:20,  1.42s/it]\u001b[A\n","Iteration:  37% 1215/3255 [29:21<48:15,  1.42s/it]\u001b[A\n","Iteration:  37% 1216/3255 [29:23<48:18,  1.42s/it]\u001b[A\n","Iteration:  37% 1217/3255 [29:24<48:21,  1.42s/it]\u001b[A\n","Iteration:  37% 1218/3255 [29:26<48:14,  1.42s/it]\u001b[A\n","Iteration:  37% 1219/3255 [29:27<48:17,  1.42s/it]\u001b[A\n","Iteration:  37% 1220/3255 [29:28<48:25,  1.43s/it]\u001b[A\n","Iteration:  38% 1221/3255 [29:30<48:09,  1.42s/it]\u001b[A\n","Iteration:  38% 1222/3255 [29:31<48:08,  1.42s/it]\u001b[A\n","Iteration:  38% 1223/3255 [29:33<48:01,  1.42s/it]\u001b[A\n","Iteration:  38% 1224/3255 [29:34<48:08,  1.42s/it]\u001b[A\n","Iteration:  38% 1225/3255 [29:35<48:00,  1.42s/it]\u001b[A\n","Iteration:  38% 1226/3255 [29:37<47:58,  1.42s/it]\u001b[A\n","Iteration:  38% 1227/3255 [29:38<48:05,  1.42s/it]\u001b[A\n","Iteration:  38% 1228/3255 [29:40<48:01,  1.42s/it]\u001b[A\n","Iteration:  38% 1229/3255 [29:41<48:08,  1.43s/it]\u001b[A\n","Iteration:  38% 1230/3255 [29:43<48:03,  1.42s/it]\u001b[A\n","Iteration:  38% 1231/3255 [29:44<47:52,  1.42s/it]\u001b[A\n","Iteration:  38% 1232/3255 [29:45<48:01,  1.42s/it]\u001b[A\n","Iteration:  38% 1233/3255 [29:47<48:10,  1.43s/it]\u001b[A\n","Iteration:  38% 1234/3255 [29:48<48:02,  1.43s/it]\u001b[A\n","Iteration:  38% 1235/3255 [29:50<47:48,  1.42s/it]\u001b[A\n","Iteration:  38% 1236/3255 [29:51<47:56,  1.42s/it]\u001b[A\n","Iteration:  38% 1237/3255 [29:53<47:43,  1.42s/it]\u001b[A\n","Iteration:  38% 1238/3255 [29:54<47:41,  1.42s/it]\u001b[A\n","Iteration:  38% 1239/3255 [29:55<47:42,  1.42s/it]\u001b[A\n","Iteration:  38% 1240/3255 [29:57<47:45,  1.42s/it]\u001b[A\n","Iteration:  38% 1241/3255 [29:58<47:44,  1.42s/it]\u001b[A\n","Iteration:  38% 1242/3255 [30:00<47:33,  1.42s/it]\u001b[A\n","Iteration:  38% 1243/3255 [30:01<47:36,  1.42s/it]\u001b[A\n","Iteration:  38% 1244/3255 [30:02<47:39,  1.42s/it]\u001b[A\n","Iteration:  38% 1245/3255 [30:04<47:41,  1.42s/it]\u001b[A\n","Iteration:  38% 1246/3255 [30:05<47:44,  1.43s/it]\u001b[A\n","Iteration:  38% 1247/3255 [30:07<47:33,  1.42s/it]\u001b[A\n","Iteration:  38% 1248/3255 [30:08<47:33,  1.42s/it]\u001b[A\n","Iteration:  38% 1249/3255 [30:10<47:33,  1.42s/it]\u001b[A11/26/2019 19:15:44 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-1250/config.json\n","11/26/2019 19:15:45 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-1250/pytorch_model.bin\n","11/26/2019 19:15:45 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-1250\n","\n","Iteration:  38% 1250/3255 [30:13<1:02:27,  1.87s/it]\u001b[A\n","Iteration:  38% 1251/3255 [30:14<57:30,  1.72s/it]  \u001b[A\n","Iteration:  38% 1252/3255 [30:15<54:20,  1.63s/it]\u001b[A\n","Iteration:  38% 1253/3255 [30:17<52:05,  1.56s/it]\u001b[A\n","Iteration:  39% 1254/3255 [30:18<50:45,  1.52s/it]\u001b[A\n","Iteration:  39% 1255/3255 [30:20<49:37,  1.49s/it]\u001b[A\n","Iteration:  39% 1256/3255 [30:21<48:57,  1.47s/it]\u001b[A\n","Iteration:  39% 1257/3255 [30:22<48:22,  1.45s/it]\u001b[A\n","Iteration:  39% 1258/3255 [30:24<48:06,  1.45s/it]\u001b[A\n","Iteration:  39% 1259/3255 [30:25<47:51,  1.44s/it]\u001b[A\n","Iteration:  39% 1260/3255 [30:27<47:51,  1.44s/it]\u001b[A\n","Iteration:  39% 1261/3255 [30:28<47:31,  1.43s/it]\u001b[A\n","Iteration:  39% 1262/3255 [30:30<47:25,  1.43s/it]\u001b[A\n","Iteration:  39% 1263/3255 [30:31<47:17,  1.42s/it]\u001b[A\n","Iteration:  39% 1264/3255 [30:32<47:15,  1.42s/it]\u001b[A\n","Iteration:  39% 1265/3255 [30:34<47:06,  1.42s/it]\u001b[A\n","Iteration:  39% 1266/3255 [30:35<47:16,  1.43s/it]\u001b[A\n","Iteration:  39% 1267/3255 [30:37<46:58,  1.42s/it]\u001b[A\n","Iteration:  39% 1268/3255 [30:38<47:06,  1.42s/it]\u001b[A\n","Iteration:  39% 1269/3255 [30:39<47:05,  1.42s/it]\u001b[A\n","Iteration:  39% 1270/3255 [30:41<46:55,  1.42s/it]\u001b[A\n","Iteration:  39% 1271/3255 [30:42<46:57,  1.42s/it]\u001b[A\n","Iteration:  39% 1272/3255 [30:44<46:56,  1.42s/it]\u001b[A\n","Iteration:  39% 1273/3255 [30:45<46:53,  1.42s/it]\u001b[A\n","Iteration:  39% 1274/3255 [30:47<46:55,  1.42s/it]\u001b[A\n","Iteration:  39% 1275/3255 [30:48<46:52,  1.42s/it]\u001b[A\n","Iteration:  39% 1276/3255 [30:49<46:51,  1.42s/it]\u001b[A\n","Iteration:  39% 1277/3255 [30:51<46:42,  1.42s/it]\u001b[A\n","Iteration:  39% 1278/3255 [30:52<46:52,  1.42s/it]\u001b[A\n","Iteration:  39% 1279/3255 [30:54<46:49,  1.42s/it]\u001b[A\n","Iteration:  39% 1280/3255 [30:55<46:57,  1.43s/it]\u001b[A\n","Iteration:  39% 1281/3255 [30:57<46:50,  1.42s/it]\u001b[A\n","Iteration:  39% 1282/3255 [30:58<46:47,  1.42s/it]\u001b[A\n","Iteration:  39% 1283/3255 [30:59<46:39,  1.42s/it]\u001b[A\n","Iteration:  39% 1284/3255 [31:01<46:44,  1.42s/it]\u001b[A\n","Iteration:  39% 1285/3255 [31:02<46:33,  1.42s/it]\u001b[A\n","Iteration:  40% 1286/3255 [31:04<46:33,  1.42s/it]\u001b[A\n","Iteration:  40% 1287/3255 [31:05<46:41,  1.42s/it]\u001b[A\n","Iteration:  40% 1288/3255 [31:06<46:42,  1.42s/it]\u001b[A\n","Iteration:  40% 1289/3255 [31:08<46:38,  1.42s/it]\u001b[A\n","Iteration:  40% 1290/3255 [31:09<46:36,  1.42s/it]\u001b[A\n","Iteration:  40% 1291/3255 [31:11<46:44,  1.43s/it]\u001b[A\n","Iteration:  40% 1292/3255 [31:12<46:45,  1.43s/it]\u001b[A\n","Iteration:  40% 1293/3255 [31:14<46:25,  1.42s/it]\u001b[A\n","Iteration:  40% 1294/3255 [31:15<46:22,  1.42s/it]\u001b[A\n","Iteration:  40% 1295/3255 [31:16<46:26,  1.42s/it]\u001b[A\n","Iteration:  40% 1296/3255 [31:18<46:16,  1.42s/it]\u001b[A\n","Iteration:  40% 1297/3255 [31:19<46:26,  1.42s/it]\u001b[A\n","Iteration:  40% 1298/3255 [31:21<46:19,  1.42s/it]\u001b[A\n","Iteration:  40% 1299/3255 [31:22<46:14,  1.42s/it]\u001b[A11/26/2019 19:16:56 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-1300/config.json\n","11/26/2019 19:16:58 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-1300/pytorch_model.bin\n","11/26/2019 19:16:58 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-1300\n","\n","Iteration:  40% 1300/3255 [31:25<1:00:04,  1.84s/it]\u001b[A\n","Iteration:  40% 1301/3255 [31:26<55:33,  1.71s/it]  \u001b[A\n","Iteration:  40% 1302/3255 [31:28<52:48,  1.62s/it]\u001b[A\n","Iteration:  40% 1303/3255 [31:29<50:47,  1.56s/it]\u001b[A\n","Iteration:  40% 1304/3255 [31:31<49:19,  1.52s/it]\u001b[A\n","Iteration:  40% 1305/3255 [31:32<48:23,  1.49s/it]\u001b[A\n","Iteration:  40% 1306/3255 [31:33<47:47,  1.47s/it]\u001b[A\n","Iteration:  40% 1307/3255 [31:35<47:12,  1.45s/it]\u001b[A\n","Iteration:  40% 1308/3255 [31:36<46:57,  1.45s/it]\u001b[A\n","Iteration:  40% 1309/3255 [31:38<46:36,  1.44s/it]\u001b[A\n","Iteration:  40% 1310/3255 [31:39<46:29,  1.43s/it]\u001b[A\n","Iteration:  40% 1311/3255 [31:41<46:21,  1.43s/it]\u001b[A\n","Iteration:  40% 1312/3255 [31:42<46:14,  1.43s/it]\u001b[A\n","Iteration:  40% 1313/3255 [31:43<46:10,  1.43s/it]\u001b[A\n","Iteration:  40% 1314/3255 [31:45<46:04,  1.42s/it]\u001b[A\n","Iteration:  40% 1315/3255 [31:46<45:52,  1.42s/it]\u001b[A\n","Iteration:  40% 1316/3255 [31:48<45:51,  1.42s/it]\u001b[A\n","Iteration:  40% 1317/3255 [31:49<45:50,  1.42s/it]\u001b[A\n","Iteration:  40% 1318/3255 [31:50<45:46,  1.42s/it]\u001b[A\n","Iteration:  41% 1319/3255 [31:52<45:43,  1.42s/it]\u001b[A\n","Iteration:  41% 1320/3255 [31:53<45:39,  1.42s/it]\u001b[A\n","Iteration:  41% 1321/3255 [31:55<45:36,  1.41s/it]\u001b[A\n","Iteration:  41% 1322/3255 [31:56<45:41,  1.42s/it]\u001b[A\n","Iteration:  41% 1323/3255 [31:58<45:34,  1.42s/it]\u001b[A\n","Iteration:  41% 1324/3255 [31:59<45:31,  1.41s/it]\u001b[A\n","Iteration:  41% 1325/3255 [32:00<45:36,  1.42s/it]\u001b[A\n","Iteration:  41% 1326/3255 [32:02<45:36,  1.42s/it]\u001b[A\n","Iteration:  41% 1327/3255 [32:03<45:34,  1.42s/it]\u001b[A\n","Iteration:  41% 1328/3255 [32:05<45:34,  1.42s/it]\u001b[A\n","Iteration:  41% 1329/3255 [32:06<45:37,  1.42s/it]\u001b[A\n","Iteration:  41% 1330/3255 [32:07<45:39,  1.42s/it]\u001b[A\n","Iteration:  41% 1331/3255 [32:09<45:42,  1.43s/it]\u001b[A\n","Iteration:  41% 1332/3255 [32:10<45:37,  1.42s/it]\u001b[A\n","Iteration:  41% 1333/3255 [32:12<45:39,  1.43s/it]\u001b[A\n","Iteration:  41% 1334/3255 [32:13<45:28,  1.42s/it]\u001b[A\n","Iteration:  41% 1335/3255 [32:15<45:27,  1.42s/it]\u001b[A\n","Iteration:  41% 1336/3255 [32:16<45:20,  1.42s/it]\u001b[A\n","Iteration:  41% 1337/3255 [32:17<45:25,  1.42s/it]\u001b[A\n","Iteration:  41% 1338/3255 [32:19<45:31,  1.42s/it]\u001b[A\n","Iteration:  41% 1339/3255 [32:20<45:23,  1.42s/it]\u001b[A\n","Iteration:  41% 1340/3255 [32:22<45:24,  1.42s/it]\u001b[A\n","Iteration:  41% 1341/3255 [32:23<45:21,  1.42s/it]\u001b[A\n","Iteration:  41% 1342/3255 [32:25<45:16,  1.42s/it]\u001b[A\n","Iteration:  41% 1343/3255 [32:26<45:26,  1.43s/it]\u001b[A\n","Iteration:  41% 1344/3255 [32:27<45:28,  1.43s/it]\u001b[A\n","Iteration:  41% 1345/3255 [32:29<45:15,  1.42s/it]\u001b[A\n","Iteration:  41% 1346/3255 [32:30<45:10,  1.42s/it]\u001b[A\n","Iteration:  41% 1347/3255 [32:32<45:09,  1.42s/it]\u001b[A\n","Iteration:  41% 1348/3255 [32:33<45:08,  1.42s/it]\u001b[A\n","Iteration:  41% 1349/3255 [32:35<45:08,  1.42s/it]\u001b[A11/26/2019 19:18:09 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-1350/config.json\n","11/26/2019 19:18:10 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-1350/pytorch_model.bin\n","11/26/2019 19:18:10 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-1350\n","\n","Iteration:  41% 1350/3255 [32:37<58:54,  1.86s/it]\u001b[A\n","Iteration:  42% 1351/3255 [32:39<54:10,  1.71s/it]\u001b[A\n","Iteration:  42% 1352/3255 [32:40<51:36,  1.63s/it]\u001b[A\n","Iteration:  42% 1353/3255 [32:42<49:30,  1.56s/it]\u001b[A\n","Iteration:  42% 1354/3255 [32:43<48:04,  1.52s/it]\u001b[A\n","Iteration:  42% 1355/3255 [32:44<47:06,  1.49s/it]\u001b[A\n","Iteration:  42% 1356/3255 [32:46<46:25,  1.47s/it]\u001b[A\n","Iteration:  42% 1357/3255 [32:47<45:54,  1.45s/it]\u001b[A\n","Iteration:  42% 1358/3255 [32:49<45:42,  1.45s/it]\u001b[A\n","Iteration:  42% 1359/3255 [32:50<45:30,  1.44s/it]\u001b[A\n","Iteration:  42% 1360/3255 [32:52<45:09,  1.43s/it]\u001b[A\n","Iteration:  42% 1361/3255 [32:53<44:56,  1.42s/it]\u001b[A\n","Iteration:  42% 1362/3255 [32:54<44:51,  1.42s/it]\u001b[A\n","Iteration:  42% 1363/3255 [32:56<44:44,  1.42s/it]\u001b[A\n","Iteration:  42% 1364/3255 [32:57<44:42,  1.42s/it]\u001b[A\n","Iteration:  42% 1365/3255 [32:59<44:43,  1.42s/it]\u001b[A\n","Iteration:  42% 1366/3255 [33:00<44:45,  1.42s/it]\u001b[A\n","Iteration:  42% 1367/3255 [33:01<44:42,  1.42s/it]\u001b[A\n","Iteration:  42% 1368/3255 [33:03<44:39,  1.42s/it]\u001b[A\n","Iteration:  42% 1369/3255 [33:04<44:39,  1.42s/it]\u001b[A\n","Iteration:  42% 1370/3255 [33:06<44:34,  1.42s/it]\u001b[A\n","Iteration:  42% 1371/3255 [33:07<44:29,  1.42s/it]\u001b[A\n","Iteration:  42% 1372/3255 [33:09<44:28,  1.42s/it]\u001b[A\n","Iteration:  42% 1373/3255 [33:10<44:28,  1.42s/it]\u001b[A\n","Iteration:  42% 1374/3255 [33:11<44:30,  1.42s/it]\u001b[A\n","Iteration:  42% 1375/3255 [33:13<44:27,  1.42s/it]\u001b[A\n","Iteration:  42% 1376/3255 [33:14<44:38,  1.43s/it]\u001b[A\n","Iteration:  42% 1377/3255 [33:16<44:31,  1.42s/it]\u001b[A\n","Iteration:  42% 1378/3255 [33:17<44:35,  1.43s/it]\u001b[A\n","Iteration:  42% 1379/3255 [33:19<44:33,  1.43s/it]\u001b[A\n","Iteration:  42% 1380/3255 [33:20<44:39,  1.43s/it]\u001b[A\n","Iteration:  42% 1381/3255 [33:21<44:22,  1.42s/it]\u001b[A\n","Iteration:  42% 1382/3255 [33:23<44:22,  1.42s/it]\u001b[A\n","Iteration:  42% 1383/3255 [33:24<44:15,  1.42s/it]\u001b[A\n","Iteration:  43% 1384/3255 [33:26<44:04,  1.41s/it]\u001b[A\n","Iteration:  43% 1385/3255 [33:27<44:12,  1.42s/it]\u001b[A\n","Iteration:  43% 1386/3255 [33:28<44:08,  1.42s/it]\u001b[A\n","Iteration:  43% 1387/3255 [33:30<44:07,  1.42s/it]\u001b[A\n","Iteration:  43% 1388/3255 [33:31<44:20,  1.42s/it]\u001b[A\n","Iteration:  43% 1389/3255 [33:33<44:06,  1.42s/it]\u001b[A\n","Iteration:  43% 1390/3255 [33:34<44:09,  1.42s/it]\u001b[A\n","Iteration:  43% 1391/3255 [33:36<44:03,  1.42s/it]\u001b[A\n","Iteration:  43% 1392/3255 [33:37<44:06,  1.42s/it]\u001b[A\n","Iteration:  43% 1393/3255 [33:38<44:00,  1.42s/it]\u001b[A\n","Iteration:  43% 1394/3255 [33:40<43:55,  1.42s/it]\u001b[A\n","Iteration:  43% 1395/3255 [33:41<43:53,  1.42s/it]\u001b[A\n","Iteration:  43% 1396/3255 [33:43<43:51,  1.42s/it]\u001b[A\n","Iteration:  43% 1397/3255 [33:44<43:54,  1.42s/it]\u001b[A\n","Iteration:  43% 1398/3255 [33:45<44:01,  1.42s/it]\u001b[A\n","Iteration:  43% 1399/3255 [33:47<43:51,  1.42s/it]\u001b[A11/26/2019 19:19:21 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-1400/config.json\n","11/26/2019 19:19:23 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-1400/pytorch_model.bin\n","11/26/2019 19:19:23 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-1400\n","\n","Iteration:  43% 1400/3255 [33:50<58:01,  1.88s/it]\u001b[A\n","Iteration:  43% 1401/3255 [33:51<53:24,  1.73s/it]\u001b[A\n","Iteration:  43% 1402/3255 [33:53<50:31,  1.64s/it]\u001b[A\n","Iteration:  43% 1403/3255 [33:54<48:33,  1.57s/it]\u001b[A\n","Iteration:  43% 1404/3255 [33:55<47:10,  1.53s/it]\u001b[A\n","Iteration:  43% 1405/3255 [33:57<46:10,  1.50s/it]\u001b[A\n","Iteration:  43% 1406/3255 [33:58<45:24,  1.47s/it]\u001b[A\n","Iteration:  43% 1407/3255 [34:00<44:52,  1.46s/it]\u001b[A\n","Iteration:  43% 1408/3255 [34:01<44:28,  1.44s/it]\u001b[A\n","Iteration:  43% 1409/3255 [34:03<44:17,  1.44s/it]\u001b[A\n","Iteration:  43% 1410/3255 [34:04<44:09,  1.44s/it]\u001b[A\n","Iteration:  43% 1411/3255 [34:05<43:56,  1.43s/it]\u001b[A\n","Iteration:  43% 1412/3255 [34:07<43:58,  1.43s/it]\u001b[A\n","Iteration:  43% 1413/3255 [34:08<43:50,  1.43s/it]\u001b[A\n","Iteration:  43% 1414/3255 [34:10<43:40,  1.42s/it]\u001b[A\n","Iteration:  43% 1415/3255 [34:11<43:31,  1.42s/it]\u001b[A\n","Iteration:  44% 1416/3255 [34:13<43:36,  1.42s/it]\u001b[A\n","Iteration:  44% 1417/3255 [34:14<43:31,  1.42s/it]\u001b[A\n","Iteration:  44% 1418/3255 [34:15<43:30,  1.42s/it]\u001b[A\n","Iteration:  44% 1419/3255 [34:17<43:25,  1.42s/it]\u001b[A\n","Iteration:  44% 1420/3255 [34:18<43:27,  1.42s/it]\u001b[A\n","Iteration:  44% 1421/3255 [34:20<43:25,  1.42s/it]\u001b[A\n","Iteration:  44% 1422/3255 [34:21<43:23,  1.42s/it]\u001b[A\n","Iteration:  44% 1423/3255 [34:22<43:18,  1.42s/it]\u001b[A\n","Iteration:  44% 1424/3255 [34:24<43:24,  1.42s/it]\u001b[A\n","Iteration:  44% 1425/3255 [34:25<43:22,  1.42s/it]\u001b[A\n","Iteration:  44% 1426/3255 [34:27<43:22,  1.42s/it]\u001b[A\n","Iteration:  44% 1427/3255 [34:28<43:22,  1.42s/it]\u001b[A\n","Iteration:  44% 1428/3255 [34:30<43:17,  1.42s/it]\u001b[A\n","Iteration:  44% 1429/3255 [34:31<43:20,  1.42s/it]\u001b[A\n","Iteration:  44% 1430/3255 [34:32<43:12,  1.42s/it]\u001b[A\n","Iteration:  44% 1431/3255 [34:34<43:14,  1.42s/it]\u001b[A\n","Iteration:  44% 1432/3255 [34:35<43:17,  1.42s/it]\u001b[A\n","Iteration:  44% 1433/3255 [34:37<43:04,  1.42s/it]\u001b[A\n","Iteration:  44% 1434/3255 [34:38<43:08,  1.42s/it]\u001b[A\n","Iteration:  44% 1435/3255 [34:40<42:57,  1.42s/it]\u001b[A\n","Iteration:  44% 1436/3255 [34:41<43:02,  1.42s/it]\u001b[A\n","Iteration:  44% 1437/3255 [34:42<43:02,  1.42s/it]\u001b[A\n","Iteration:  44% 1438/3255 [34:44<43:01,  1.42s/it]\u001b[A\n","Iteration:  44% 1439/3255 [34:45<43:01,  1.42s/it]\u001b[A\n","Iteration:  44% 1440/3255 [34:47<43:14,  1.43s/it]\u001b[A\n","Iteration:  44% 1441/3255 [34:48<43:00,  1.42s/it]\u001b[A\n","Iteration:  44% 1442/3255 [34:49<42:51,  1.42s/it]\u001b[A\n","Iteration:  44% 1443/3255 [34:51<42:57,  1.42s/it]\u001b[A\n","Iteration:  44% 1444/3255 [34:52<42:54,  1.42s/it]\u001b[A\n","Iteration:  44% 1445/3255 [34:54<42:48,  1.42s/it]\u001b[A\n","Iteration:  44% 1446/3255 [34:55<42:55,  1.42s/it]\u001b[A\n","Iteration:  44% 1447/3255 [34:57<42:47,  1.42s/it]\u001b[A\n","Iteration:  44% 1448/3255 [34:58<42:40,  1.42s/it]\u001b[A\n","Iteration:  45% 1449/3255 [34:59<42:42,  1.42s/it]\u001b[A11/26/2019 19:20:34 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-1450/config.json\n","11/26/2019 19:20:35 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-1450/pytorch_model.bin\n","11/26/2019 19:20:35 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-1450\n","\n","Iteration:  45% 1450/3255 [35:02<56:28,  1.88s/it]\u001b[A\n","Iteration:  45% 1451/3255 [35:04<51:52,  1.73s/it]\u001b[A\n","Iteration:  45% 1452/3255 [35:05<49:05,  1.63s/it]\u001b[A\n","Iteration:  45% 1453/3255 [35:07<47:09,  1.57s/it]\u001b[A\n","Iteration:  45% 1454/3255 [35:08<45:56,  1.53s/it]\u001b[A\n","Iteration:  45% 1455/3255 [35:09<45:00,  1.50s/it]\u001b[A\n","Iteration:  45% 1456/3255 [35:11<44:14,  1.48s/it]\u001b[A\n","Iteration:  45% 1457/3255 [35:12<43:36,  1.46s/it]\u001b[A\n","Iteration:  45% 1458/3255 [35:14<43:10,  1.44s/it]\u001b[A\n","Iteration:  45% 1459/3255 [35:15<42:56,  1.43s/it]\u001b[A\n","Iteration:  45% 1460/3255 [35:17<42:52,  1.43s/it]\u001b[A\n","Iteration:  45% 1461/3255 [35:18<42:42,  1.43s/it]\u001b[A\n","Iteration:  45% 1462/3255 [35:19<42:45,  1.43s/it]\u001b[A\n","Iteration:  45% 1463/3255 [35:21<42:30,  1.42s/it]\u001b[A\n","Iteration:  45% 1464/3255 [35:22<42:28,  1.42s/it]\u001b[A\n","Iteration:  45% 1465/3255 [35:24<42:24,  1.42s/it]\u001b[A\n","Iteration:  45% 1466/3255 [35:25<42:26,  1.42s/it]\u001b[A\n","Iteration:  45% 1467/3255 [35:26<42:23,  1.42s/it]\u001b[A\n","Iteration:  45% 1468/3255 [35:28<42:19,  1.42s/it]\u001b[A\n","Iteration:  45% 1469/3255 [35:29<42:17,  1.42s/it]\u001b[A\n","Iteration:  45% 1470/3255 [35:31<42:21,  1.42s/it]\u001b[A\n","Iteration:  45% 1471/3255 [35:32<42:16,  1.42s/it]\u001b[A\n","Iteration:  45% 1472/3255 [35:34<42:14,  1.42s/it]\u001b[A\n","Iteration:  45% 1473/3255 [35:35<42:19,  1.43s/it]\u001b[A\n","Iteration:  45% 1474/3255 [35:36<42:22,  1.43s/it]\u001b[A\n","Iteration:  45% 1475/3255 [35:38<42:05,  1.42s/it]\u001b[A\n","Iteration:  45% 1476/3255 [35:39<42:08,  1.42s/it]\u001b[A\n","Iteration:  45% 1477/3255 [35:41<41:58,  1.42s/it]\u001b[A\n","Iteration:  45% 1478/3255 [35:42<41:59,  1.42s/it]\u001b[A\n","Iteration:  45% 1479/3255 [35:44<41:57,  1.42s/it]\u001b[A\n","Iteration:  45% 1480/3255 [35:45<42:05,  1.42s/it]\u001b[A\n","Iteration:  45% 1481/3255 [35:46<42:01,  1.42s/it]\u001b[A\n","Iteration:  46% 1482/3255 [35:48<41:54,  1.42s/it]\u001b[A\n","Iteration:  46% 1483/3255 [35:49<42:07,  1.43s/it]\u001b[A\n","Iteration:  46% 1484/3255 [35:51<42:00,  1.42s/it]\u001b[A\n","Iteration:  46% 1485/3255 [35:52<41:55,  1.42s/it]\u001b[A\n","Iteration:  46% 1486/3255 [35:53<42:00,  1.42s/it]\u001b[A\n","Iteration:  46% 1487/3255 [35:55<42:00,  1.43s/it]\u001b[A\n","Iteration:  46% 1488/3255 [35:56<41:47,  1.42s/it]\u001b[A\n","Iteration:  46% 1489/3255 [35:58<41:45,  1.42s/it]\u001b[A\n","Iteration:  46% 1490/3255 [35:59<41:39,  1.42s/it]\u001b[A\n","Iteration:  46% 1491/3255 [36:01<41:37,  1.42s/it]\u001b[A\n","Iteration:  46% 1492/3255 [36:02<41:44,  1.42s/it]\u001b[A\n","Iteration:  46% 1493/3255 [36:03<41:35,  1.42s/it]\u001b[A\n","Iteration:  46% 1494/3255 [36:05<41:38,  1.42s/it]\u001b[A\n","Iteration:  46% 1495/3255 [36:06<41:45,  1.42s/it]\u001b[A\n","Iteration:  46% 1496/3255 [36:08<41:38,  1.42s/it]\u001b[A\n","Iteration:  46% 1497/3255 [36:09<41:39,  1.42s/it]\u001b[A\n","Iteration:  46% 1498/3255 [36:11<41:34,  1.42s/it]\u001b[A\n","Iteration:  46% 1499/3255 [36:12<41:27,  1.42s/it]\u001b[A11/26/2019 19:21:46 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-1500/config.json\n","11/26/2019 19:21:48 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-1500/pytorch_model.bin\n","11/26/2019 19:21:48 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-1500\n","\n","Iteration:  46% 1500/3255 [36:15<54:28,  1.86s/it]\u001b[A\n","Iteration:  46% 1501/3255 [36:16<50:10,  1.72s/it]\u001b[A\n","Iteration:  46% 1502/3255 [36:18<47:38,  1.63s/it]\u001b[A\n","Iteration:  46% 1503/3255 [36:19<45:48,  1.57s/it]\u001b[A\n","Iteration:  46% 1504/3255 [36:20<44:32,  1.53s/it]\u001b[A\n","Iteration:  46% 1505/3255 [36:22<43:38,  1.50s/it]\u001b[A\n","Iteration:  46% 1506/3255 [36:23<43:01,  1.48s/it]\u001b[A\n","Iteration:  46% 1507/3255 [36:25<42:36,  1.46s/it]\u001b[A\n","Iteration:  46% 1508/3255 [36:26<42:17,  1.45s/it]\u001b[A\n","Iteration:  46% 1509/3255 [36:28<42:00,  1.44s/it]\u001b[A\n","Iteration:  46% 1510/3255 [36:29<41:48,  1.44s/it]\u001b[A\n","Iteration:  46% 1511/3255 [36:30<41:36,  1.43s/it]\u001b[A\n","Iteration:  46% 1512/3255 [36:32<41:29,  1.43s/it]\u001b[A\n","Iteration:  46% 1513/3255 [36:33<41:21,  1.42s/it]\u001b[A\n","Iteration:  47% 1514/3255 [36:35<41:12,  1.42s/it]\u001b[A\n","Iteration:  47% 1515/3255 [36:36<41:06,  1.42s/it]\u001b[A\n","Iteration:  47% 1516/3255 [36:38<41:09,  1.42s/it]\u001b[A\n","Iteration:  47% 1517/3255 [36:39<41:13,  1.42s/it]\u001b[A\n","Iteration:  47% 1518/3255 [36:40<41:04,  1.42s/it]\u001b[A\n","Iteration:  47% 1519/3255 [36:42<41:07,  1.42s/it]\u001b[A\n","Iteration:  47% 1520/3255 [36:43<41:10,  1.42s/it]\u001b[A\n","Iteration:  47% 1521/3255 [36:45<41:05,  1.42s/it]\u001b[A\n","Iteration:  47% 1522/3255 [36:46<41:01,  1.42s/it]\u001b[A\n","Iteration:  47% 1523/3255 [36:48<41:00,  1.42s/it]\u001b[A\n","Iteration:  47% 1524/3255 [36:49<41:01,  1.42s/it]\u001b[A\n","Iteration:  47% 1525/3255 [36:50<41:03,  1.42s/it]\u001b[A\n","Iteration:  47% 1526/3255 [36:52<41:01,  1.42s/it]\u001b[A\n","Iteration:  47% 1527/3255 [36:53<40:56,  1.42s/it]\u001b[A\n","Iteration:  47% 1528/3255 [36:55<40:52,  1.42s/it]\u001b[A\n","Iteration:  47% 1529/3255 [36:56<40:52,  1.42s/it]\u001b[A\n","Iteration:  47% 1530/3255 [36:57<40:49,  1.42s/it]\u001b[A\n","Iteration:  47% 1531/3255 [36:59<40:46,  1.42s/it]\u001b[A\n","Iteration:  47% 1532/3255 [37:00<40:47,  1.42s/it]\u001b[A\n","Iteration:  47% 1533/3255 [37:02<40:44,  1.42s/it]\u001b[A\n","Iteration:  47% 1534/3255 [37:03<40:47,  1.42s/it]\u001b[A\n","Iteration:  47% 1535/3255 [37:05<40:38,  1.42s/it]\u001b[A\n","Iteration:  47% 1536/3255 [37:06<40:37,  1.42s/it]\u001b[A\n","Iteration:  47% 1537/3255 [37:07<40:34,  1.42s/it]\u001b[A\n","Iteration:  47% 1538/3255 [37:09<40:28,  1.41s/it]\u001b[A\n","Iteration:  47% 1539/3255 [37:10<40:24,  1.41s/it]\u001b[A\n","Iteration:  47% 1540/3255 [37:12<40:31,  1.42s/it]\u001b[A\n","Iteration:  47% 1541/3255 [37:13<40:22,  1.41s/it]\u001b[A\n","Iteration:  47% 1542/3255 [37:14<40:21,  1.41s/it]\u001b[A\n","Iteration:  47% 1543/3255 [37:16<40:30,  1.42s/it]\u001b[A\n","Iteration:  47% 1544/3255 [37:17<40:28,  1.42s/it]\u001b[A\n","Iteration:  47% 1545/3255 [37:19<40:21,  1.42s/it]\u001b[A\n","Iteration:  47% 1546/3255 [37:20<40:30,  1.42s/it]\u001b[A\n","Iteration:  48% 1547/3255 [37:22<40:19,  1.42s/it]\u001b[A\n","Iteration:  48% 1548/3255 [37:23<40:17,  1.42s/it]\u001b[A\n","Iteration:  48% 1549/3255 [37:24<40:14,  1.42s/it]\u001b[A11/26/2019 19:22:59 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-1550/config.json\n","11/26/2019 19:23:00 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-1550/pytorch_model.bin\n","11/26/2019 19:23:00 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-1550\n","\n","Iteration:  48% 1550/3255 [37:27<52:50,  1.86s/it]\u001b[A\n","Iteration:  48% 1551/3255 [37:29<48:38,  1.71s/it]\u001b[A\n","Iteration:  48% 1552/3255 [37:30<46:08,  1.63s/it]\u001b[A\n","Iteration:  48% 1553/3255 [37:31<44:15,  1.56s/it]\u001b[A\n","Iteration:  48% 1554/3255 [37:33<43:02,  1.52s/it]\u001b[A\n","Iteration:  48% 1555/3255 [37:34<42:09,  1.49s/it]\u001b[A\n","Iteration:  48% 1556/3255 [37:36<41:26,  1.46s/it]\u001b[A\n","Iteration:  48% 1557/3255 [37:37<41:02,  1.45s/it]\u001b[A\n","Iteration:  48% 1558/3255 [37:39<40:41,  1.44s/it]\u001b[A\n","Iteration:  48% 1559/3255 [37:40<40:30,  1.43s/it]\u001b[A\n","Iteration:  48% 1560/3255 [37:41<40:23,  1.43s/it]\u001b[A\n","Iteration:  48% 1561/3255 [37:43<40:16,  1.43s/it]\u001b[A\n","Iteration:  48% 1562/3255 [37:44<40:13,  1.43s/it]\u001b[A\n","Iteration:  48% 1563/3255 [37:46<40:10,  1.42s/it]\u001b[A\n","Iteration:  48% 1564/3255 [37:47<40:03,  1.42s/it]\u001b[A\n","Iteration:  48% 1565/3255 [37:48<39:58,  1.42s/it]\u001b[A\n","Iteration:  48% 1566/3255 [37:50<40:01,  1.42s/it]\u001b[A\n","Iteration:  48% 1567/3255 [37:51<40:02,  1.42s/it]\u001b[A\n","Iteration:  48% 1568/3255 [37:53<40:05,  1.43s/it]\u001b[A\n","Iteration:  48% 1569/3255 [37:54<40:10,  1.43s/it]\u001b[A\n","Iteration:  48% 1570/3255 [37:56<40:08,  1.43s/it]\u001b[A\n","Iteration:  48% 1571/3255 [37:57<40:01,  1.43s/it]\u001b[A\n","Iteration:  48% 1572/3255 [37:58<39:59,  1.43s/it]\u001b[A\n","Iteration:  48% 1573/3255 [38:00<39:59,  1.43s/it]\u001b[A\n","Iteration:  48% 1574/3255 [38:01<39:51,  1.42s/it]\u001b[A\n","Iteration:  48% 1575/3255 [38:03<39:49,  1.42s/it]\u001b[A\n","Iteration:  48% 1576/3255 [38:04<39:46,  1.42s/it]\u001b[A\n","Iteration:  48% 1577/3255 [38:06<39:45,  1.42s/it]\u001b[A\n","Iteration:  48% 1578/3255 [38:07<39:44,  1.42s/it]\u001b[A\n","Iteration:  49% 1579/3255 [38:08<39:55,  1.43s/it]\u001b[A\n","Iteration:  49% 1580/3255 [38:10<39:44,  1.42s/it]\u001b[A\n","Iteration:  49% 1581/3255 [38:11<39:40,  1.42s/it]\u001b[A\n","Iteration:  49% 1582/3255 [38:13<39:25,  1.41s/it]\u001b[A\n","Iteration:  49% 1583/3255 [38:14<39:21,  1.41s/it]\u001b[A\n","Iteration:  49% 1584/3255 [38:16<39:24,  1.42s/it]\u001b[A\n","Iteration:  49% 1585/3255 [38:17<39:24,  1.42s/it]\u001b[A\n","Iteration:  49% 1586/3255 [38:18<39:23,  1.42s/it]\u001b[A\n","Iteration:  49% 1587/3255 [38:20<39:26,  1.42s/it]\u001b[A\n","Iteration:  49% 1588/3255 [38:21<39:22,  1.42s/it]\u001b[A\n","Iteration:  49% 1589/3255 [38:23<39:19,  1.42s/it]\u001b[A\n","Iteration:  49% 1590/3255 [38:24<39:24,  1.42s/it]\u001b[A\n","Iteration:  49% 1591/3255 [38:25<39:27,  1.42s/it]\u001b[A\n","Iteration:  49% 1592/3255 [38:27<39:23,  1.42s/it]\u001b[A\n","Iteration:  49% 1593/3255 [38:28<39:28,  1.43s/it]\u001b[A\n","Iteration:  49% 1594/3255 [38:30<39:24,  1.42s/it]\u001b[A\n","Iteration:  49% 1595/3255 [38:31<39:26,  1.43s/it]\u001b[A\n","Iteration:  49% 1596/3255 [38:33<39:23,  1.42s/it]\u001b[A\n","Iteration:  49% 1597/3255 [38:34<39:20,  1.42s/it]\u001b[A\n","Iteration:  49% 1598/3255 [38:35<39:15,  1.42s/it]\u001b[A\n","Iteration:  49% 1599/3255 [38:37<39:15,  1.42s/it]\u001b[A11/26/2019 19:24:11 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-1600/config.json\n","11/26/2019 19:24:12 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-1600/pytorch_model.bin\n","11/26/2019 19:24:12 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-1600\n","\n","Iteration:  49% 1600/3255 [38:40<51:24,  1.86s/it]\u001b[A\n","Iteration:  49% 1601/3255 [38:41<47:15,  1.71s/it]\u001b[A\n","Iteration:  49% 1602/3255 [38:43<44:50,  1.63s/it]\u001b[A\n","Iteration:  49% 1603/3255 [38:44<43:09,  1.57s/it]\u001b[A\n","Iteration:  49% 1604/3255 [38:45<41:53,  1.52s/it]\u001b[A\n","Iteration:  49% 1605/3255 [38:47<41:07,  1.50s/it]\u001b[A\n","Iteration:  49% 1606/3255 [38:48<40:29,  1.47s/it]\u001b[A\n","Iteration:  49% 1607/3255 [38:50<39:53,  1.45s/it]\u001b[A\n","Iteration:  49% 1608/3255 [38:51<39:42,  1.45s/it]\u001b[A\n","Iteration:  49% 1609/3255 [38:52<39:31,  1.44s/it]\u001b[A\n","Iteration:  49% 1610/3255 [38:54<39:13,  1.43s/it]\u001b[A\n","Iteration:  49% 1611/3255 [38:55<39:10,  1.43s/it]\u001b[A\n","Iteration:  50% 1612/3255 [38:57<39:13,  1.43s/it]\u001b[A\n","Iteration:  50% 1613/3255 [38:58<38:56,  1.42s/it]\u001b[A\n","Iteration:  50% 1614/3255 [39:00<38:57,  1.42s/it]\u001b[A\n","Iteration:  50% 1615/3255 [39:01<38:52,  1.42s/it]\u001b[A\n","Iteration:  50% 1616/3255 [39:02<38:49,  1.42s/it]\u001b[A\n","Iteration:  50% 1617/3255 [39:04<38:49,  1.42s/it]\u001b[A\n","Iteration:  50% 1618/3255 [39:05<38:46,  1.42s/it]\u001b[A\n","Iteration:  50% 1619/3255 [39:07<38:44,  1.42s/it]\u001b[A\n","Iteration:  50% 1620/3255 [39:08<38:39,  1.42s/it]\u001b[A\n","Iteration:  50% 1621/3255 [39:10<38:34,  1.42s/it]\u001b[A\n","Iteration:  50% 1622/3255 [39:11<38:36,  1.42s/it]\u001b[A\n","Iteration:  50% 1623/3255 [39:12<38:31,  1.42s/it]\u001b[A\n","Iteration:  50% 1624/3255 [39:14<38:37,  1.42s/it]\u001b[A\n","Iteration:  50% 1625/3255 [39:15<38:31,  1.42s/it]\u001b[A\n","Iteration:  50% 1626/3255 [39:17<38:45,  1.43s/it]\u001b[A\n","Iteration:  50% 1627/3255 [39:18<38:43,  1.43s/it]\u001b[A\n","Iteration:  50% 1628/3255 [39:19<38:35,  1.42s/it]\u001b[A\n","Iteration:  50% 1629/3255 [39:21<38:32,  1.42s/it]\u001b[A\n","Iteration:  50% 1630/3255 [39:22<38:35,  1.43s/it]\u001b[A\n","Iteration:  50% 1631/3255 [39:24<38:33,  1.42s/it]\u001b[A\n","Iteration:  50% 1632/3255 [39:25<38:36,  1.43s/it]\u001b[A\n","Iteration:  50% 1633/3255 [39:27<38:36,  1.43s/it]\u001b[A\n","Iteration:  50% 1634/3255 [39:28<38:27,  1.42s/it]\u001b[A\n","Iteration:  50% 1635/3255 [39:29<38:22,  1.42s/it]\u001b[A\n","Iteration:  50% 1636/3255 [39:31<38:23,  1.42s/it]\u001b[A\n","Iteration:  50% 1637/3255 [39:32<38:25,  1.42s/it]\u001b[A\n","Iteration:  50% 1638/3255 [39:34<38:20,  1.42s/it]\u001b[A\n","Iteration:  50% 1639/3255 [39:35<38:17,  1.42s/it]\u001b[A\n","Iteration:  50% 1640/3255 [39:37<38:14,  1.42s/it]\u001b[A\n","Iteration:  50% 1641/3255 [39:38<38:08,  1.42s/it]\u001b[A\n","Iteration:  50% 1642/3255 [39:39<38:01,  1.41s/it]\u001b[A\n","Iteration:  50% 1643/3255 [39:41<38:08,  1.42s/it]\u001b[A\n","Iteration:  51% 1644/3255 [39:42<38:00,  1.42s/it]\u001b[A\n","Iteration:  51% 1645/3255 [39:44<38:13,  1.42s/it]\u001b[A\n","Iteration:  51% 1646/3255 [39:45<38:12,  1.42s/it]\u001b[A\n","Iteration:  51% 1647/3255 [39:46<38:02,  1.42s/it]\u001b[A\n","Iteration:  51% 1648/3255 [39:48<38:00,  1.42s/it]\u001b[A\n","Iteration:  51% 1649/3255 [39:49<38:00,  1.42s/it]\u001b[A11/26/2019 19:25:23 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-1650/config.json\n","11/26/2019 19:25:25 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-1650/pytorch_model.bin\n","11/26/2019 19:25:25 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-1650\n","\n","Iteration:  51% 1650/3255 [39:52<49:40,  1.86s/it]\u001b[A\n","Iteration:  51% 1651/3255 [39:54<45:48,  1.71s/it]\u001b[A\n","Iteration:  51% 1652/3255 [39:55<43:28,  1.63s/it]\u001b[A\n","Iteration:  51% 1653/3255 [39:56<41:47,  1.57s/it]\u001b[A\n","Iteration:  51% 1654/3255 [39:58<40:41,  1.53s/it]\u001b[A\n","Iteration:  51% 1655/3255 [39:59<39:49,  1.49s/it]\u001b[A\n","Iteration:  51% 1656/3255 [40:01<39:12,  1.47s/it]\u001b[A\n","Iteration:  51% 1657/3255 [40:02<38:50,  1.46s/it]\u001b[A\n","Iteration:  51% 1658/3255 [40:04<38:29,  1.45s/it]\u001b[A\n","Iteration:  51% 1659/3255 [40:05<38:19,  1.44s/it]\u001b[A\n","Iteration:  51% 1660/3255 [40:06<38:14,  1.44s/it]\u001b[A\n","Iteration:  51% 1661/3255 [40:08<38:01,  1.43s/it]\u001b[A\n","Iteration:  51% 1662/3255 [40:09<37:53,  1.43s/it]\u001b[A\n","Iteration:  51% 1663/3255 [40:11<38:01,  1.43s/it]\u001b[A\n","Iteration:  51% 1664/3255 [40:12<37:54,  1.43s/it]\u001b[A\n","Iteration:  51% 1665/3255 [40:14<37:47,  1.43s/it]\u001b[A\n","Iteration:  51% 1666/3255 [40:15<37:38,  1.42s/it]\u001b[A\n","Iteration:  51% 1667/3255 [40:16<37:40,  1.42s/it]\u001b[A\n","Iteration:  51% 1668/3255 [40:18<37:35,  1.42s/it]\u001b[A\n","Iteration:  51% 1669/3255 [40:19<37:42,  1.43s/it]\u001b[A\n","Iteration:  51% 1670/3255 [40:21<37:36,  1.42s/it]\u001b[A\n","Iteration:  51% 1671/3255 [40:22<37:28,  1.42s/it]\u001b[A\n","Iteration:  51% 1672/3255 [40:23<37:25,  1.42s/it]\u001b[A\n","Iteration:  51% 1673/3255 [40:25<37:20,  1.42s/it]\u001b[A\n","Iteration:  51% 1674/3255 [40:26<37:19,  1.42s/it]\u001b[A\n","Iteration:  51% 1675/3255 [40:28<37:14,  1.41s/it]\u001b[A\n","Iteration:  51% 1676/3255 [40:29<37:17,  1.42s/it]\u001b[A\n","Iteration:  52% 1677/3255 [40:31<37:19,  1.42s/it]\u001b[A\n","Iteration:  52% 1678/3255 [40:32<37:21,  1.42s/it]\u001b[A\n","Iteration:  52% 1679/3255 [40:33<37:24,  1.42s/it]\u001b[A\n","Iteration:  52% 1680/3255 [40:35<37:19,  1.42s/it]\u001b[A\n","Iteration:  52% 1681/3255 [40:36<37:25,  1.43s/it]\u001b[A\n","Iteration:  52% 1682/3255 [40:38<37:23,  1.43s/it]\u001b[A\n","Iteration:  52% 1683/3255 [40:39<37:24,  1.43s/it]\u001b[A\n","Iteration:  52% 1684/3255 [40:41<37:19,  1.43s/it]\u001b[A\n","Iteration:  52% 1685/3255 [40:42<37:17,  1.43s/it]\u001b[A\n","Iteration:  52% 1686/3255 [40:43<37:17,  1.43s/it]\u001b[A\n","Iteration:  52% 1687/3255 [40:45<37:15,  1.43s/it]\u001b[A\n","Iteration:  52% 1688/3255 [40:46<37:20,  1.43s/it]\u001b[A\n","Iteration:  52% 1689/3255 [40:48<37:00,  1.42s/it]\u001b[A\n","Iteration:  52% 1690/3255 [40:49<36:54,  1.41s/it]\u001b[A\n","Iteration:  52% 1691/3255 [40:50<36:56,  1.42s/it]\u001b[A\n","Iteration:  52% 1692/3255 [40:52<37:00,  1.42s/it]\u001b[A\n","Iteration:  52% 1693/3255 [40:53<36:53,  1.42s/it]\u001b[A\n","Iteration:  52% 1694/3255 [40:55<36:57,  1.42s/it]\u001b[A\n","Iteration:  52% 1695/3255 [40:56<37:01,  1.42s/it]\u001b[A\n","Iteration:  52% 1696/3255 [40:58<36:53,  1.42s/it]\u001b[A\n","Iteration:  52% 1697/3255 [40:59<37:03,  1.43s/it]\u001b[A\n","Iteration:  52% 1698/3255 [41:00<36:58,  1.42s/it]\u001b[A\n","Iteration:  52% 1699/3255 [41:02<36:47,  1.42s/it]\u001b[A11/26/2019 19:26:36 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-1700/config.json\n","11/26/2019 19:26:38 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-1700/pytorch_model.bin\n","11/26/2019 19:26:38 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-1700\n","\n","Iteration:  52% 1700/3255 [41:05<48:42,  1.88s/it]\u001b[A\n","Iteration:  52% 1701/3255 [41:06<44:41,  1.73s/it]\u001b[A\n","Iteration:  52% 1702/3255 [41:08<42:13,  1.63s/it]\u001b[A\n","Iteration:  52% 1703/3255 [41:09<40:38,  1.57s/it]\u001b[A\n","Iteration:  52% 1704/3255 [41:10<39:30,  1.53s/it]\u001b[A\n","Iteration:  52% 1705/3255 [41:12<38:43,  1.50s/it]\u001b[A\n","Iteration:  52% 1706/3255 [41:13<38:10,  1.48s/it]\u001b[A\n","Iteration:  52% 1707/3255 [41:15<37:42,  1.46s/it]\u001b[A\n","Iteration:  52% 1708/3255 [41:16<37:21,  1.45s/it]\u001b[A\n","Iteration:  53% 1709/3255 [41:18<37:10,  1.44s/it]\u001b[A\n","Iteration:  53% 1710/3255 [41:19<37:07,  1.44s/it]\u001b[A\n","Iteration:  53% 1711/3255 [41:20<36:52,  1.43s/it]\u001b[A\n","Iteration:  53% 1712/3255 [41:22<36:43,  1.43s/it]\u001b[A\n","Iteration:  53% 1713/3255 [41:23<36:41,  1.43s/it]\u001b[A\n","Iteration:  53% 1714/3255 [41:25<36:29,  1.42s/it]\u001b[A\n","Iteration:  53% 1715/3255 [41:26<36:26,  1.42s/it]\u001b[A\n","Iteration:  53% 1716/3255 [41:28<36:22,  1.42s/it]\u001b[A\n","Iteration:  53% 1717/3255 [41:29<36:23,  1.42s/it]\u001b[A\n","Iteration:  53% 1718/3255 [41:30<36:25,  1.42s/it]\u001b[A\n","Iteration:  53% 1719/3255 [41:32<36:24,  1.42s/it]\u001b[A\n","Iteration:  53% 1720/3255 [41:33<36:12,  1.42s/it]\u001b[A\n","Iteration:  53% 1721/3255 [41:35<36:12,  1.42s/it]\u001b[A\n","Iteration:  53% 1722/3255 [41:36<36:15,  1.42s/it]\u001b[A\n","Iteration:  53% 1723/3255 [41:37<36:12,  1.42s/it]\u001b[A\n","Iteration:  53% 1724/3255 [41:39<36:05,  1.41s/it]\u001b[A\n","Iteration:  53% 1725/3255 [41:40<36:11,  1.42s/it]\u001b[A\n","Iteration:  53% 1726/3255 [41:42<36:08,  1.42s/it]\u001b[A\n","Iteration:  53% 1727/3255 [41:43<36:01,  1.41s/it]\u001b[A\n","Iteration:  53% 1728/3255 [41:45<36:00,  1.42s/it]\u001b[A\n","Iteration:  53% 1729/3255 [41:46<35:57,  1.41s/it]\u001b[A\n","Iteration:  53% 1730/3255 [41:47<35:51,  1.41s/it]\u001b[A\n","Iteration:  53% 1731/3255 [41:49<36:00,  1.42s/it]\u001b[A\n","Iteration:  53% 1732/3255 [41:50<35:58,  1.42s/it]\u001b[A\n","Iteration:  53% 1733/3255 [41:52<35:59,  1.42s/it]\u001b[A\n","Iteration:  53% 1734/3255 [41:53<36:06,  1.42s/it]\u001b[A\n","Iteration:  53% 1735/3255 [41:54<36:01,  1.42s/it]\u001b[A\n","Iteration:  53% 1736/3255 [41:56<35:57,  1.42s/it]\u001b[A\n","Iteration:  53% 1737/3255 [41:57<35:57,  1.42s/it]\u001b[A\n","Iteration:  53% 1738/3255 [41:59<35:48,  1.42s/it]\u001b[A\n","Iteration:  53% 1739/3255 [42:00<35:54,  1.42s/it]\u001b[A\n","Iteration:  53% 1740/3255 [42:02<35:39,  1.41s/it]\u001b[A\n","Iteration:  53% 1741/3255 [42:03<35:37,  1.41s/it]\u001b[A\n","Iteration:  54% 1742/3255 [42:04<35:37,  1.41s/it]\u001b[A\n","Iteration:  54% 1743/3255 [42:06<35:38,  1.41s/it]\u001b[A\n","Iteration:  54% 1744/3255 [42:07<35:38,  1.42s/it]\u001b[A\n","Iteration:  54% 1745/3255 [42:09<35:40,  1.42s/it]\u001b[A\n","Iteration:  54% 1746/3255 [42:10<35:47,  1.42s/it]\u001b[A\n","Iteration:  54% 1747/3255 [42:11<35:44,  1.42s/it]\u001b[A\n","Iteration:  54% 1748/3255 [42:13<35:40,  1.42s/it]\u001b[A\n","Iteration:  54% 1749/3255 [42:14<35:43,  1.42s/it]\u001b[A11/26/2019 19:27:48 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-1750/config.json\n","11/26/2019 19:27:50 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-1750/pytorch_model.bin\n","11/26/2019 19:27:50 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-1750\n","\n","Iteration:  54% 1750/3255 [42:17<47:08,  1.88s/it]\u001b[A\n","Iteration:  54% 1751/3255 [42:19<43:09,  1.72s/it]\u001b[A\n","Iteration:  54% 1752/3255 [42:20<40:51,  1.63s/it]\u001b[A\n","Iteration:  54% 1753/3255 [42:21<39:15,  1.57s/it]\u001b[A\n","Iteration:  54% 1754/3255 [42:23<38:12,  1.53s/it]\u001b[A\n","Iteration:  54% 1755/3255 [42:24<37:19,  1.49s/it]\u001b[A\n","Iteration:  54% 1756/3255 [42:26<36:43,  1.47s/it]\u001b[A\n","Iteration:  54% 1757/3255 [42:27<36:18,  1.45s/it]\u001b[A\n","Iteration:  54% 1758/3255 [42:29<35:59,  1.44s/it]\u001b[A\n","Iteration:  54% 1759/3255 [42:30<35:49,  1.44s/it]\u001b[A\n","Iteration:  54% 1760/3255 [42:31<35:35,  1.43s/it]\u001b[A\n","Iteration:  54% 1761/3255 [42:33<35:28,  1.42s/it]\u001b[A\n","Iteration:  54% 1762/3255 [42:34<35:30,  1.43s/it]\u001b[A\n","Iteration:  54% 1763/3255 [42:36<35:27,  1.43s/it]\u001b[A\n","Iteration:  54% 1764/3255 [42:37<35:25,  1.43s/it]\u001b[A\n","Iteration:  54% 1765/3255 [42:38<35:17,  1.42s/it]\u001b[A\n","Iteration:  54% 1766/3255 [42:40<35:19,  1.42s/it]\u001b[A\n","Iteration:  54% 1767/3255 [42:41<35:09,  1.42s/it]\u001b[A\n","Iteration:  54% 1768/3255 [42:43<35:15,  1.42s/it]\u001b[A\n","Iteration:  54% 1769/3255 [42:44<35:18,  1.43s/it]\u001b[A\n","Iteration:  54% 1770/3255 [42:46<35:14,  1.42s/it]\u001b[A\n","Iteration:  54% 1771/3255 [42:47<35:09,  1.42s/it]\u001b[A\n","Iteration:  54% 1772/3255 [42:48<35:05,  1.42s/it]\u001b[A\n","Iteration:  54% 1773/3255 [42:50<34:59,  1.42s/it]\u001b[A\n","Iteration:  55% 1774/3255 [42:51<34:59,  1.42s/it]\u001b[A\n","Iteration:  55% 1775/3255 [42:53<34:56,  1.42s/it]\u001b[A\n","Iteration:  55% 1776/3255 [42:54<35:07,  1.43s/it]\u001b[A\n","Iteration:  55% 1777/3255 [42:56<34:57,  1.42s/it]\u001b[A\n","Iteration:  55% 1778/3255 [42:57<34:53,  1.42s/it]\u001b[A\n","Iteration:  55% 1779/3255 [42:58<34:49,  1.42s/it]\u001b[A\n","Iteration:  55% 1780/3255 [43:00<34:53,  1.42s/it]\u001b[A\n","Iteration:  55% 1781/3255 [43:01<34:51,  1.42s/it]\u001b[A\n","Iteration:  55% 1782/3255 [43:03<34:53,  1.42s/it]\u001b[A\n","Iteration:  55% 1783/3255 [43:04<34:56,  1.42s/it]\u001b[A\n","Iteration:  55% 1784/3255 [43:05<34:52,  1.42s/it]\u001b[A\n","Iteration:  55% 1785/3255 [43:07<34:43,  1.42s/it]\u001b[A\n","Iteration:  55% 1786/3255 [43:08<34:45,  1.42s/it]\u001b[A\n","Iteration:  55% 1787/3255 [43:10<34:37,  1.42s/it]\u001b[A\n","Iteration:  55% 1788/3255 [43:11<34:41,  1.42s/it]\u001b[A\n","Iteration:  55% 1789/3255 [43:13<34:39,  1.42s/it]\u001b[A\n","Iteration:  55% 1790/3255 [43:14<34:48,  1.43s/it]\u001b[A\n","Iteration:  55% 1791/3255 [43:15<34:41,  1.42s/it]\u001b[A\n","Iteration:  55% 1792/3255 [43:17<34:37,  1.42s/it]\u001b[A\n","Iteration:  55% 1793/3255 [43:18<34:38,  1.42s/it]\u001b[A\n","Iteration:  55% 1794/3255 [43:20<34:38,  1.42s/it]\u001b[A\n","Iteration:  55% 1795/3255 [43:21<34:38,  1.42s/it]\u001b[A\n","Iteration:  55% 1796/3255 [43:23<34:32,  1.42s/it]\u001b[A\n","Iteration:  55% 1797/3255 [43:24<34:27,  1.42s/it]\u001b[A\n","Iteration:  55% 1798/3255 [43:25<34:32,  1.42s/it]\u001b[A\n","Iteration:  55% 1799/3255 [43:27<34:31,  1.42s/it]\u001b[A11/26/2019 19:29:01 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-1800/config.json\n","11/26/2019 19:29:02 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-1800/pytorch_model.bin\n","11/26/2019 19:29:02 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-1800\n","\n","Iteration:  55% 1800/3255 [43:30<45:05,  1.86s/it]\u001b[A\n","Iteration:  55% 1801/3255 [43:31<41:34,  1.72s/it]\u001b[A\n","Iteration:  55% 1802/3255 [43:32<39:25,  1.63s/it]\u001b[A\n","Iteration:  55% 1803/3255 [43:34<37:54,  1.57s/it]\u001b[A\n","Iteration:  55% 1804/3255 [43:35<36:47,  1.52s/it]\u001b[A\n","Iteration:  55% 1805/3255 [43:37<36:09,  1.50s/it]\u001b[A\n","Iteration:  55% 1806/3255 [43:38<35:33,  1.47s/it]\u001b[A\n","Iteration:  56% 1807/3255 [43:40<35:02,  1.45s/it]\u001b[A\n","Iteration:  56% 1808/3255 [43:41<34:55,  1.45s/it]\u001b[A\n","Iteration:  56% 1809/3255 [43:42<34:40,  1.44s/it]\u001b[A\n","Iteration:  56% 1810/3255 [43:44<34:33,  1.43s/it]\u001b[A\n","Iteration:  56% 1811/3255 [43:45<34:24,  1.43s/it]\u001b[A\n","Iteration:  56% 1812/3255 [43:47<34:18,  1.43s/it]\u001b[A\n","Iteration:  56% 1813/3255 [43:48<34:09,  1.42s/it]\u001b[A\n","Iteration:  56% 1814/3255 [43:50<34:04,  1.42s/it]\u001b[A\n","Iteration:  56% 1815/3255 [43:51<34:05,  1.42s/it]\u001b[A\n","Iteration:  56% 1816/3255 [43:52<33:58,  1.42s/it]\u001b[A\n","Iteration:  56% 1817/3255 [43:54<34:03,  1.42s/it]\u001b[A\n","Iteration:  56% 1818/3255 [43:55<33:58,  1.42s/it]\u001b[A\n","Iteration:  56% 1819/3255 [43:57<33:53,  1.42s/it]\u001b[A\n","Iteration:  56% 1820/3255 [43:58<33:57,  1.42s/it]\u001b[A\n","Iteration:  56% 1821/3255 [43:59<33:57,  1.42s/it]\u001b[A\n","Iteration:  56% 1822/3255 [44:01<33:51,  1.42s/it]\u001b[A\n","Iteration:  56% 1823/3255 [44:02<33:56,  1.42s/it]\u001b[A\n","Iteration:  56% 1824/3255 [44:04<33:49,  1.42s/it]\u001b[A\n","Iteration:  56% 1825/3255 [44:05<33:49,  1.42s/it]\u001b[A\n","Iteration:  56% 1826/3255 [44:07<33:52,  1.42s/it]\u001b[A\n","Iteration:  56% 1827/3255 [44:08<33:52,  1.42s/it]\u001b[A\n","Iteration:  56% 1828/3255 [44:09<33:47,  1.42s/it]\u001b[A\n","Iteration:  56% 1829/3255 [44:11<33:48,  1.42s/it]\u001b[A\n","Iteration:  56% 1830/3255 [44:12<33:41,  1.42s/it]\u001b[A\n","Iteration:  56% 1831/3255 [44:14<33:36,  1.42s/it]\u001b[A\n","Iteration:  56% 1832/3255 [44:15<33:36,  1.42s/it]\u001b[A\n","Iteration:  56% 1833/3255 [44:16<33:38,  1.42s/it]\u001b[A\n","Iteration:  56% 1834/3255 [44:18<33:43,  1.42s/it]\u001b[A\n","Iteration:  56% 1835/3255 [44:19<33:36,  1.42s/it]\u001b[A\n","Iteration:  56% 1836/3255 [44:21<33:32,  1.42s/it]\u001b[A\n","Iteration:  56% 1837/3255 [44:22<33:33,  1.42s/it]\u001b[A\n","Iteration:  56% 1838/3255 [44:24<33:24,  1.41s/it]\u001b[A\n","Iteration:  56% 1839/3255 [44:25<33:26,  1.42s/it]\u001b[A\n","Iteration:  57% 1840/3255 [44:26<33:30,  1.42s/it]\u001b[A\n","Iteration:  57% 1841/3255 [44:28<33:30,  1.42s/it]\u001b[A\n","Iteration:  57% 1842/3255 [44:29<33:32,  1.42s/it]\u001b[A\n","Iteration:  57% 1843/3255 [44:31<33:29,  1.42s/it]\u001b[A\n","Iteration:  57% 1844/3255 [44:32<33:27,  1.42s/it]\u001b[A\n","Iteration:  57% 1845/3255 [44:34<33:24,  1.42s/it]\u001b[A\n","Iteration:  57% 1846/3255 [44:35<33:24,  1.42s/it]\u001b[A\n","Iteration:  57% 1847/3255 [44:36<33:21,  1.42s/it]\u001b[A\n","Iteration:  57% 1848/3255 [44:38<33:22,  1.42s/it]\u001b[A\n","Iteration:  57% 1849/3255 [44:39<33:23,  1.42s/it]\u001b[A11/26/2019 19:30:13 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-1850/config.json\n","11/26/2019 19:30:15 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-1850/pytorch_model.bin\n","11/26/2019 19:30:15 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-1850\n","\n","Iteration:  57% 1850/3255 [44:42<43:50,  1.87s/it]\u001b[A\n","Iteration:  57% 1851/3255 [44:44<40:16,  1.72s/it]\u001b[A\n","Iteration:  57% 1852/3255 [44:45<38:03,  1.63s/it]\u001b[A\n","Iteration:  57% 1853/3255 [44:46<36:34,  1.57s/it]\u001b[A\n","Iteration:  57% 1854/3255 [44:48<35:28,  1.52s/it]\u001b[A\n","Iteration:  57% 1855/3255 [44:49<34:41,  1.49s/it]\u001b[A\n","Iteration:  57% 1856/3255 [44:51<34:12,  1.47s/it]\u001b[A\n","Iteration:  57% 1857/3255 [44:52<33:49,  1.45s/it]\u001b[A\n","Iteration:  57% 1858/3255 [44:53<33:35,  1.44s/it]\u001b[A\n","Iteration:  57% 1859/3255 [44:55<33:35,  1.44s/it]\u001b[A\n","Iteration:  57% 1860/3255 [44:56<33:26,  1.44s/it]\u001b[A\n","Iteration:  57% 1861/3255 [44:58<33:14,  1.43s/it]\u001b[A\n","Iteration:  57% 1862/3255 [44:59<33:07,  1.43s/it]\u001b[A\n","Iteration:  57% 1863/3255 [45:01<33:00,  1.42s/it]\u001b[A\n","Iteration:  57% 1864/3255 [45:02<33:00,  1.42s/it]\u001b[A\n","Iteration:  57% 1865/3255 [45:03<33:06,  1.43s/it]\u001b[A\n","Iteration:  57% 1866/3255 [45:05<32:58,  1.42s/it]\u001b[A\n","Iteration:  57% 1867/3255 [45:06<32:55,  1.42s/it]\u001b[A\n","Iteration:  57% 1868/3255 [45:08<32:45,  1.42s/it]\u001b[A\n","Iteration:  57% 1869/3255 [45:09<32:42,  1.42s/it]\u001b[A\n","Iteration:  57% 1870/3255 [45:10<32:39,  1.42s/it]\u001b[A\n","Iteration:  57% 1871/3255 [45:12<32:39,  1.42s/it]\u001b[A\n","Iteration:  58% 1872/3255 [45:13<32:44,  1.42s/it]\u001b[A\n","Iteration:  58% 1873/3255 [45:15<32:44,  1.42s/it]\u001b[A\n","Iteration:  58% 1874/3255 [45:16<32:50,  1.43s/it]\u001b[A\n","Iteration:  58% 1875/3255 [45:18<32:44,  1.42s/it]\u001b[A\n","Iteration:  58% 1876/3255 [45:19<32:38,  1.42s/it]\u001b[A\n","Iteration:  58% 1877/3255 [45:20<32:40,  1.42s/it]\u001b[A\n","Iteration:  58% 1878/3255 [45:22<32:29,  1.42s/it]\u001b[A\n","Iteration:  58% 1879/3255 [45:23<32:31,  1.42s/it]\u001b[A\n","Iteration:  58% 1880/3255 [45:25<32:29,  1.42s/it]\u001b[A\n","Iteration:  58% 1881/3255 [45:26<32:37,  1.42s/it]\u001b[A\n","Iteration:  58% 1882/3255 [45:28<32:30,  1.42s/it]\u001b[A\n","Iteration:  58% 1883/3255 [45:29<32:32,  1.42s/it]\u001b[A\n","Iteration:  58% 1884/3255 [45:30<32:32,  1.42s/it]\u001b[A\n","Iteration:  58% 1885/3255 [45:32<32:25,  1.42s/it]\u001b[A\n","Iteration:  58% 1886/3255 [45:33<32:30,  1.42s/it]\u001b[A\n","Iteration:  58% 1887/3255 [45:35<32:27,  1.42s/it]\u001b[A\n","Iteration:  58% 1888/3255 [45:36<32:26,  1.42s/it]\u001b[A\n","Iteration:  58% 1889/3255 [45:37<32:21,  1.42s/it]\u001b[A\n","Iteration:  58% 1890/3255 [45:39<32:18,  1.42s/it]\u001b[A\n","Iteration:  58% 1891/3255 [45:40<32:19,  1.42s/it]\u001b[A\n","Iteration:  58% 1892/3255 [45:42<32:17,  1.42s/it]\u001b[A\n","Iteration:  58% 1893/3255 [45:43<32:24,  1.43s/it]\u001b[A\n","Iteration:  58% 1894/3255 [45:45<32:15,  1.42s/it]\u001b[A\n","Iteration:  58% 1895/3255 [45:46<32:09,  1.42s/it]\u001b[A\n","Iteration:  58% 1896/3255 [45:47<32:08,  1.42s/it]\u001b[A\n","Iteration:  58% 1897/3255 [45:49<32:07,  1.42s/it]\u001b[A\n","Iteration:  58% 1898/3255 [45:50<32:02,  1.42s/it]\u001b[A\n","Iteration:  58% 1899/3255 [45:52<31:59,  1.42s/it]\u001b[A11/26/2019 19:31:26 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-1900/config.json\n","11/26/2019 19:31:27 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-1900/pytorch_model.bin\n","11/26/2019 19:31:27 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-1900\n","\n","Iteration:  58% 1900/3255 [45:55<42:08,  1.87s/it]\u001b[A\n","Iteration:  58% 1901/3255 [45:56<38:45,  1.72s/it]\u001b[A\n","Iteration:  58% 1902/3255 [45:57<36:46,  1.63s/it]\u001b[A\n","Iteration:  58% 1903/3255 [45:59<35:15,  1.56s/it]\u001b[A\n","Iteration:  58% 1904/3255 [46:00<34:16,  1.52s/it]\u001b[A\n","Iteration:  59% 1905/3255 [46:02<33:29,  1.49s/it]\u001b[A\n","Iteration:  59% 1906/3255 [46:03<33:02,  1.47s/it]\u001b[A\n","Iteration:  59% 1907/3255 [46:04<32:44,  1.46s/it]\u001b[A\n","Iteration:  59% 1908/3255 [46:06<32:30,  1.45s/it]\u001b[A\n","Iteration:  59% 1909/3255 [46:07<32:13,  1.44s/it]\u001b[A\n","Iteration:  59% 1910/3255 [46:09<32:05,  1.43s/it]\u001b[A\n","Iteration:  59% 1911/3255 [46:10<32:03,  1.43s/it]\u001b[A\n","Iteration:  59% 1912/3255 [46:12<31:55,  1.43s/it]\u001b[A\n","Iteration:  59% 1913/3255 [46:13<31:56,  1.43s/it]\u001b[A\n","Iteration:  59% 1914/3255 [46:14<31:54,  1.43s/it]\u001b[A\n","Iteration:  59% 1915/3255 [46:16<31:48,  1.42s/it]\u001b[A\n","Iteration:  59% 1916/3255 [46:17<31:44,  1.42s/it]\u001b[A\n","Iteration:  59% 1917/3255 [46:19<31:46,  1.42s/it]\u001b[A\n","Iteration:  59% 1918/3255 [46:20<31:45,  1.42s/it]\u001b[A\n","Iteration:  59% 1919/3255 [46:22<31:43,  1.42s/it]\u001b[A\n","Iteration:  59% 1920/3255 [46:23<31:43,  1.43s/it]\u001b[A\n","Iteration:  59% 1921/3255 [46:24<31:40,  1.42s/it]\u001b[A\n","Iteration:  59% 1922/3255 [46:26<31:38,  1.42s/it]\u001b[A\n","Iteration:  59% 1923/3255 [46:27<31:39,  1.43s/it]\u001b[A\n","Iteration:  59% 1924/3255 [46:29<31:31,  1.42s/it]\u001b[A\n","Iteration:  59% 1925/3255 [46:30<31:33,  1.42s/it]\u001b[A\n","Iteration:  59% 1926/3255 [46:32<31:24,  1.42s/it]\u001b[A\n","Iteration:  59% 1927/3255 [46:33<31:20,  1.42s/it]\u001b[A\n","Iteration:  59% 1928/3255 [46:34<31:21,  1.42s/it]\u001b[A\n","Iteration:  59% 1929/3255 [46:36<31:16,  1.42s/it]\u001b[A\n","Iteration:  59% 1930/3255 [46:37<31:13,  1.41s/it]\u001b[A\n","Iteration:  59% 1931/3255 [46:39<31:17,  1.42s/it]\u001b[A\n","Iteration:  59% 1932/3255 [46:40<31:16,  1.42s/it]\u001b[A\n","Iteration:  59% 1933/3255 [46:41<31:14,  1.42s/it]\u001b[A\n","Iteration:  59% 1934/3255 [46:43<31:11,  1.42s/it]\u001b[A\n","Iteration:  59% 1935/3255 [46:44<31:06,  1.41s/it]\u001b[A\n","Iteration:  59% 1936/3255 [46:46<31:03,  1.41s/it]\u001b[A\n","Iteration:  60% 1937/3255 [46:47<31:10,  1.42s/it]\u001b[A\n","Iteration:  60% 1938/3255 [46:49<31:06,  1.42s/it]\u001b[A\n","Iteration:  60% 1939/3255 [46:50<31:04,  1.42s/it]\u001b[A\n","Iteration:  60% 1940/3255 [46:51<31:01,  1.42s/it]\u001b[A\n","Iteration:  60% 1941/3255 [46:53<31:01,  1.42s/it]\u001b[A\n","Iteration:  60% 1942/3255 [46:54<31:06,  1.42s/it]\u001b[A\n","Iteration:  60% 1943/3255 [46:56<31:08,  1.42s/it]\u001b[A\n","Iteration:  60% 1944/3255 [46:57<31:07,  1.42s/it]\u001b[A\n","Iteration:  60% 1945/3255 [46:58<31:01,  1.42s/it]\u001b[A\n","Iteration:  60% 1946/3255 [47:00<30:56,  1.42s/it]\u001b[A\n","Iteration:  60% 1947/3255 [47:01<30:55,  1.42s/it]\u001b[A\n","Iteration:  60% 1948/3255 [47:03<30:54,  1.42s/it]\u001b[A\n","Iteration:  60% 1949/3255 [47:04<30:53,  1.42s/it]\u001b[A11/26/2019 19:32:38 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-1950/config.json\n","11/26/2019 19:32:40 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-1950/pytorch_model.bin\n","11/26/2019 19:32:40 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-1950\n","\n","Iteration:  60% 1950/3255 [47:07<40:34,  1.87s/it]\u001b[A\n","Iteration:  60% 1951/3255 [47:08<37:15,  1.71s/it]\u001b[A\n","Iteration:  60% 1952/3255 [47:10<35:19,  1.63s/it]\u001b[A\n","Iteration:  60% 1953/3255 [47:11<33:55,  1.56s/it]\u001b[A\n","Iteration:  60% 1954/3255 [47:13<32:54,  1.52s/it]\u001b[A\n","Iteration:  60% 1955/3255 [47:14<32:18,  1.49s/it]\u001b[A\n","Iteration:  60% 1956/3255 [47:16<31:47,  1.47s/it]\u001b[A\n","Iteration:  60% 1957/3255 [47:17<31:22,  1.45s/it]\u001b[A\n","Iteration:  60% 1958/3255 [47:18<31:13,  1.44s/it]\u001b[A\n","Iteration:  60% 1959/3255 [47:20<30:50,  1.43s/it]\u001b[A\n","Iteration:  60% 1960/3255 [47:21<30:51,  1.43s/it]\u001b[A\n","Iteration:  60% 1961/3255 [47:23<30:45,  1.43s/it]\u001b[A\n","Iteration:  60% 1962/3255 [47:24<30:40,  1.42s/it]\u001b[A\n","Iteration:  60% 1963/3255 [47:25<30:47,  1.43s/it]\u001b[A\n","Iteration:  60% 1964/3255 [47:27<30:41,  1.43s/it]\u001b[A\n","Iteration:  60% 1965/3255 [47:28<30:40,  1.43s/it]\u001b[A\n","Iteration:  60% 1966/3255 [47:30<30:35,  1.42s/it]\u001b[A\n","Iteration:  60% 1967/3255 [47:31<30:35,  1.43s/it]\u001b[A\n","Iteration:  60% 1968/3255 [47:33<30:36,  1.43s/it]\u001b[A\n","Iteration:  60% 1969/3255 [47:34<30:32,  1.42s/it]\u001b[A\n","Iteration:  61% 1970/3255 [47:35<30:34,  1.43s/it]\u001b[A\n","Iteration:  61% 1971/3255 [47:37<30:30,  1.43s/it]\u001b[A\n","Iteration:  61% 1972/3255 [47:38<30:26,  1.42s/it]\u001b[A\n","Iteration:  61% 1973/3255 [47:40<30:20,  1.42s/it]\u001b[A\n","Iteration:  61% 1974/3255 [47:41<30:20,  1.42s/it]\u001b[A\n","Iteration:  61% 1975/3255 [47:43<30:18,  1.42s/it]\u001b[A\n","Iteration:  61% 1976/3255 [47:44<30:21,  1.42s/it]\u001b[A\n","Iteration:  61% 1977/3255 [47:45<30:17,  1.42s/it]\u001b[A\n","Iteration:  61% 1978/3255 [47:47<30:08,  1.42s/it]\u001b[A\n","Iteration:  61% 1979/3255 [47:48<30:07,  1.42s/it]\u001b[A\n","Iteration:  61% 1980/3255 [47:50<30:06,  1.42s/it]\u001b[A\n","Iteration:  61% 1981/3255 [47:51<30:07,  1.42s/it]\u001b[A\n","Iteration:  61% 1982/3255 [47:52<30:05,  1.42s/it]\u001b[A\n","Iteration:  61% 1983/3255 [47:54<30:05,  1.42s/it]\u001b[A\n","Iteration:  61% 1984/3255 [47:55<30:05,  1.42s/it]\u001b[A\n","Iteration:  61% 1985/3255 [47:57<29:59,  1.42s/it]\u001b[A\n","Iteration:  61% 1986/3255 [47:58<30:02,  1.42s/it]\u001b[A\n","Iteration:  61% 1987/3255 [48:00<29:59,  1.42s/it]\u001b[A\n","Iteration:  61% 1988/3255 [48:01<29:59,  1.42s/it]\u001b[A\n","Iteration:  61% 1989/3255 [48:02<30:08,  1.43s/it]\u001b[A\n","Iteration:  61% 1990/3255 [48:04<30:02,  1.42s/it]\u001b[A\n","Iteration:  61% 1991/3255 [48:05<29:58,  1.42s/it]\u001b[A\n","Iteration:  61% 1992/3255 [48:07<29:54,  1.42s/it]\u001b[A\n","Iteration:  61% 1993/3255 [48:08<29:51,  1.42s/it]\u001b[A\n","Iteration:  61% 1994/3255 [48:10<29:53,  1.42s/it]\u001b[A\n","Iteration:  61% 1995/3255 [48:11<29:50,  1.42s/it]\u001b[A\n","Iteration:  61% 1996/3255 [48:12<29:46,  1.42s/it]\u001b[A\n","Iteration:  61% 1997/3255 [48:14<29:48,  1.42s/it]\u001b[A\n","Iteration:  61% 1998/3255 [48:15<29:42,  1.42s/it]\u001b[A\n","Iteration:  61% 1999/3255 [48:17<29:41,  1.42s/it]\u001b[A11/26/2019 19:33:51 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-2000/config.json\n","11/26/2019 19:33:52 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-2000/pytorch_model.bin\n","11/26/2019 19:33:52 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-2000\n","\n","Iteration:  61% 2000/3255 [48:19<38:48,  1.86s/it]\u001b[A\n","Iteration:  61% 2001/3255 [48:21<35:40,  1.71s/it]\u001b[A\n","Iteration:  62% 2002/3255 [48:22<33:54,  1.62s/it]\u001b[A\n","Iteration:  62% 2003/3255 [48:24<32:36,  1.56s/it]\u001b[A\n","Iteration:  62% 2004/3255 [48:25<31:45,  1.52s/it]\u001b[A\n","Iteration:  62% 2005/3255 [48:27<31:02,  1.49s/it]\u001b[A\n","Iteration:  62% 2006/3255 [48:28<30:32,  1.47s/it]\u001b[A\n","Iteration:  62% 2007/3255 [48:29<30:15,  1.45s/it]\u001b[A\n","Iteration:  62% 2008/3255 [48:31<30:01,  1.44s/it]\u001b[A\n","Iteration:  62% 2009/3255 [48:32<29:54,  1.44s/it]\u001b[A\n","Iteration:  62% 2010/3255 [48:34<29:51,  1.44s/it]\u001b[A\n","Iteration:  62% 2011/3255 [48:35<29:42,  1.43s/it]\u001b[A\n","Iteration:  62% 2012/3255 [48:36<29:37,  1.43s/it]\u001b[A\n","Iteration:  62% 2013/3255 [48:38<29:29,  1.42s/it]\u001b[A\n","Iteration:  62% 2014/3255 [48:39<29:26,  1.42s/it]\u001b[A\n","Iteration:  62% 2015/3255 [48:41<29:17,  1.42s/it]\u001b[A\n","Iteration:  62% 2016/3255 [48:42<29:17,  1.42s/it]\u001b[A\n","Iteration:  62% 2017/3255 [48:44<29:14,  1.42s/it]\u001b[A\n","Iteration:  62% 2018/3255 [48:45<29:14,  1.42s/it]\u001b[A\n","Iteration:  62% 2019/3255 [48:46<29:15,  1.42s/it]\u001b[A\n","Iteration:  62% 2020/3255 [48:48<29:11,  1.42s/it]\u001b[A\n","Iteration:  62% 2021/3255 [48:49<29:14,  1.42s/it]\u001b[A\n","Iteration:  62% 2022/3255 [48:51<29:12,  1.42s/it]\u001b[A\n","Iteration:  62% 2023/3255 [48:52<29:12,  1.42s/it]\u001b[A\n","Iteration:  62% 2024/3255 [48:54<29:06,  1.42s/it]\u001b[A\n","Iteration:  62% 2025/3255 [48:55<29:04,  1.42s/it]\u001b[A\n","Iteration:  62% 2026/3255 [48:56<29:05,  1.42s/it]\u001b[A\n","Iteration:  62% 2027/3255 [48:58<29:05,  1.42s/it]\u001b[A\n","Iteration:  62% 2028/3255 [48:59<29:07,  1.42s/it]\u001b[A\n","Iteration:  62% 2029/3255 [49:01<29:02,  1.42s/it]\u001b[A\n","Iteration:  62% 2030/3255 [49:02<29:03,  1.42s/it]\u001b[A\n","Iteration:  62% 2031/3255 [49:03<29:10,  1.43s/it]\u001b[A\n","Iteration:  62% 2032/3255 [49:05<29:04,  1.43s/it]\u001b[A\n","Iteration:  62% 2033/3255 [49:06<29:03,  1.43s/it]\u001b[A\n","Iteration:  62% 2034/3255 [49:08<28:59,  1.42s/it]\u001b[A\n","Iteration:  63% 2035/3255 [49:09<28:58,  1.42s/it]\u001b[A\n","Iteration:  63% 2036/3255 [49:11<28:46,  1.42s/it]\u001b[A\n","Iteration:  63% 2037/3255 [49:12<28:50,  1.42s/it]\u001b[A\n","Iteration:  63% 2038/3255 [49:13<28:45,  1.42s/it]\u001b[A\n","Iteration:  63% 2039/3255 [49:15<28:44,  1.42s/it]\u001b[A\n","Iteration:  63% 2040/3255 [49:16<28:48,  1.42s/it]\u001b[A\n","Iteration:  63% 2041/3255 [49:18<28:41,  1.42s/it]\u001b[A\n","Iteration:  63% 2042/3255 [49:19<28:45,  1.42s/it]\u001b[A\n","Iteration:  63% 2043/3255 [49:21<28:43,  1.42s/it]\u001b[A\n","Iteration:  63% 2044/3255 [49:22<28:43,  1.42s/it]\u001b[A\n","Iteration:  63% 2045/3255 [49:23<28:41,  1.42s/it]\u001b[A\n","Iteration:  63% 2046/3255 [49:25<28:40,  1.42s/it]\u001b[A\n","Iteration:  63% 2047/3255 [49:26<28:37,  1.42s/it]\u001b[A\n","Iteration:  63% 2048/3255 [49:28<28:34,  1.42s/it]\u001b[A\n","Iteration:  63% 2049/3255 [49:29<28:35,  1.42s/it]\u001b[A11/26/2019 19:35:03 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-2050/config.json\n","11/26/2019 19:35:05 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-2050/pytorch_model.bin\n","11/26/2019 19:35:05 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-2050\n","\n","Iteration:  63% 2050/3255 [49:32<37:39,  1.87s/it]\u001b[A\n","Iteration:  63% 2051/3255 [49:33<34:31,  1.72s/it]\u001b[A\n","Iteration:  63% 2052/3255 [49:35<32:41,  1.63s/it]\u001b[A\n","Iteration:  63% 2053/3255 [49:36<31:24,  1.57s/it]\u001b[A\n","Iteration:  63% 2054/3255 [49:38<30:34,  1.53s/it]\u001b[A\n","Iteration:  63% 2055/3255 [49:39<30:01,  1.50s/it]\u001b[A\n","Iteration:  63% 2056/3255 [49:40<29:27,  1.47s/it]\u001b[A\n","Iteration:  63% 2057/3255 [49:42<29:05,  1.46s/it]\u001b[A\n","Iteration:  63% 2058/3255 [49:43<28:44,  1.44s/it]\u001b[A\n","Iteration:  63% 2059/3255 [49:45<28:32,  1.43s/it]\u001b[A\n","Iteration:  63% 2060/3255 [49:46<28:31,  1.43s/it]\u001b[A\n","Iteration:  63% 2061/3255 [49:48<28:23,  1.43s/it]\u001b[A\n","Iteration:  63% 2062/3255 [49:49<28:23,  1.43s/it]\u001b[A\n","Iteration:  63% 2063/3255 [49:50<28:21,  1.43s/it]\u001b[A\n","Iteration:  63% 2064/3255 [49:52<28:16,  1.42s/it]\u001b[A\n","Iteration:  63% 2065/3255 [49:53<28:18,  1.43s/it]\u001b[A\n","Iteration:  63% 2066/3255 [49:55<28:15,  1.43s/it]\u001b[A\n","Iteration:  64% 2067/3255 [49:56<28:17,  1.43s/it]\u001b[A\n","Iteration:  64% 2068/3255 [49:58<28:11,  1.43s/it]\u001b[A\n","Iteration:  64% 2069/3255 [49:59<28:04,  1.42s/it]\u001b[A\n","Iteration:  64% 2070/3255 [50:00<28:03,  1.42s/it]\u001b[A\n","Iteration:  64% 2071/3255 [50:02<28:03,  1.42s/it]\u001b[A\n","Iteration:  64% 2072/3255 [50:03<28:00,  1.42s/it]\u001b[A\n","Iteration:  64% 2073/3255 [50:05<27:59,  1.42s/it]\u001b[A\n","Iteration:  64% 2074/3255 [50:06<28:01,  1.42s/it]\u001b[A\n","Iteration:  64% 2075/3255 [50:07<27:57,  1.42s/it]\u001b[A\n","Iteration:  64% 2076/3255 [50:09<27:54,  1.42s/it]\u001b[A\n","Iteration:  64% 2077/3255 [50:10<27:56,  1.42s/it]\u001b[A\n","Iteration:  64% 2078/3255 [50:12<27:51,  1.42s/it]\u001b[A\n","Iteration:  64% 2079/3255 [50:13<27:56,  1.43s/it]\u001b[A\n","Iteration:  64% 2080/3255 [50:15<27:49,  1.42s/it]\u001b[A\n","Iteration:  64% 2081/3255 [50:16<27:51,  1.42s/it]\u001b[A\n","Iteration:  64% 2082/3255 [50:17<27:42,  1.42s/it]\u001b[A\n","Iteration:  64% 2083/3255 [50:19<27:44,  1.42s/it]\u001b[A\n","Iteration:  64% 2084/3255 [50:20<27:41,  1.42s/it]\u001b[A\n","Iteration:  64% 2085/3255 [50:22<27:44,  1.42s/it]\u001b[A\n","Iteration:  64% 2086/3255 [50:23<27:44,  1.42s/it]\u001b[A\n","Iteration:  64% 2087/3255 [50:25<27:43,  1.42s/it]\u001b[A\n","Iteration:  64% 2088/3255 [50:26<27:42,  1.42s/it]\u001b[A\n","Iteration:  64% 2089/3255 [50:27<27:40,  1.42s/it]\u001b[A\n","Iteration:  64% 2090/3255 [50:29<27:35,  1.42s/it]\u001b[A\n","Iteration:  64% 2091/3255 [50:30<27:35,  1.42s/it]\u001b[A\n","Iteration:  64% 2092/3255 [50:32<27:30,  1.42s/it]\u001b[A\n","Iteration:  64% 2093/3255 [50:33<27:28,  1.42s/it]\u001b[A\n","Iteration:  64% 2094/3255 [50:34<27:24,  1.42s/it]\u001b[A\n","Iteration:  64% 2095/3255 [50:36<27:22,  1.42s/it]\u001b[A\n","Iteration:  64% 2096/3255 [50:37<27:22,  1.42s/it]\u001b[A\n","Iteration:  64% 2097/3255 [50:39<27:18,  1.42s/it]\u001b[A\n","Iteration:  64% 2098/3255 [50:40<27:17,  1.42s/it]\u001b[A\n","Iteration:  64% 2099/3255 [50:42<27:17,  1.42s/it]\u001b[A11/26/2019 19:36:16 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-2100/config.json\n","11/26/2019 19:36:17 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-2100/pytorch_model.bin\n","11/26/2019 19:36:17 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-2100\n","\n","Iteration:  65% 2100/3255 [50:44<35:46,  1.86s/it]\u001b[A\n","Iteration:  65% 2101/3255 [50:46<32:58,  1.71s/it]\u001b[A\n","Iteration:  65% 2102/3255 [50:47<31:18,  1.63s/it]\u001b[A\n","Iteration:  65% 2103/3255 [50:49<29:59,  1.56s/it]\u001b[A\n","Iteration:  65% 2104/3255 [50:50<29:09,  1.52s/it]\u001b[A\n","Iteration:  65% 2105/3255 [50:52<28:31,  1.49s/it]\u001b[A\n","Iteration:  65% 2106/3255 [50:53<28:06,  1.47s/it]\u001b[A\n","Iteration:  65% 2107/3255 [50:54<27:46,  1.45s/it]\u001b[A\n","Iteration:  65% 2108/3255 [50:56<27:31,  1.44s/it]\u001b[A\n","Iteration:  65% 2109/3255 [50:57<27:28,  1.44s/it]\u001b[A\n","Iteration:  65% 2110/3255 [50:59<27:17,  1.43s/it]\u001b[A\n","Iteration:  65% 2111/3255 [51:00<27:11,  1.43s/it]\u001b[A\n","Iteration:  65% 2112/3255 [51:01<27:05,  1.42s/it]\u001b[A\n","Iteration:  65% 2113/3255 [51:03<27:00,  1.42s/it]\u001b[A\n","Iteration:  65% 2114/3255 [51:04<26:57,  1.42s/it]\u001b[A\n","Iteration:  65% 2115/3255 [51:06<26:52,  1.41s/it]\u001b[A\n","Iteration:  65% 2116/3255 [51:07<26:48,  1.41s/it]\u001b[A\n","Iteration:  65% 2117/3255 [51:08<26:46,  1.41s/it]\u001b[A\n","Iteration:  65% 2118/3255 [51:10<26:50,  1.42s/it]\u001b[A\n","Iteration:  65% 2119/3255 [51:11<26:46,  1.41s/it]\u001b[A\n","Iteration:  65% 2120/3255 [51:13<26:48,  1.42s/it]\u001b[A\n","Iteration:  65% 2121/3255 [51:14<26:52,  1.42s/it]\u001b[A\n","Iteration:  65% 2122/3255 [51:16<26:43,  1.42s/it]\u001b[A\n","Iteration:  65% 2123/3255 [51:17<26:46,  1.42s/it]\u001b[A\n","Iteration:  65% 2124/3255 [51:18<26:42,  1.42s/it]\u001b[A\n","Iteration:  65% 2125/3255 [51:20<26:37,  1.41s/it]\u001b[A\n","Iteration:  65% 2126/3255 [51:21<26:37,  1.42s/it]\u001b[A\n","Iteration:  65% 2127/3255 [51:23<26:36,  1.42s/it]\u001b[A\n","Iteration:  65% 2128/3255 [51:24<26:33,  1.41s/it]\u001b[A\n","Iteration:  65% 2129/3255 [51:26<26:40,  1.42s/it]\u001b[A\n","Iteration:  65% 2130/3255 [51:27<26:39,  1.42s/it]\u001b[A\n","Iteration:  65% 2131/3255 [51:28<26:34,  1.42s/it]\u001b[A\n","Iteration:  65% 2132/3255 [51:30<26:37,  1.42s/it]\u001b[A\n","Iteration:  66% 2133/3255 [51:31<26:37,  1.42s/it]\u001b[A\n","Iteration:  66% 2134/3255 [51:33<26:29,  1.42s/it]\u001b[A\n","Iteration:  66% 2135/3255 [51:34<26:28,  1.42s/it]\u001b[A\n","Iteration:  66% 2136/3255 [51:35<26:29,  1.42s/it]\u001b[A\n","Iteration:  66% 2137/3255 [51:37<26:31,  1.42s/it]\u001b[A\n","Iteration:  66% 2138/3255 [51:38<26:24,  1.42s/it]\u001b[A\n","Iteration:  66% 2139/3255 [51:40<26:25,  1.42s/it]\u001b[A\n","Iteration:  66% 2140/3255 [51:41<26:24,  1.42s/it]\u001b[A\n","Iteration:  66% 2141/3255 [51:43<26:20,  1.42s/it]\u001b[A\n","Iteration:  66% 2142/3255 [51:44<26:24,  1.42s/it]\u001b[A\n","Iteration:  66% 2143/3255 [51:45<26:25,  1.43s/it]\u001b[A\n","Iteration:  66% 2144/3255 [51:47<26:21,  1.42s/it]\u001b[A\n","Iteration:  66% 2145/3255 [51:48<26:21,  1.43s/it]\u001b[A\n","Iteration:  66% 2146/3255 [51:50<26:17,  1.42s/it]\u001b[A\n","Iteration:  66% 2147/3255 [51:51<26:15,  1.42s/it]\u001b[A\n","Iteration:  66% 2148/3255 [51:53<26:11,  1.42s/it]\u001b[A\n","Iteration:  66% 2149/3255 [51:54<26:14,  1.42s/it]\u001b[A11/26/2019 19:37:28 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-2150/config.json\n","11/26/2019 19:37:30 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-2150/pytorch_model.bin\n","11/26/2019 19:37:30 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-2150\n","\n","Iteration:  66% 2150/3255 [51:57<34:32,  1.88s/it]\u001b[A\n","Iteration:  66% 2151/3255 [51:58<31:41,  1.72s/it]\u001b[A\n","Iteration:  66% 2152/3255 [52:00<29:57,  1.63s/it]\u001b[A\n","Iteration:  66% 2153/3255 [52:01<28:45,  1.57s/it]\u001b[A\n","Iteration:  66% 2154/3255 [52:02<27:59,  1.53s/it]\u001b[A\n","Iteration:  66% 2155/3255 [52:04<27:22,  1.49s/it]\u001b[A\n","Iteration:  66% 2156/3255 [52:05<26:53,  1.47s/it]\u001b[A\n","Iteration:  66% 2157/3255 [52:07<26:36,  1.45s/it]\u001b[A\n","Iteration:  66% 2158/3255 [52:08<26:24,  1.44s/it]\u001b[A\n","Iteration:  66% 2159/3255 [52:10<26:10,  1.43s/it]\u001b[A\n","Iteration:  66% 2160/3255 [52:11<26:07,  1.43s/it]\u001b[A\n","Iteration:  66% 2161/3255 [52:12<26:06,  1.43s/it]\u001b[A\n","Iteration:  66% 2162/3255 [52:14<26:06,  1.43s/it]\u001b[A\n","Iteration:  66% 2163/3255 [52:15<25:58,  1.43s/it]\u001b[A\n","Iteration:  66% 2164/3255 [52:17<25:49,  1.42s/it]\u001b[A\n","Iteration:  67% 2165/3255 [52:18<25:52,  1.42s/it]\u001b[A\n","Iteration:  67% 2166/3255 [52:20<25:47,  1.42s/it]\u001b[A\n","Iteration:  67% 2167/3255 [52:21<25:47,  1.42s/it]\u001b[A\n","Iteration:  67% 2168/3255 [52:22<25:46,  1.42s/it]\u001b[A\n","Iteration:  67% 2169/3255 [52:24<25:43,  1.42s/it]\u001b[A\n","Iteration:  67% 2170/3255 [52:25<25:41,  1.42s/it]\u001b[A\n","Iteration:  67% 2171/3255 [52:27<25:37,  1.42s/it]\u001b[A\n","Iteration:  67% 2172/3255 [52:28<25:40,  1.42s/it]\u001b[A\n","Iteration:  67% 2173/3255 [52:29<25:35,  1.42s/it]\u001b[A\n","Iteration:  67% 2174/3255 [52:31<25:37,  1.42s/it]\u001b[A\n","Iteration:  67% 2175/3255 [52:32<25:33,  1.42s/it]\u001b[A\n","Iteration:  67% 2176/3255 [52:34<25:33,  1.42s/it]\u001b[A\n","Iteration:  67% 2177/3255 [52:35<25:31,  1.42s/it]\u001b[A\n","Iteration:  67% 2178/3255 [52:37<25:29,  1.42s/it]\u001b[A\n","Iteration:  67% 2179/3255 [52:38<25:25,  1.42s/it]\u001b[A\n","Iteration:  67% 2180/3255 [52:39<25:21,  1.42s/it]\u001b[A\n","Iteration:  67% 2181/3255 [52:41<25:21,  1.42s/it]\u001b[A\n","Iteration:  67% 2182/3255 [52:42<25:24,  1.42s/it]\u001b[A\n","Iteration:  67% 2183/3255 [52:44<25:30,  1.43s/it]\u001b[A\n","Iteration:  67% 2184/3255 [52:45<25:23,  1.42s/it]\u001b[A\n","Iteration:  67% 2185/3255 [52:47<25:20,  1.42s/it]\u001b[A\n","Iteration:  67% 2186/3255 [52:48<25:20,  1.42s/it]\u001b[A\n","Iteration:  67% 2187/3255 [52:49<25:16,  1.42s/it]\u001b[A\n","Iteration:  67% 2188/3255 [52:51<25:20,  1.43s/it]\u001b[A\n","Iteration:  67% 2189/3255 [52:52<25:15,  1.42s/it]\u001b[A\n","Iteration:  67% 2190/3255 [52:54<25:17,  1.43s/it]\u001b[A\n","Iteration:  67% 2191/3255 [52:55<25:17,  1.43s/it]\u001b[A\n","Iteration:  67% 2192/3255 [52:56<25:11,  1.42s/it]\u001b[A\n","Iteration:  67% 2193/3255 [52:58<25:09,  1.42s/it]\u001b[A\n","Iteration:  67% 2194/3255 [52:59<25:13,  1.43s/it]\u001b[A\n","Iteration:  67% 2195/3255 [53:01<25:07,  1.42s/it]\u001b[A\n","Iteration:  67% 2196/3255 [53:02<25:02,  1.42s/it]\u001b[A\n","Iteration:  67% 2197/3255 [53:04<25:01,  1.42s/it]\u001b[A\n","Iteration:  68% 2198/3255 [53:05<24:58,  1.42s/it]\u001b[A\n","Iteration:  68% 2199/3255 [53:06<25:03,  1.42s/it]\u001b[A11/26/2019 19:38:41 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-2200/config.json\n","11/26/2019 19:38:42 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-2200/pytorch_model.bin\n","11/26/2019 19:38:42 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-2200\n","\n","Iteration:  68% 2200/3255 [53:09<33:00,  1.88s/it]\u001b[A\n","Iteration:  68% 2201/3255 [53:11<30:18,  1.73s/it]\u001b[A\n","Iteration:  68% 2202/3255 [53:12<28:40,  1.63s/it]\u001b[A\n","Iteration:  68% 2203/3255 [53:14<27:27,  1.57s/it]\u001b[A\n","Iteration:  68% 2204/3255 [53:15<26:45,  1.53s/it]\u001b[A\n","Iteration:  68% 2205/3255 [53:16<26:10,  1.50s/it]\u001b[A\n","Iteration:  68% 2206/3255 [53:18<25:48,  1.48s/it]\u001b[A\n","Iteration:  68% 2207/3255 [53:19<25:28,  1.46s/it]\u001b[A\n","Iteration:  68% 2208/3255 [53:21<25:18,  1.45s/it]\u001b[A\n","Iteration:  68% 2209/3255 [53:22<25:15,  1.45s/it]\u001b[A\n","Iteration:  68% 2210/3255 [53:24<25:02,  1.44s/it]\u001b[A\n","Iteration:  68% 2211/3255 [53:25<24:53,  1.43s/it]\u001b[A\n","Iteration:  68% 2212/3255 [53:26<24:50,  1.43s/it]\u001b[A\n","Iteration:  68% 2213/3255 [53:28<24:46,  1.43s/it]\u001b[A\n","Iteration:  68% 2214/3255 [53:29<24:44,  1.43s/it]\u001b[A\n","Iteration:  68% 2215/3255 [53:31<24:44,  1.43s/it]\u001b[A\n","Iteration:  68% 2216/3255 [53:32<24:41,  1.43s/it]\u001b[A\n","Iteration:  68% 2217/3255 [53:34<24:38,  1.42s/it]\u001b[A\n","Iteration:  68% 2218/3255 [53:35<24:37,  1.42s/it]\u001b[A\n","Iteration:  68% 2219/3255 [53:36<24:35,  1.42s/it]\u001b[A\n","Iteration:  68% 2220/3255 [53:38<24:31,  1.42s/it]\u001b[A\n","Iteration:  68% 2221/3255 [53:39<24:29,  1.42s/it]\u001b[A\n","Iteration:  68% 2222/3255 [53:41<24:30,  1.42s/it]\u001b[A\n","Iteration:  68% 2223/3255 [53:42<24:28,  1.42s/it]\u001b[A\n","Iteration:  68% 2224/3255 [53:43<24:24,  1.42s/it]\u001b[A\n","Iteration:  68% 2225/3255 [53:45<24:22,  1.42s/it]\u001b[A\n","Iteration:  68% 2226/3255 [53:46<24:20,  1.42s/it]\u001b[A\n","Iteration:  68% 2227/3255 [53:48<24:23,  1.42s/it]\u001b[A\n","Iteration:  68% 2228/3255 [53:49<24:20,  1.42s/it]\u001b[A\n","Iteration:  68% 2229/3255 [53:51<24:15,  1.42s/it]\u001b[A\n","Iteration:  69% 2230/3255 [53:52<24:12,  1.42s/it]\u001b[A\n","Iteration:  69% 2231/3255 [53:53<24:16,  1.42s/it]\u001b[A\n","Iteration:  69% 2232/3255 [53:55<24:11,  1.42s/it]\u001b[A\n","Iteration:  69% 2233/3255 [53:56<24:04,  1.41s/it]\u001b[A\n","Iteration:  69% 2234/3255 [53:58<24:05,  1.42s/it]\u001b[A\n","Iteration:  69% 2235/3255 [53:59<24:09,  1.42s/it]\u001b[A\n","Iteration:  69% 2236/3255 [54:01<24:08,  1.42s/it]\u001b[A\n","Iteration:  69% 2237/3255 [54:02<24:12,  1.43s/it]\u001b[A\n","Iteration:  69% 2238/3255 [54:03<24:09,  1.42s/it]\u001b[A\n","Iteration:  69% 2239/3255 [54:05<24:02,  1.42s/it]\u001b[A\n","Iteration:  69% 2240/3255 [54:06<24:02,  1.42s/it]\u001b[A\n","Iteration:  69% 2241/3255 [54:08<24:00,  1.42s/it]\u001b[A\n","Iteration:  69% 2242/3255 [54:09<23:56,  1.42s/it]\u001b[A\n","Iteration:  69% 2243/3255 [54:10<23:56,  1.42s/it]\u001b[A\n","Iteration:  69% 2244/3255 [54:12<23:59,  1.42s/it]\u001b[A\n","Iteration:  69% 2245/3255 [54:13<23:54,  1.42s/it]\u001b[A\n","Iteration:  69% 2246/3255 [54:15<23:55,  1.42s/it]\u001b[A\n","Iteration:  69% 2247/3255 [54:16<23:50,  1.42s/it]\u001b[A\n","Iteration:  69% 2248/3255 [54:18<23:52,  1.42s/it]\u001b[A\n","Iteration:  69% 2249/3255 [54:19<23:56,  1.43s/it]\u001b[A11/26/2019 19:39:53 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-2250/config.json\n","11/26/2019 19:39:55 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-2250/pytorch_model.bin\n","11/26/2019 19:39:55 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-2250\n","\n","Iteration:  69% 2250/3255 [54:22<31:05,  1.86s/it]\u001b[A\n","Iteration:  69% 2251/3255 [54:23<28:38,  1.71s/it]\u001b[A\n","Iteration:  69% 2252/3255 [54:25<27:06,  1.62s/it]\u001b[A\n","Iteration:  69% 2253/3255 [54:26<26:06,  1.56s/it]\u001b[A\n","Iteration:  69% 2254/3255 [54:28<25:22,  1.52s/it]\u001b[A\n","Iteration:  69% 2255/3255 [54:29<24:53,  1.49s/it]\u001b[A\n","Iteration:  69% 2256/3255 [54:30<24:33,  1.48s/it]\u001b[A\n","Iteration:  69% 2257/3255 [54:32<24:14,  1.46s/it]\u001b[A\n","Iteration:  69% 2258/3255 [54:33<24:01,  1.45s/it]\u001b[A\n","Iteration:  69% 2259/3255 [54:35<23:52,  1.44s/it]\u001b[A\n","Iteration:  69% 2260/3255 [54:36<23:46,  1.43s/it]\u001b[A\n","Iteration:  69% 2261/3255 [54:37<23:38,  1.43s/it]\u001b[A\n","Iteration:  69% 2262/3255 [54:39<23:38,  1.43s/it]\u001b[A\n","Iteration:  70% 2263/3255 [54:40<23:32,  1.42s/it]\u001b[A\n","Iteration:  70% 2264/3255 [54:42<23:27,  1.42s/it]\u001b[A\n","Iteration:  70% 2265/3255 [54:43<23:30,  1.42s/it]\u001b[A\n","Iteration:  70% 2266/3255 [54:45<23:25,  1.42s/it]\u001b[A\n","Iteration:  70% 2267/3255 [54:46<23:23,  1.42s/it]\u001b[A\n","Iteration:  70% 2268/3255 [54:47<23:22,  1.42s/it]\u001b[A\n","Iteration:  70% 2269/3255 [54:49<23:19,  1.42s/it]\u001b[A\n","Iteration:  70% 2270/3255 [54:50<23:23,  1.43s/it]\u001b[A\n","Iteration:  70% 2271/3255 [54:52<23:19,  1.42s/it]\u001b[A\n","Iteration:  70% 2272/3255 [54:53<23:11,  1.42s/it]\u001b[A\n","Iteration:  70% 2273/3255 [54:55<23:13,  1.42s/it]\u001b[A\n","Iteration:  70% 2274/3255 [54:56<23:11,  1.42s/it]\u001b[A\n","Iteration:  70% 2275/3255 [54:57<23:15,  1.42s/it]\u001b[A\n","Iteration:  70% 2276/3255 [54:59<23:13,  1.42s/it]\u001b[A\n","Iteration:  70% 2277/3255 [55:00<23:13,  1.42s/it]\u001b[A\n","Iteration:  70% 2278/3255 [55:02<23:13,  1.43s/it]\u001b[A\n","Iteration:  70% 2279/3255 [55:03<23:10,  1.43s/it]\u001b[A\n","Iteration:  70% 2280/3255 [55:04<23:06,  1.42s/it]\u001b[A\n","Iteration:  70% 2281/3255 [55:06<23:07,  1.42s/it]\u001b[A\n","Iteration:  70% 2282/3255 [55:07<23:02,  1.42s/it]\u001b[A\n","Iteration:  70% 2283/3255 [55:09<22:57,  1.42s/it]\u001b[A\n","Iteration:  70% 2284/3255 [55:10<22:56,  1.42s/it]\u001b[A\n","Iteration:  70% 2285/3255 [55:12<22:55,  1.42s/it]\u001b[A\n","Iteration:  70% 2286/3255 [55:13<22:52,  1.42s/it]\u001b[A\n","Iteration:  70% 2287/3255 [55:14<22:55,  1.42s/it]\u001b[A\n","Iteration:  70% 2288/3255 [55:16<22:54,  1.42s/it]\u001b[A\n","Iteration:  70% 2289/3255 [55:17<22:54,  1.42s/it]\u001b[A\n","Iteration:  70% 2290/3255 [55:19<22:49,  1.42s/it]\u001b[A\n","Iteration:  70% 2291/3255 [55:20<22:53,  1.43s/it]\u001b[A\n","Iteration:  70% 2292/3255 [55:22<22:51,  1.42s/it]\u001b[A\n","Iteration:  70% 2293/3255 [55:23<22:43,  1.42s/it]\u001b[A\n","Iteration:  70% 2294/3255 [55:24<22:43,  1.42s/it]\u001b[A\n","Iteration:  71% 2295/3255 [55:26<22:46,  1.42s/it]\u001b[A\n","Iteration:  71% 2296/3255 [55:27<22:44,  1.42s/it]\u001b[A\n","Iteration:  71% 2297/3255 [55:29<22:42,  1.42s/it]\u001b[A\n","Iteration:  71% 2298/3255 [55:30<22:41,  1.42s/it]\u001b[A\n","Iteration:  71% 2299/3255 [55:31<22:35,  1.42s/it]\u001b[A11/26/2019 19:41:06 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-2300/config.json\n","11/26/2019 19:41:07 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-2300/pytorch_model.bin\n","11/26/2019 19:41:07 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-2300\n","\n","Iteration:  71% 2300/3255 [55:34<29:38,  1.86s/it]\u001b[A\n","Iteration:  71% 2301/3255 [55:36<27:17,  1.72s/it]\u001b[A\n","Iteration:  71% 2302/3255 [55:37<25:56,  1.63s/it]\u001b[A\n","Iteration:  71% 2303/3255 [55:39<24:49,  1.56s/it]\u001b[A\n","Iteration:  71% 2304/3255 [55:40<24:06,  1.52s/it]\u001b[A\n","Iteration:  71% 2305/3255 [55:41<23:40,  1.50s/it]\u001b[A\n","Iteration:  71% 2306/3255 [55:43<23:21,  1.48s/it]\u001b[A\n","Iteration:  71% 2307/3255 [55:44<23:04,  1.46s/it]\u001b[A\n","Iteration:  71% 2308/3255 [55:46<22:46,  1.44s/it]\u001b[A\n","Iteration:  71% 2309/3255 [55:47<22:40,  1.44s/it]\u001b[A\n","Iteration:  71% 2310/3255 [55:49<22:33,  1.43s/it]\u001b[A\n","Iteration:  71% 2311/3255 [55:50<22:21,  1.42s/it]\u001b[A\n","Iteration:  71% 2312/3255 [55:51<22:24,  1.43s/it]\u001b[A\n","Iteration:  71% 2313/3255 [55:53<22:17,  1.42s/it]\u001b[A\n","Iteration:  71% 2314/3255 [55:54<22:17,  1.42s/it]\u001b[A\n","Iteration:  71% 2315/3255 [55:56<22:17,  1.42s/it]\u001b[A\n","Iteration:  71% 2316/3255 [55:57<22:11,  1.42s/it]\u001b[A\n","Iteration:  71% 2317/3255 [55:58<22:14,  1.42s/it]\u001b[A\n","Iteration:  71% 2318/3255 [56:00<22:12,  1.42s/it]\u001b[A\n","Iteration:  71% 2319/3255 [56:01<22:13,  1.42s/it]\u001b[A\n","Iteration:  71% 2320/3255 [56:03<22:09,  1.42s/it]\u001b[A\n","Iteration:  71% 2321/3255 [56:04<22:12,  1.43s/it]\u001b[A\n","Iteration:  71% 2322/3255 [56:06<22:05,  1.42s/it]\u001b[A\n","Iteration:  71% 2323/3255 [56:07<22:02,  1.42s/it]\u001b[A\n","Iteration:  71% 2324/3255 [56:08<22:00,  1.42s/it]\u001b[A\n","Iteration:  71% 2325/3255 [56:10<21:59,  1.42s/it]\u001b[A\n","Iteration:  71% 2326/3255 [56:11<21:59,  1.42s/it]\u001b[A\n","Iteration:  71% 2327/3255 [56:13<21:54,  1.42s/it]\u001b[A\n","Iteration:  72% 2328/3255 [56:14<21:55,  1.42s/it]\u001b[A\n","Iteration:  72% 2329/3255 [56:16<21:53,  1.42s/it]\u001b[A\n","Iteration:  72% 2330/3255 [56:17<21:55,  1.42s/it]\u001b[A\n","Iteration:  72% 2331/3255 [56:18<21:53,  1.42s/it]\u001b[A\n","Iteration:  72% 2332/3255 [56:20<21:49,  1.42s/it]\u001b[A\n","Iteration:  72% 2333/3255 [56:21<21:43,  1.41s/it]\u001b[A\n","Iteration:  72% 2334/3255 [56:23<21:45,  1.42s/it]\u001b[A\n","Iteration:  72% 2335/3255 [56:24<21:41,  1.41s/it]\u001b[A\n","Iteration:  72% 2336/3255 [56:25<21:42,  1.42s/it]\u001b[A\n","Iteration:  72% 2337/3255 [56:27<21:40,  1.42s/it]\u001b[A\n","Iteration:  72% 2338/3255 [56:28<21:41,  1.42s/it]\u001b[A\n","Iteration:  72% 2339/3255 [56:30<21:41,  1.42s/it]\u001b[A\n","Iteration:  72% 2340/3255 [56:31<21:40,  1.42s/it]\u001b[A\n","Iteration:  72% 2341/3255 [56:33<21:37,  1.42s/it]\u001b[A\n","Iteration:  72% 2342/3255 [56:34<21:35,  1.42s/it]\u001b[A\n","Iteration:  72% 2343/3255 [56:35<21:36,  1.42s/it]\u001b[A\n","Iteration:  72% 2344/3255 [56:37<21:33,  1.42s/it]\u001b[A\n","Iteration:  72% 2345/3255 [56:38<21:32,  1.42s/it]\u001b[A\n","Iteration:  72% 2346/3255 [56:40<21:37,  1.43s/it]\u001b[A\n","Iteration:  72% 2347/3255 [56:41<21:27,  1.42s/it]\u001b[A\n","Iteration:  72% 2348/3255 [56:42<21:25,  1.42s/it]\u001b[A\n","Iteration:  72% 2349/3255 [56:44<21:22,  1.42s/it]\u001b[A11/26/2019 19:42:18 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-2350/config.json\n","11/26/2019 19:42:20 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-2350/pytorch_model.bin\n","11/26/2019 19:42:20 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-2350\n","\n","Iteration:  72% 2350/3255 [56:47<27:58,  1.86s/it]\u001b[A\n","Iteration:  72% 2351/3255 [56:48<25:46,  1.71s/it]\u001b[A\n","Iteration:  72% 2352/3255 [56:50<24:23,  1.62s/it]\u001b[A\n","Iteration:  72% 2353/3255 [56:51<23:28,  1.56s/it]\u001b[A\n","Iteration:  72% 2354/3255 [56:52<22:51,  1.52s/it]\u001b[A\n","Iteration:  72% 2355/3255 [56:54<22:16,  1.49s/it]\u001b[A\n","Iteration:  72% 2356/3255 [56:55<22:00,  1.47s/it]\u001b[A\n","Iteration:  72% 2357/3255 [56:57<21:40,  1.45s/it]\u001b[A\n","Iteration:  72% 2358/3255 [56:58<21:27,  1.44s/it]\u001b[A\n","Iteration:  72% 2359/3255 [56:59<21:21,  1.43s/it]\u001b[A\n","Iteration:  73% 2360/3255 [57:01<21:14,  1.42s/it]\u001b[A\n","Iteration:  73% 2361/3255 [57:02<21:13,  1.42s/it]\u001b[A\n","Iteration:  73% 2362/3255 [57:04<21:10,  1.42s/it]\u001b[A\n","Iteration:  73% 2363/3255 [57:05<21:08,  1.42s/it]\u001b[A\n","Iteration:  73% 2364/3255 [57:07<21:08,  1.42s/it]\u001b[A\n","Iteration:  73% 2365/3255 [57:08<21:06,  1.42s/it]\u001b[A\n","Iteration:  73% 2366/3255 [57:09<21:04,  1.42s/it]\u001b[A\n","Iteration:  73% 2367/3255 [57:11<21:01,  1.42s/it]\u001b[A\n","Iteration:  73% 2368/3255 [57:12<21:02,  1.42s/it]\u001b[A\n","Iteration:  73% 2369/3255 [57:14<21:03,  1.43s/it]\u001b[A\n","Iteration:  73% 2370/3255 [57:15<20:57,  1.42s/it]\u001b[A\n","Iteration:  73% 2371/3255 [57:17<21:00,  1.43s/it]\u001b[A\n","Iteration:  73% 2372/3255 [57:18<20:53,  1.42s/it]\u001b[A\n","Iteration:  73% 2373/3255 [57:19<20:49,  1.42s/it]\u001b[A\n","Iteration:  73% 2374/3255 [57:21<20:47,  1.42s/it]\u001b[A\n","Iteration:  73% 2375/3255 [57:22<20:45,  1.41s/it]\u001b[A\n","Iteration:  73% 2376/3255 [57:24<20:47,  1.42s/it]\u001b[A\n","Iteration:  73% 2377/3255 [57:25<20:48,  1.42s/it]\u001b[A\n","Iteration:  73% 2378/3255 [57:26<20:45,  1.42s/it]\u001b[A\n","Iteration:  73% 2379/3255 [57:28<20:43,  1.42s/it]\u001b[A\n","Iteration:  73% 2380/3255 [57:29<20:45,  1.42s/it]\u001b[A\n","Iteration:  73% 2381/3255 [57:31<20:44,  1.42s/it]\u001b[A\n","Iteration:  73% 2382/3255 [57:32<20:47,  1.43s/it]\u001b[A\n","Iteration:  73% 2383/3255 [57:34<20:39,  1.42s/it]\u001b[A\n","Iteration:  73% 2384/3255 [57:35<20:38,  1.42s/it]\u001b[A\n","Iteration:  73% 2385/3255 [57:36<20:38,  1.42s/it]\u001b[A\n","Iteration:  73% 2386/3255 [57:38<20:32,  1.42s/it]\u001b[A\n","Iteration:  73% 2387/3255 [57:39<20:28,  1.42s/it]\u001b[A\n","Iteration:  73% 2388/3255 [57:41<20:29,  1.42s/it]\u001b[A\n","Iteration:  73% 2389/3255 [57:42<20:32,  1.42s/it]\u001b[A\n","Iteration:  73% 2390/3255 [57:44<20:30,  1.42s/it]\u001b[A\n","Iteration:  73% 2391/3255 [57:45<20:31,  1.43s/it]\u001b[A\n","Iteration:  73% 2392/3255 [57:46<20:29,  1.43s/it]\u001b[A\n","Iteration:  74% 2393/3255 [57:48<20:27,  1.42s/it]\u001b[A\n","Iteration:  74% 2394/3255 [57:49<20:24,  1.42s/it]\u001b[A\n","Iteration:  74% 2395/3255 [57:51<20:24,  1.42s/it]\u001b[A\n","Iteration:  74% 2396/3255 [57:52<20:21,  1.42s/it]\u001b[A\n","Iteration:  74% 2397/3255 [57:53<20:20,  1.42s/it]\u001b[A\n","Iteration:  74% 2398/3255 [57:55<20:16,  1.42s/it]\u001b[A\n","Iteration:  74% 2399/3255 [57:56<20:14,  1.42s/it]\u001b[A11/26/2019 19:43:30 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-2400/config.json\n","11/26/2019 19:43:32 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-2400/pytorch_model.bin\n","11/26/2019 19:43:32 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-2400\n","\n","Iteration:  74% 2400/3255 [57:59<26:34,  1.87s/it]\u001b[A\n","Iteration:  74% 2401/3255 [58:01<24:28,  1.72s/it]\u001b[A\n","Iteration:  74% 2402/3255 [58:02<23:07,  1.63s/it]\u001b[A\n","Iteration:  74% 2403/3255 [58:03<22:12,  1.56s/it]\u001b[A\n","Iteration:  74% 2404/3255 [58:05<21:30,  1.52s/it]\u001b[A\n","Iteration:  74% 2405/3255 [58:06<21:03,  1.49s/it]\u001b[A\n","Iteration:  74% 2406/3255 [58:08<20:41,  1.46s/it]\u001b[A\n","Iteration:  74% 2407/3255 [58:09<20:31,  1.45s/it]\u001b[A\n","Iteration:  74% 2408/3255 [58:11<20:23,  1.44s/it]\u001b[A\n","Iteration:  74% 2409/3255 [58:12<20:12,  1.43s/it]\u001b[A\n","Iteration:  74% 2410/3255 [58:13<20:09,  1.43s/it]\u001b[A\n","Iteration:  74% 2411/3255 [58:15<20:08,  1.43s/it]\u001b[A\n","Iteration:  74% 2412/3255 [58:16<20:04,  1.43s/it]\u001b[A\n","Iteration:  74% 2413/3255 [58:18<20:04,  1.43s/it]\u001b[A\n","Iteration:  74% 2414/3255 [58:19<19:58,  1.43s/it]\u001b[A\n","Iteration:  74% 2415/3255 [58:20<19:54,  1.42s/it]\u001b[A\n","Iteration:  74% 2416/3255 [58:22<19:52,  1.42s/it]\u001b[A\n","Iteration:  74% 2417/3255 [58:23<19:54,  1.43s/it]\u001b[A\n","Iteration:  74% 2418/3255 [58:25<19:50,  1.42s/it]\u001b[A\n","Iteration:  74% 2419/3255 [58:26<19:51,  1.43s/it]\u001b[A\n","Iteration:  74% 2420/3255 [58:28<19:47,  1.42s/it]\u001b[A\n","Iteration:  74% 2421/3255 [58:29<19:42,  1.42s/it]\u001b[A\n","Iteration:  74% 2422/3255 [58:30<19:44,  1.42s/it]\u001b[A\n","Iteration:  74% 2423/3255 [58:32<19:42,  1.42s/it]\u001b[A\n","Iteration:  74% 2424/3255 [58:33<19:43,  1.42s/it]\u001b[A\n","Iteration:  75% 2425/3255 [58:35<19:42,  1.43s/it]\u001b[A\n","Iteration:  75% 2426/3255 [58:36<19:41,  1.42s/it]\u001b[A\n","Iteration:  75% 2427/3255 [58:38<19:37,  1.42s/it]\u001b[A\n","Iteration:  75% 2428/3255 [58:39<19:35,  1.42s/it]\u001b[A\n","Iteration:  75% 2429/3255 [58:40<19:33,  1.42s/it]\u001b[A\n","Iteration:  75% 2430/3255 [58:42<19:32,  1.42s/it]\u001b[A\n","Iteration:  75% 2431/3255 [58:43<19:34,  1.43s/it]\u001b[A\n","Iteration:  75% 2432/3255 [58:45<19:30,  1.42s/it]\u001b[A\n","Iteration:  75% 2433/3255 [58:46<19:27,  1.42s/it]\u001b[A\n","Iteration:  75% 2434/3255 [58:47<19:28,  1.42s/it]\u001b[A\n","Iteration:  75% 2435/3255 [58:49<19:26,  1.42s/it]\u001b[A\n","Iteration:  75% 2436/3255 [58:50<19:26,  1.42s/it]\u001b[A\n","Iteration:  75% 2437/3255 [58:52<19:22,  1.42s/it]\u001b[A\n","Iteration:  75% 2438/3255 [58:53<19:20,  1.42s/it]\u001b[A\n","Iteration:  75% 2439/3255 [58:55<19:18,  1.42s/it]\u001b[A\n","Iteration:  75% 2440/3255 [58:56<19:16,  1.42s/it]\u001b[A\n","Iteration:  75% 2441/3255 [58:57<19:16,  1.42s/it]\u001b[A\n","Iteration:  75% 2442/3255 [58:59<19:16,  1.42s/it]\u001b[A\n","Iteration:  75% 2443/3255 [59:00<19:16,  1.42s/it]\u001b[A\n","Iteration:  75% 2444/3255 [59:02<19:14,  1.42s/it]\u001b[A\n","Iteration:  75% 2445/3255 [59:03<19:13,  1.42s/it]\u001b[A\n","Iteration:  75% 2446/3255 [59:05<19:09,  1.42s/it]\u001b[A\n","Iteration:  75% 2447/3255 [59:06<19:09,  1.42s/it]\u001b[A\n","Iteration:  75% 2448/3255 [59:07<19:04,  1.42s/it]\u001b[A\n","Iteration:  75% 2449/3255 [59:09<19:04,  1.42s/it]\u001b[A11/26/2019 19:44:43 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-2450/config.json\n","11/26/2019 19:44:44 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-2450/pytorch_model.bin\n","11/26/2019 19:44:44 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-2450\n","\n","Iteration:  75% 2450/3255 [59:12<24:57,  1.86s/it]\u001b[A\n","Iteration:  75% 2451/3255 [59:13<22:54,  1.71s/it]\u001b[A\n","Iteration:  75% 2452/3255 [59:14<21:40,  1.62s/it]\u001b[A\n","Iteration:  75% 2453/3255 [59:16<20:49,  1.56s/it]\u001b[A\n","Iteration:  75% 2454/3255 [59:17<20:16,  1.52s/it]\u001b[A\n","Iteration:  75% 2455/3255 [59:19<19:47,  1.48s/it]\u001b[A\n","Iteration:  75% 2456/3255 [59:20<19:33,  1.47s/it]\u001b[A\n","Iteration:  75% 2457/3255 [59:22<19:20,  1.45s/it]\u001b[A\n","Iteration:  76% 2458/3255 [59:23<19:18,  1.45s/it]\u001b[A\n","Iteration:  76% 2459/3255 [59:24<19:08,  1.44s/it]\u001b[A\n","Iteration:  76% 2460/3255 [59:26<19:01,  1.44s/it]\u001b[A\n","Iteration:  76% 2461/3255 [59:27<18:55,  1.43s/it]\u001b[A\n","Iteration:  76% 2462/3255 [59:29<18:49,  1.42s/it]\u001b[A\n","Iteration:  76% 2463/3255 [59:30<18:47,  1.42s/it]\u001b[A\n","Iteration:  76% 2464/3255 [59:32<18:43,  1.42s/it]\u001b[A\n","Iteration:  76% 2465/3255 [59:33<18:40,  1.42s/it]\u001b[A\n","Iteration:  76% 2466/3255 [59:34<18:42,  1.42s/it]\u001b[A\n","Iteration:  76% 2467/3255 [59:36<18:40,  1.42s/it]\u001b[A\n","Iteration:  76% 2468/3255 [59:37<18:39,  1.42s/it]\u001b[A\n","Iteration:  76% 2469/3255 [59:39<18:36,  1.42s/it]\u001b[A\n","Iteration:  76% 2470/3255 [59:40<18:37,  1.42s/it]\u001b[A\n","Iteration:  76% 2471/3255 [59:41<18:39,  1.43s/it]\u001b[A\n","Iteration:  76% 2472/3255 [59:43<18:34,  1.42s/it]\u001b[A\n","Iteration:  76% 2473/3255 [59:44<18:34,  1.43s/it]\u001b[A\n","Iteration:  76% 2474/3255 [59:46<18:32,  1.42s/it]\u001b[A\n","Iteration:  76% 2475/3255 [59:47<18:31,  1.42s/it]\u001b[A\n","Iteration:  76% 2476/3255 [59:49<18:27,  1.42s/it]\u001b[A\n","Iteration:  76% 2477/3255 [59:50<18:23,  1.42s/it]\u001b[A\n","Iteration:  76% 2478/3255 [59:51<18:24,  1.42s/it]\u001b[A\n","Iteration:  76% 2479/3255 [59:53<18:23,  1.42s/it]\u001b[A\n","Iteration:  76% 2480/3255 [59:54<18:21,  1.42s/it]\u001b[A\n","Iteration:  76% 2481/3255 [59:56<18:17,  1.42s/it]\u001b[A\n","Iteration:  76% 2482/3255 [59:57<18:19,  1.42s/it]\u001b[A\n","Iteration:  76% 2483/3255 [59:59<18:18,  1.42s/it]\u001b[A\n","Iteration:  76% 2484/3255 [1:00:00<18:17,  1.42s/it]\u001b[A\n","Iteration:  76% 2485/3255 [1:00:01<18:16,  1.42s/it]\u001b[A\n","Iteration:  76% 2486/3255 [1:00:03<18:16,  1.43s/it]\u001b[A\n","Iteration:  76% 2487/3255 [1:00:04<18:16,  1.43s/it]\u001b[A\n","Iteration:  76% 2488/3255 [1:00:06<18:12,  1.42s/it]\u001b[A\n","Iteration:  76% 2489/3255 [1:00:07<18:12,  1.43s/it]\u001b[A\n","Iteration:  76% 2490/3255 [1:00:09<18:09,  1.42s/it]\u001b[A\n","Iteration:  77% 2491/3255 [1:00:10<18:07,  1.42s/it]\u001b[A\n","Iteration:  77% 2492/3255 [1:00:11<18:03,  1.42s/it]\u001b[A\n","Iteration:  77% 2493/3255 [1:00:13<17:58,  1.42s/it]\u001b[A\n","Iteration:  77% 2494/3255 [1:00:14<17:55,  1.41s/it]\u001b[A\n","Iteration:  77% 2495/3255 [1:00:16<17:57,  1.42s/it]\u001b[A\n","Iteration:  77% 2496/3255 [1:00:17<17:57,  1.42s/it]\u001b[A\n","Iteration:  77% 2497/3255 [1:00:18<17:59,  1.42s/it]\u001b[A\n","Iteration:  77% 2498/3255 [1:00:20<17:58,  1.42s/it]\u001b[A\n","Iteration:  77% 2499/3255 [1:00:21<17:57,  1.43s/it]\u001b[A11/26/2019 19:45:55 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-2500/config.json\n","11/26/2019 19:45:57 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-2500/pytorch_model.bin\n","11/26/2019 19:45:57 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-2500\n","\n","Iteration:  77% 2500/3255 [1:00:24<23:26,  1.86s/it]\u001b[A\n","Iteration:  77% 2501/3255 [1:00:26<21:32,  1.71s/it]\u001b[A\n","Iteration:  77% 2502/3255 [1:00:27<20:26,  1.63s/it]\u001b[A\n","Iteration:  77% 2503/3255 [1:00:28<19:37,  1.57s/it]\u001b[A\n","Iteration:  77% 2504/3255 [1:00:30<19:05,  1.53s/it]\u001b[A\n","Iteration:  77% 2505/3255 [1:00:31<18:37,  1.49s/it]\u001b[A\n","Iteration:  77% 2506/3255 [1:00:33<18:23,  1.47s/it]\u001b[A\n","Iteration:  77% 2507/3255 [1:00:34<18:15,  1.46s/it]\u001b[A\n","Iteration:  77% 2508/3255 [1:00:36<18:00,  1.45s/it]\u001b[A\n","Iteration:  77% 2509/3255 [1:00:37<17:50,  1.44s/it]\u001b[A\n","Iteration:  77% 2510/3255 [1:00:38<17:45,  1.43s/it]\u001b[A\n","Iteration:  77% 2511/3255 [1:00:40<17:38,  1.42s/it]\u001b[A\n","Iteration:  77% 2512/3255 [1:00:41<17:37,  1.42s/it]\u001b[A\n","Iteration:  77% 2513/3255 [1:00:43<17:37,  1.42s/it]\u001b[A\n","Iteration:  77% 2514/3255 [1:00:44<17:35,  1.42s/it]\u001b[A\n","Iteration:  77% 2515/3255 [1:00:45<17:33,  1.42s/it]\u001b[A\n","Iteration:  77% 2516/3255 [1:00:47<17:34,  1.43s/it]\u001b[A\n","Iteration:  77% 2517/3255 [1:00:48<17:30,  1.42s/it]\u001b[A\n","Iteration:  77% 2518/3255 [1:00:50<17:26,  1.42s/it]\u001b[A\n","Iteration:  77% 2519/3255 [1:00:51<17:28,  1.42s/it]\u001b[A\n","Iteration:  77% 2520/3255 [1:00:53<17:26,  1.42s/it]\u001b[A\n","Iteration:  77% 2521/3255 [1:00:54<17:22,  1.42s/it]\u001b[A\n","Iteration:  77% 2522/3255 [1:00:55<17:19,  1.42s/it]\u001b[A\n","Iteration:  78% 2523/3255 [1:00:57<17:19,  1.42s/it]\u001b[A\n","Iteration:  78% 2524/3255 [1:00:58<17:16,  1.42s/it]\u001b[A\n","Iteration:  78% 2525/3255 [1:01:00<17:14,  1.42s/it]\u001b[A\n","Iteration:  78% 2526/3255 [1:01:01<17:13,  1.42s/it]\u001b[A\n","Iteration:  78% 2527/3255 [1:01:03<17:15,  1.42s/it]\u001b[A\n","Iteration:  78% 2528/3255 [1:01:04<17:12,  1.42s/it]\u001b[A\n","Iteration:  78% 2529/3255 [1:01:05<17:11,  1.42s/it]\u001b[A\n","Iteration:  78% 2530/3255 [1:01:07<17:06,  1.42s/it]\u001b[A\n","Iteration:  78% 2531/3255 [1:01:08<17:06,  1.42s/it]\u001b[A\n","Iteration:  78% 2532/3255 [1:01:10<17:01,  1.41s/it]\u001b[A\n","Iteration:  78% 2533/3255 [1:01:11<17:04,  1.42s/it]\u001b[A\n","Iteration:  78% 2534/3255 [1:01:12<17:01,  1.42s/it]\u001b[A\n","Iteration:  78% 2535/3255 [1:01:14<17:00,  1.42s/it]\u001b[A\n","Iteration:  78% 2536/3255 [1:01:15<17:02,  1.42s/it]\u001b[A\n","Iteration:  78% 2537/3255 [1:01:17<17:01,  1.42s/it]\u001b[A\n","Iteration:  78% 2538/3255 [1:01:18<16:57,  1.42s/it]\u001b[A\n","Iteration:  78% 2539/3255 [1:01:20<16:56,  1.42s/it]\u001b[A\n","Iteration:  78% 2540/3255 [1:01:21<16:56,  1.42s/it]\u001b[A\n","Iteration:  78% 2541/3255 [1:01:22<16:56,  1.42s/it]\u001b[A\n","Iteration:  78% 2542/3255 [1:01:24<16:52,  1.42s/it]\u001b[A\n","Iteration:  78% 2543/3255 [1:01:25<16:51,  1.42s/it]\u001b[A\n","Iteration:  78% 2544/3255 [1:01:27<16:49,  1.42s/it]\u001b[A\n","Iteration:  78% 2545/3255 [1:01:28<16:49,  1.42s/it]\u001b[A\n","Iteration:  78% 2546/3255 [1:01:29<16:49,  1.42s/it]\u001b[A\n","Iteration:  78% 2547/3255 [1:01:31<16:48,  1.42s/it]\u001b[A\n","Iteration:  78% 2548/3255 [1:01:32<16:44,  1.42s/it]\u001b[A\n","Iteration:  78% 2549/3255 [1:01:34<16:41,  1.42s/it]\u001b[A11/26/2019 19:47:08 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-2550/config.json\n","11/26/2019 19:47:09 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-2550/pytorch_model.bin\n","11/26/2019 19:47:09 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-2550\n","\n","Iteration:  78% 2550/3255 [1:01:37<21:59,  1.87s/it]\u001b[A\n","Iteration:  78% 2551/3255 [1:01:38<20:10,  1.72s/it]\u001b[A\n","Iteration:  78% 2552/3255 [1:01:39<19:05,  1.63s/it]\u001b[A\n","Iteration:  78% 2553/3255 [1:01:41<18:18,  1.57s/it]\u001b[A\n","Iteration:  78% 2554/3255 [1:01:42<17:46,  1.52s/it]\u001b[A\n","Iteration:  78% 2555/3255 [1:01:44<17:24,  1.49s/it]\u001b[A\n","Iteration:  79% 2556/3255 [1:01:45<17:08,  1.47s/it]\u001b[A\n","Iteration:  79% 2557/3255 [1:01:47<16:56,  1.46s/it]\u001b[A\n","Iteration:  79% 2558/3255 [1:01:48<16:47,  1.45s/it]\u001b[A\n","Iteration:  79% 2559/3255 [1:01:49<16:41,  1.44s/it]\u001b[A\n","Iteration:  79% 2560/3255 [1:01:51<16:36,  1.43s/it]\u001b[A\n","Iteration:  79% 2561/3255 [1:01:52<16:28,  1.42s/it]\u001b[A\n","Iteration:  79% 2562/3255 [1:01:54<16:26,  1.42s/it]\u001b[A\n","Iteration:  79% 2563/3255 [1:01:55<16:25,  1.42s/it]\u001b[A\n","Iteration:  79% 2564/3255 [1:01:56<16:24,  1.42s/it]\u001b[A\n","Iteration:  79% 2565/3255 [1:01:58<16:21,  1.42s/it]\u001b[A\n","Iteration:  79% 2566/3255 [1:01:59<16:18,  1.42s/it]\u001b[A\n","Iteration:  79% 2567/3255 [1:02:01<16:19,  1.42s/it]\u001b[A\n","Iteration:  79% 2568/3255 [1:02:02<16:16,  1.42s/it]\u001b[A\n","Iteration:  79% 2569/3255 [1:02:04<16:12,  1.42s/it]\u001b[A\n","Iteration:  79% 2570/3255 [1:02:05<16:13,  1.42s/it]\u001b[A\n","Iteration:  79% 2571/3255 [1:02:06<16:13,  1.42s/it]\u001b[A\n","Iteration:  79% 2572/3255 [1:02:08<16:07,  1.42s/it]\u001b[A\n","Iteration:  79% 2573/3255 [1:02:09<16:08,  1.42s/it]\u001b[A\n","Iteration:  79% 2574/3255 [1:02:11<16:03,  1.41s/it]\u001b[A\n","Iteration:  79% 2575/3255 [1:02:12<15:59,  1.41s/it]\u001b[A\n","Iteration:  79% 2576/3255 [1:02:13<16:00,  1.41s/it]\u001b[A\n","Iteration:  79% 2577/3255 [1:02:15<15:58,  1.41s/it]\u001b[A\n","Iteration:  79% 2578/3255 [1:02:16<16:00,  1.42s/it]\u001b[A\n","Iteration:  79% 2579/3255 [1:02:18<15:59,  1.42s/it]\u001b[A\n","Iteration:  79% 2580/3255 [1:02:19<16:00,  1.42s/it]\u001b[A\n","Iteration:  79% 2581/3255 [1:02:21<15:57,  1.42s/it]\u001b[A\n","Iteration:  79% 2582/3255 [1:02:22<15:57,  1.42s/it]\u001b[A\n","Iteration:  79% 2583/3255 [1:02:23<15:55,  1.42s/it]\u001b[A\n","Iteration:  79% 2584/3255 [1:02:25<15:53,  1.42s/it]\u001b[A\n","Iteration:  79% 2585/3255 [1:02:26<15:55,  1.43s/it]\u001b[A\n","Iteration:  79% 2586/3255 [1:02:28<15:53,  1.42s/it]\u001b[A\n","Iteration:  79% 2587/3255 [1:02:29<15:48,  1.42s/it]\u001b[A\n","Iteration:  80% 2588/3255 [1:02:31<15:48,  1.42s/it]\u001b[A\n","Iteration:  80% 2589/3255 [1:02:32<15:47,  1.42s/it]\u001b[A\n","Iteration:  80% 2590/3255 [1:02:33<15:46,  1.42s/it]\u001b[A\n","Iteration:  80% 2591/3255 [1:02:35<15:47,  1.43s/it]\u001b[A\n","Iteration:  80% 2592/3255 [1:02:36<15:45,  1.43s/it]\u001b[A\n","Iteration:  80% 2593/3255 [1:02:38<15:42,  1.42s/it]\u001b[A\n","Iteration:  80% 2594/3255 [1:02:39<15:39,  1.42s/it]\u001b[A\n","Iteration:  80% 2595/3255 [1:02:41<15:37,  1.42s/it]\u001b[A\n","Iteration:  80% 2596/3255 [1:02:42<15:34,  1.42s/it]\u001b[A\n","Iteration:  80% 2597/3255 [1:02:43<15:32,  1.42s/it]\u001b[A\n","Iteration:  80% 2598/3255 [1:02:45<15:32,  1.42s/it]\u001b[A\n","Iteration:  80% 2599/3255 [1:02:46<15:32,  1.42s/it]\u001b[A11/26/2019 19:48:20 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-2600/config.json\n","11/26/2019 19:48:22 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-2600/pytorch_model.bin\n","11/26/2019 19:48:22 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-2600\n","\n","Iteration:  80% 2600/3255 [1:02:49<20:24,  1.87s/it]\u001b[A\n","Iteration:  80% 2601/3255 [1:02:50<18:46,  1.72s/it]\u001b[A\n","Iteration:  80% 2602/3255 [1:02:52<17:44,  1.63s/it]\u001b[A\n","Iteration:  80% 2603/3255 [1:02:53<17:03,  1.57s/it]\u001b[A\n","Iteration:  80% 2604/3255 [1:02:55<16:31,  1.52s/it]\u001b[A\n","Iteration:  80% 2605/3255 [1:02:56<16:11,  1.50s/it]\u001b[A\n","Iteration:  80% 2606/3255 [1:02:58<15:53,  1.47s/it]\u001b[A\n","Iteration:  80% 2607/3255 [1:02:59<15:44,  1.46s/it]\u001b[A\n","Iteration:  80% 2608/3255 [1:03:00<15:34,  1.44s/it]\u001b[A\n","Iteration:  80% 2609/3255 [1:03:02<15:27,  1.44s/it]\u001b[A\n","Iteration:  80% 2610/3255 [1:03:03<15:23,  1.43s/it]\u001b[A\n","Iteration:  80% 2611/3255 [1:03:05<15:18,  1.43s/it]\u001b[A\n","Iteration:  80% 2612/3255 [1:03:06<15:16,  1.43s/it]\u001b[A\n","Iteration:  80% 2613/3255 [1:03:08<15:13,  1.42s/it]\u001b[A\n","Iteration:  80% 2614/3255 [1:03:09<15:11,  1.42s/it]\u001b[A\n","Iteration:  80% 2615/3255 [1:03:10<15:10,  1.42s/it]\u001b[A\n","Iteration:  80% 2616/3255 [1:03:12<15:08,  1.42s/it]\u001b[A\n","Iteration:  80% 2617/3255 [1:03:13<15:08,  1.42s/it]\u001b[A\n","Iteration:  80% 2618/3255 [1:03:15<15:07,  1.42s/it]\u001b[A\n","Iteration:  80% 2619/3255 [1:03:16<15:04,  1.42s/it]\u001b[A\n","Iteration:  80% 2620/3255 [1:03:17<15:02,  1.42s/it]\u001b[A\n","Iteration:  81% 2621/3255 [1:03:19<15:01,  1.42s/it]\u001b[A\n","Iteration:  81% 2622/3255 [1:03:20<15:02,  1.43s/it]\u001b[A\n","Iteration:  81% 2623/3255 [1:03:22<15:00,  1.42s/it]\u001b[A\n","Iteration:  81% 2624/3255 [1:03:23<14:59,  1.43s/it]\u001b[A\n","Iteration:  81% 2625/3255 [1:03:25<14:54,  1.42s/it]\u001b[A\n","Iteration:  81% 2626/3255 [1:03:26<14:51,  1.42s/it]\u001b[A\n","Iteration:  81% 2627/3255 [1:03:27<14:51,  1.42s/it]\u001b[A\n","Iteration:  81% 2628/3255 [1:03:29<14:48,  1.42s/it]\u001b[A\n","Iteration:  81% 2629/3255 [1:03:30<14:47,  1.42s/it]\u001b[A\n","Iteration:  81% 2630/3255 [1:03:32<14:45,  1.42s/it]\u001b[A\n","Iteration:  81% 2631/3255 [1:03:33<14:45,  1.42s/it]\u001b[A\n","Iteration:  81% 2632/3255 [1:03:35<14:41,  1.42s/it]\u001b[A\n","Iteration:  81% 2633/3255 [1:03:36<14:40,  1.42s/it]\u001b[A\n","Iteration:  81% 2634/3255 [1:03:37<14:41,  1.42s/it]\u001b[A\n","Iteration:  81% 2635/3255 [1:03:39<14:39,  1.42s/it]\u001b[A\n","Iteration:  81% 2636/3255 [1:03:40<14:38,  1.42s/it]\u001b[A\n","Iteration:  81% 2637/3255 [1:03:42<14:36,  1.42s/it]\u001b[A\n","Iteration:  81% 2638/3255 [1:03:43<14:33,  1.42s/it]\u001b[A\n","Iteration:  81% 2639/3255 [1:03:44<14:36,  1.42s/it]\u001b[A\n","Iteration:  81% 2640/3255 [1:03:46<14:35,  1.42s/it]\u001b[A\n","Iteration:  81% 2641/3255 [1:03:47<14:32,  1.42s/it]\u001b[A\n","Iteration:  81% 2642/3255 [1:03:49<14:29,  1.42s/it]\u001b[A\n","Iteration:  81% 2643/3255 [1:03:50<14:29,  1.42s/it]\u001b[A\n","Iteration:  81% 2644/3255 [1:03:52<14:27,  1.42s/it]\u001b[A\n","Iteration:  81% 2645/3255 [1:03:53<14:29,  1.43s/it]\u001b[A\n","Iteration:  81% 2646/3255 [1:03:54<14:26,  1.42s/it]\u001b[A\n","Iteration:  81% 2647/3255 [1:03:56<14:24,  1.42s/it]\u001b[A\n","Iteration:  81% 2648/3255 [1:03:57<14:24,  1.42s/it]\u001b[A\n","Iteration:  81% 2649/3255 [1:03:59<14:20,  1.42s/it]\u001b[A11/26/2019 19:49:33 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-2650/config.json\n","11/26/2019 19:49:34 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-2650/pytorch_model.bin\n","11/26/2019 19:49:34 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-2650\n","\n","Iteration:  81% 2650/3255 [1:04:02<18:56,  1.88s/it]\u001b[A\n","Iteration:  81% 2651/3255 [1:04:03<17:23,  1.73s/it]\u001b[A\n","Iteration:  81% 2652/3255 [1:04:04<16:28,  1.64s/it]\u001b[A\n","Iteration:  82% 2653/3255 [1:04:06<15:47,  1.57s/it]\u001b[A\n","Iteration:  82% 2654/3255 [1:04:07<15:17,  1.53s/it]\u001b[A\n","Iteration:  82% 2655/3255 [1:04:09<14:55,  1.49s/it]\u001b[A\n","Iteration:  82% 2656/3255 [1:04:10<14:40,  1.47s/it]\u001b[A\n","Iteration:  82% 2657/3255 [1:04:12<14:29,  1.45s/it]\u001b[A\n","Iteration:  82% 2658/3255 [1:04:13<14:22,  1.44s/it]\u001b[A\n","Iteration:  82% 2659/3255 [1:04:14<14:17,  1.44s/it]\u001b[A\n","Iteration:  82% 2660/3255 [1:04:16<14:12,  1.43s/it]\u001b[A\n","Iteration:  82% 2661/3255 [1:04:17<14:11,  1.43s/it]\u001b[A\n","Iteration:  82% 2662/3255 [1:04:19<14:05,  1.43s/it]\u001b[A\n","Iteration:  82% 2663/3255 [1:04:20<14:04,  1.43s/it]\u001b[A\n","Iteration:  82% 2664/3255 [1:04:21<14:00,  1.42s/it]\u001b[A\n","Iteration:  82% 2665/3255 [1:04:23<13:59,  1.42s/it]\u001b[A\n","Iteration:  82% 2666/3255 [1:04:24<13:58,  1.42s/it]\u001b[A\n","Iteration:  82% 2667/3255 [1:04:26<13:58,  1.43s/it]\u001b[A\n","Iteration:  82% 2668/3255 [1:04:27<13:56,  1.42s/it]\u001b[A\n","Iteration:  82% 2669/3255 [1:04:29<13:51,  1.42s/it]\u001b[A\n","Iteration:  82% 2670/3255 [1:04:30<13:52,  1.42s/it]\u001b[A\n","Iteration:  82% 2671/3255 [1:04:31<13:49,  1.42s/it]\u001b[A\n","Iteration:  82% 2672/3255 [1:04:33<13:45,  1.42s/it]\u001b[A\n","Iteration:  82% 2673/3255 [1:04:34<13:45,  1.42s/it]\u001b[A\n","Iteration:  82% 2674/3255 [1:04:36<13:46,  1.42s/it]\u001b[A\n","Iteration:  82% 2675/3255 [1:04:37<13:45,  1.42s/it]\u001b[A\n","Iteration:  82% 2676/3255 [1:04:39<13:43,  1.42s/it]\u001b[A\n","Iteration:  82% 2677/3255 [1:04:40<13:40,  1.42s/it]\u001b[A\n","Iteration:  82% 2678/3255 [1:04:41<13:36,  1.42s/it]\u001b[A\n","Iteration:  82% 2679/3255 [1:04:43<13:36,  1.42s/it]\u001b[A\n","Iteration:  82% 2680/3255 [1:04:44<13:35,  1.42s/it]\u001b[A\n","Iteration:  82% 2681/3255 [1:04:46<13:33,  1.42s/it]\u001b[A\n","Iteration:  82% 2682/3255 [1:04:47<13:34,  1.42s/it]\u001b[A\n","Iteration:  82% 2683/3255 [1:04:48<13:31,  1.42s/it]\u001b[A\n","Iteration:  82% 2684/3255 [1:04:50<13:30,  1.42s/it]\u001b[A\n","Iteration:  82% 2685/3255 [1:04:51<13:30,  1.42s/it]\u001b[A\n","Iteration:  83% 2686/3255 [1:04:53<13:26,  1.42s/it]\u001b[A\n","Iteration:  83% 2687/3255 [1:04:54<13:28,  1.42s/it]\u001b[A\n","Iteration:  83% 2688/3255 [1:04:56<13:24,  1.42s/it]\u001b[A\n","Iteration:  83% 2689/3255 [1:04:57<13:26,  1.42s/it]\u001b[A\n","Iteration:  83% 2690/3255 [1:04:58<13:23,  1.42s/it]\u001b[A\n","Iteration:  83% 2691/3255 [1:05:00<13:20,  1.42s/it]\u001b[A\n","Iteration:  83% 2692/3255 [1:05:01<13:18,  1.42s/it]\u001b[A\n","Iteration:  83% 2693/3255 [1:05:03<13:15,  1.42s/it]\u001b[A\n","Iteration:  83% 2694/3255 [1:05:04<13:17,  1.42s/it]\u001b[A\n","Iteration:  83% 2695/3255 [1:05:05<13:14,  1.42s/it]\u001b[A\n","Iteration:  83% 2696/3255 [1:05:07<13:13,  1.42s/it]\u001b[A\n","Iteration:  83% 2697/3255 [1:05:08<13:12,  1.42s/it]\u001b[A\n","Iteration:  83% 2698/3255 [1:05:10<13:15,  1.43s/it]\u001b[A\n","Iteration:  83% 2699/3255 [1:05:11<13:09,  1.42s/it]\u001b[A11/26/2019 19:50:45 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-2700/config.json\n","11/26/2019 19:50:47 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-2700/pytorch_model.bin\n","11/26/2019 19:50:47 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-2700\n","\n","Iteration:  83% 2700/3255 [1:05:14<17:23,  1.88s/it]\u001b[A\n","Iteration:  83% 2701/3255 [1:05:15<15:56,  1.73s/it]\u001b[A\n","Iteration:  83% 2702/3255 [1:05:17<15:03,  1.63s/it]\u001b[A\n","Iteration:  83% 2703/3255 [1:05:18<14:27,  1.57s/it]\u001b[A\n","Iteration:  83% 2704/3255 [1:05:20<14:03,  1.53s/it]\u001b[A\n","Iteration:  83% 2705/3255 [1:05:21<13:42,  1.49s/it]\u001b[A\n","Iteration:  83% 2706/3255 [1:05:23<13:30,  1.48s/it]\u001b[A\n","Iteration:  83% 2707/3255 [1:05:24<13:21,  1.46s/it]\u001b[A\n","Iteration:  83% 2708/3255 [1:05:25<13:13,  1.45s/it]\u001b[A\n","Iteration:  83% 2709/3255 [1:05:27<13:09,  1.45s/it]\u001b[A\n","Iteration:  83% 2710/3255 [1:05:28<13:04,  1.44s/it]\u001b[A\n","Iteration:  83% 2711/3255 [1:05:30<13:00,  1.43s/it]\u001b[A\n","Iteration:  83% 2712/3255 [1:05:31<12:56,  1.43s/it]\u001b[A\n","Iteration:  83% 2713/3255 [1:05:33<12:54,  1.43s/it]\u001b[A\n","Iteration:  83% 2714/3255 [1:05:34<12:52,  1.43s/it]\u001b[A\n","Iteration:  83% 2715/3255 [1:05:35<12:49,  1.42s/it]\u001b[A\n","Iteration:  83% 2716/3255 [1:05:37<12:49,  1.43s/it]\u001b[A\n","Iteration:  83% 2717/3255 [1:05:38<12:46,  1.42s/it]\u001b[A\n","Iteration:  84% 2718/3255 [1:05:40<12:43,  1.42s/it]\u001b[A\n","Iteration:  84% 2719/3255 [1:05:41<12:44,  1.43s/it]\u001b[A\n","Iteration:  84% 2720/3255 [1:05:43<12:40,  1.42s/it]\u001b[A\n","Iteration:  84% 2721/3255 [1:05:44<12:39,  1.42s/it]\u001b[A\n","Iteration:  84% 2722/3255 [1:05:45<12:41,  1.43s/it]\u001b[A\n","Iteration:  84% 2723/3255 [1:05:47<12:35,  1.42s/it]\u001b[A\n","Iteration:  84% 2724/3255 [1:05:48<12:35,  1.42s/it]\u001b[A\n","Iteration:  84% 2725/3255 [1:05:50<12:35,  1.43s/it]\u001b[A\n","Iteration:  84% 2726/3255 [1:05:51<12:32,  1.42s/it]\u001b[A\n","Iteration:  84% 2727/3255 [1:05:53<12:32,  1.43s/it]\u001b[A\n","Iteration:  84% 2728/3255 [1:05:54<12:30,  1.42s/it]\u001b[A\n","Iteration:  84% 2729/3255 [1:05:55<12:27,  1.42s/it]\u001b[A\n","Iteration:  84% 2730/3255 [1:05:57<12:26,  1.42s/it]\u001b[A\n","Iteration:  84% 2731/3255 [1:05:58<12:25,  1.42s/it]\u001b[A\n","Iteration:  84% 2732/3255 [1:06:00<12:24,  1.42s/it]\u001b[A\n","Iteration:  84% 2733/3255 [1:06:01<12:22,  1.42s/it]\u001b[A\n","Iteration:  84% 2734/3255 [1:06:03<12:23,  1.43s/it]\u001b[A\n","Iteration:  84% 2735/3255 [1:06:04<12:18,  1.42s/it]\u001b[A\n","Iteration:  84% 2736/3255 [1:06:05<12:18,  1.42s/it]\u001b[A\n","Iteration:  84% 2737/3255 [1:06:07<12:15,  1.42s/it]\u001b[A\n","Iteration:  84% 2738/3255 [1:06:08<12:13,  1.42s/it]\u001b[A\n","Iteration:  84% 2739/3255 [1:06:10<12:12,  1.42s/it]\u001b[A\n","Iteration:  84% 2740/3255 [1:06:11<12:10,  1.42s/it]\u001b[A\n","Iteration:  84% 2741/3255 [1:06:12<12:11,  1.42s/it]\u001b[A\n","Iteration:  84% 2742/3255 [1:06:14<12:08,  1.42s/it]\u001b[A\n","Iteration:  84% 2743/3255 [1:06:15<12:06,  1.42s/it]\u001b[A\n","Iteration:  84% 2744/3255 [1:06:17<12:08,  1.42s/it]\u001b[A\n","Iteration:  84% 2745/3255 [1:06:18<12:05,  1.42s/it]\u001b[A\n","Iteration:  84% 2746/3255 [1:06:20<12:02,  1.42s/it]\u001b[A\n","Iteration:  84% 2747/3255 [1:06:21<12:03,  1.42s/it]\u001b[A\n","Iteration:  84% 2748/3255 [1:06:22<12:02,  1.42s/it]\u001b[A\n","Iteration:  84% 2749/3255 [1:06:24<11:58,  1.42s/it]\u001b[A11/26/2019 19:51:58 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-2750/config.json\n","11/26/2019 19:52:00 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-2750/pytorch_model.bin\n","11/26/2019 19:52:00 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-2750\n","\n","Iteration:  84% 2750/3255 [1:06:27<15:55,  1.89s/it]\u001b[A\n","Iteration:  85% 2751/3255 [1:06:28<14:34,  1.74s/it]\u001b[A\n","Iteration:  85% 2752/3255 [1:06:30<13:45,  1.64s/it]\u001b[A\n","Iteration:  85% 2753/3255 [1:06:31<13:09,  1.57s/it]\u001b[A\n","Iteration:  85% 2754/3255 [1:06:32<12:44,  1.53s/it]\u001b[A\n","Iteration:  85% 2755/3255 [1:06:34<12:26,  1.49s/it]\u001b[A\n","Iteration:  85% 2756/3255 [1:06:35<12:15,  1.47s/it]\u001b[A\n","Iteration:  85% 2757/3255 [1:06:37<12:05,  1.46s/it]\u001b[A\n","Iteration:  85% 2758/3255 [1:06:38<11:59,  1.45s/it]\u001b[A\n","Iteration:  85% 2759/3255 [1:06:40<11:53,  1.44s/it]\u001b[A\n","Iteration:  85% 2760/3255 [1:06:41<11:49,  1.43s/it]\u001b[A\n","Iteration:  85% 2761/3255 [1:06:42<11:48,  1.43s/it]\u001b[A\n","Iteration:  85% 2762/3255 [1:06:44<11:42,  1.43s/it]\u001b[A\n","Iteration:  85% 2763/3255 [1:06:45<11:40,  1.42s/it]\u001b[A\n","Iteration:  85% 2764/3255 [1:06:47<11:37,  1.42s/it]\u001b[A\n","Iteration:  85% 2765/3255 [1:06:48<11:37,  1.42s/it]\u001b[A\n","Iteration:  85% 2766/3255 [1:06:49<11:36,  1.42s/it]\u001b[A\n","Iteration:  85% 2767/3255 [1:06:51<11:34,  1.42s/it]\u001b[A\n","Iteration:  85% 2768/3255 [1:06:52<11:34,  1.43s/it]\u001b[A\n","Iteration:  85% 2769/3255 [1:06:54<11:31,  1.42s/it]\u001b[A\n","Iteration:  85% 2770/3255 [1:06:55<11:29,  1.42s/it]\u001b[A\n","Iteration:  85% 2771/3255 [1:06:57<11:25,  1.42s/it]\u001b[A\n","Iteration:  85% 2772/3255 [1:06:58<11:26,  1.42s/it]\u001b[A\n","Iteration:  85% 2773/3255 [1:06:59<11:25,  1.42s/it]\u001b[A\n","Iteration:  85% 2774/3255 [1:07:01<11:22,  1.42s/it]\u001b[A\n","Iteration:  85% 2775/3255 [1:07:02<11:22,  1.42s/it]\u001b[A\n","Iteration:  85% 2776/3255 [1:07:04<11:18,  1.42s/it]\u001b[A\n","Iteration:  85% 2777/3255 [1:07:05<11:17,  1.42s/it]\u001b[A\n","Iteration:  85% 2778/3255 [1:07:07<11:16,  1.42s/it]\u001b[A\n","Iteration:  85% 2779/3255 [1:07:08<11:13,  1.42s/it]\u001b[A\n","Iteration:  85% 2780/3255 [1:07:09<11:13,  1.42s/it]\u001b[A\n","Iteration:  85% 2781/3255 [1:07:11<11:15,  1.43s/it]\u001b[A\n","Iteration:  85% 2782/3255 [1:07:12<11:11,  1.42s/it]\u001b[A\n","Iteration:  85% 2783/3255 [1:07:14<11:07,  1.41s/it]\u001b[A\n","Iteration:  86% 2784/3255 [1:07:15<11:09,  1.42s/it]\u001b[A\n","Iteration:  86% 2785/3255 [1:07:16<11:07,  1.42s/it]\u001b[A\n","Iteration:  86% 2786/3255 [1:07:18<11:04,  1.42s/it]\u001b[A\n","Iteration:  86% 2787/3255 [1:07:19<11:05,  1.42s/it]\u001b[A\n","Iteration:  86% 2788/3255 [1:07:21<11:03,  1.42s/it]\u001b[A\n","Iteration:  86% 2789/3255 [1:07:22<11:01,  1.42s/it]\u001b[A\n","Iteration:  86% 2790/3255 [1:07:24<11:01,  1.42s/it]\u001b[A\n","Iteration:  86% 2791/3255 [1:07:25<10:58,  1.42s/it]\u001b[A\n","Iteration:  86% 2792/3255 [1:07:26<10:55,  1.42s/it]\u001b[A\n","Iteration:  86% 2793/3255 [1:07:28<10:55,  1.42s/it]\u001b[A\n","Iteration:  86% 2794/3255 [1:07:29<10:54,  1.42s/it]\u001b[A\n","Iteration:  86% 2795/3255 [1:07:31<10:52,  1.42s/it]\u001b[A\n","Iteration:  86% 2796/3255 [1:07:32<10:53,  1.42s/it]\u001b[A\n","Iteration:  86% 2797/3255 [1:07:34<10:52,  1.42s/it]\u001b[A\n","Iteration:  86% 2798/3255 [1:07:35<10:47,  1.42s/it]\u001b[A\n","Iteration:  86% 2799/3255 [1:07:36<10:47,  1.42s/it]\u001b[A11/26/2019 19:53:10 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-2800/config.json\n","11/26/2019 19:53:12 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-2800/pytorch_model.bin\n","11/26/2019 19:53:12 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-2800\n","\n","Iteration:  86% 2800/3255 [1:07:39<14:31,  1.92s/it]\u001b[A\n","Iteration:  86% 2801/3255 [1:07:41<13:12,  1.75s/it]\u001b[A\n","Iteration:  86% 2802/3255 [1:07:42<12:26,  1.65s/it]\u001b[A\n","Iteration:  86% 2803/3255 [1:07:44<11:54,  1.58s/it]\u001b[A\n","Iteration:  86% 2804/3255 [1:07:45<11:30,  1.53s/it]\u001b[A\n","Iteration:  86% 2805/3255 [1:07:46<11:16,  1.50s/it]\u001b[A\n","Iteration:  86% 2806/3255 [1:07:48<11:03,  1.48s/it]\u001b[A\n","Iteration:  86% 2807/3255 [1:07:49<10:53,  1.46s/it]\u001b[A\n","Iteration:  86% 2808/3255 [1:07:51<10:47,  1.45s/it]\u001b[A\n","Iteration:  86% 2809/3255 [1:07:52<10:41,  1.44s/it]\u001b[A\n","Iteration:  86% 2810/3255 [1:07:54<10:36,  1.43s/it]\u001b[A\n","Iteration:  86% 2811/3255 [1:07:55<10:34,  1.43s/it]\u001b[A\n","Iteration:  86% 2812/3255 [1:07:56<10:33,  1.43s/it]\u001b[A\n","Iteration:  86% 2813/3255 [1:07:58<10:30,  1.43s/it]\u001b[A\n","Iteration:  86% 2814/3255 [1:07:59<10:28,  1.43s/it]\u001b[A\n","Iteration:  86% 2815/3255 [1:08:01<10:26,  1.42s/it]\u001b[A\n","Iteration:  87% 2816/3255 [1:08:02<10:25,  1.42s/it]\u001b[A\n","Iteration:  87% 2817/3255 [1:08:04<10:24,  1.43s/it]\u001b[A\n","Iteration:  87% 2818/3255 [1:08:05<10:19,  1.42s/it]\u001b[A\n","Iteration:  87% 2819/3255 [1:08:06<10:18,  1.42s/it]\u001b[A\n","Iteration:  87% 2820/3255 [1:08:08<10:19,  1.42s/it]\u001b[A\n","Iteration:  87% 2821/3255 [1:08:09<10:17,  1.42s/it]\u001b[A\n","Iteration:  87% 2822/3255 [1:08:11<10:15,  1.42s/it]\u001b[A\n","Iteration:  87% 2823/3255 [1:08:12<10:13,  1.42s/it]\u001b[A\n","Iteration:  87% 2824/3255 [1:08:13<10:14,  1.43s/it]\u001b[A\n","Iteration:  87% 2825/3255 [1:08:15<10:12,  1.42s/it]\u001b[A\n","Iteration:  87% 2826/3255 [1:08:16<10:11,  1.42s/it]\u001b[A\n","Iteration:  87% 2827/3255 [1:08:18<10:08,  1.42s/it]\u001b[A\n","Iteration:  87% 2828/3255 [1:08:19<10:06,  1.42s/it]\u001b[A\n","Iteration:  87% 2829/3255 [1:08:21<10:06,  1.42s/it]\u001b[A\n","Iteration:  87% 2830/3255 [1:08:22<10:04,  1.42s/it]\u001b[A\n","Iteration:  87% 2831/3255 [1:08:23<10:02,  1.42s/it]\u001b[A\n","Iteration:  87% 2832/3255 [1:08:25<10:03,  1.43s/it]\u001b[A\n","Iteration:  87% 2833/3255 [1:08:26<09:58,  1.42s/it]\u001b[A\n","Iteration:  87% 2834/3255 [1:08:28<09:58,  1.42s/it]\u001b[A\n","Iteration:  87% 2835/3255 [1:08:29<09:57,  1.42s/it]\u001b[A\n","Iteration:  87% 2836/3255 [1:08:31<09:54,  1.42s/it]\u001b[A\n","Iteration:  87% 2837/3255 [1:08:32<09:54,  1.42s/it]\u001b[A\n","Iteration:  87% 2838/3255 [1:08:33<09:54,  1.42s/it]\u001b[A\n","Iteration:  87% 2839/3255 [1:08:35<09:50,  1.42s/it]\u001b[A\n","Iteration:  87% 2840/3255 [1:08:36<09:47,  1.42s/it]\u001b[A\n","Iteration:  87% 2841/3255 [1:08:38<09:47,  1.42s/it]\u001b[A\n","Iteration:  87% 2842/3255 [1:08:39<09:45,  1.42s/it]\u001b[A\n","Iteration:  87% 2843/3255 [1:08:40<09:44,  1.42s/it]\u001b[A\n","Iteration:  87% 2844/3255 [1:08:42<09:41,  1.42s/it]\u001b[A\n","Iteration:  87% 2845/3255 [1:08:43<09:41,  1.42s/it]\u001b[A\n","Iteration:  87% 2846/3255 [1:08:45<09:40,  1.42s/it]\u001b[A\n","Iteration:  87% 2847/3255 [1:08:46<09:41,  1.42s/it]\u001b[A\n","Iteration:  87% 2848/3255 [1:08:48<09:35,  1.41s/it]\u001b[A\n","Iteration:  88% 2849/3255 [1:08:49<09:35,  1.42s/it]\u001b[A11/26/2019 19:54:23 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-2850/config.json\n","11/26/2019 19:54:25 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-2850/pytorch_model.bin\n","11/26/2019 19:54:25 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-2850\n","\n","Iteration:  88% 2850/3255 [1:08:52<12:36,  1.87s/it]\u001b[A\n","Iteration:  88% 2851/3255 [1:08:53<11:33,  1.72s/it]\u001b[A\n","Iteration:  88% 2852/3255 [1:08:55<10:55,  1.63s/it]\u001b[A\n","Iteration:  88% 2853/3255 [1:08:56<10:27,  1.56s/it]\u001b[A\n","Iteration:  88% 2854/3255 [1:08:57<10:09,  1.52s/it]\u001b[A\n","Iteration:  88% 2855/3255 [1:08:59<09:54,  1.49s/it]\u001b[A\n","Iteration:  88% 2856/3255 [1:09:00<09:46,  1.47s/it]\u001b[A\n","Iteration:  88% 2857/3255 [1:09:02<09:38,  1.45s/it]\u001b[A\n","Iteration:  88% 2858/3255 [1:09:03<09:33,  1.45s/it]\u001b[A\n","Iteration:  88% 2859/3255 [1:09:05<09:31,  1.44s/it]\u001b[A\n","Iteration:  88% 2860/3255 [1:09:06<09:26,  1.44s/it]\u001b[A\n","Iteration:  88% 2861/3255 [1:09:07<09:23,  1.43s/it]\u001b[A\n","Iteration:  88% 2862/3255 [1:09:09<09:21,  1.43s/it]\u001b[A\n","Iteration:  88% 2863/3255 [1:09:10<09:18,  1.43s/it]\u001b[A\n","Iteration:  88% 2864/3255 [1:09:12<09:17,  1.43s/it]\u001b[A\n","Iteration:  88% 2865/3255 [1:09:13<09:17,  1.43s/it]\u001b[A\n","Iteration:  88% 2866/3255 [1:09:15<09:12,  1.42s/it]\u001b[A\n","Iteration:  88% 2867/3255 [1:09:16<09:13,  1.43s/it]\u001b[A\n","Iteration:  88% 2868/3255 [1:09:17<09:10,  1.42s/it]\u001b[A\n","Iteration:  88% 2869/3255 [1:09:19<09:07,  1.42s/it]\u001b[A\n","Iteration:  88% 2870/3255 [1:09:20<09:07,  1.42s/it]\u001b[A\n","Iteration:  88% 2871/3255 [1:09:22<09:05,  1.42s/it]\u001b[A\n","Iteration:  88% 2872/3255 [1:09:23<09:06,  1.43s/it]\u001b[A\n","Iteration:  88% 2873/3255 [1:09:25<09:05,  1.43s/it]\u001b[A\n","Iteration:  88% 2874/3255 [1:09:26<09:03,  1.43s/it]\u001b[A\n","Iteration:  88% 2875/3255 [1:09:27<09:00,  1.42s/it]\u001b[A\n","Iteration:  88% 2876/3255 [1:09:29<08:58,  1.42s/it]\u001b[A\n","Iteration:  88% 2877/3255 [1:09:30<09:00,  1.43s/it]\u001b[A\n","Iteration:  88% 2878/3255 [1:09:32<08:57,  1.43s/it]\u001b[A\n","Iteration:  88% 2879/3255 [1:09:33<08:53,  1.42s/it]\u001b[A\n","Iteration:  88% 2880/3255 [1:09:34<08:53,  1.42s/it]\u001b[A\n","Iteration:  89% 2881/3255 [1:09:36<08:50,  1.42s/it]\u001b[A\n","Iteration:  89% 2882/3255 [1:09:37<08:50,  1.42s/it]\u001b[A\n","Iteration:  89% 2883/3255 [1:09:39<08:50,  1.43s/it]\u001b[A\n","Iteration:  89% 2884/3255 [1:09:40<08:49,  1.43s/it]\u001b[A\n","Iteration:  89% 2885/3255 [1:09:42<08:46,  1.42s/it]\u001b[A\n","Iteration:  89% 2886/3255 [1:09:43<08:45,  1.42s/it]\u001b[A\n","Iteration:  89% 2887/3255 [1:09:44<08:44,  1.43s/it]\u001b[A\n","Iteration:  89% 2888/3255 [1:09:46<08:42,  1.42s/it]\u001b[A\n","Iteration:  89% 2889/3255 [1:09:47<08:41,  1.43s/it]\u001b[A\n","Iteration:  89% 2890/3255 [1:09:49<08:38,  1.42s/it]\u001b[A\n","Iteration:  89% 2891/3255 [1:09:50<08:36,  1.42s/it]\u001b[A\n","Iteration:  89% 2892/3255 [1:09:52<08:34,  1.42s/it]\u001b[A\n","Iteration:  89% 2893/3255 [1:09:53<08:34,  1.42s/it]\u001b[A\n","Iteration:  89% 2894/3255 [1:09:54<08:31,  1.42s/it]\u001b[A\n","Iteration:  89% 2895/3255 [1:09:56<08:31,  1.42s/it]\u001b[A\n","Iteration:  89% 2896/3255 [1:09:57<08:32,  1.43s/it]\u001b[A\n","Iteration:  89% 2897/3255 [1:09:59<08:29,  1.42s/it]\u001b[A\n","Iteration:  89% 2898/3255 [1:10:00<08:26,  1.42s/it]\u001b[A\n","Iteration:  89% 2899/3255 [1:10:01<08:24,  1.42s/it]\u001b[A11/26/2019 19:55:36 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-2900/config.json\n","11/26/2019 19:55:37 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-2900/pytorch_model.bin\n","11/26/2019 19:55:37 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-2900\n","\n","Iteration:  89% 2900/3255 [1:10:04<11:01,  1.86s/it]\u001b[A\n","Iteration:  89% 2901/3255 [1:10:06<10:07,  1.72s/it]\u001b[A\n","Iteration:  89% 2902/3255 [1:10:07<09:33,  1.63s/it]\u001b[A\n","Iteration:  89% 2903/3255 [1:10:09<09:11,  1.57s/it]\u001b[A\n","Iteration:  89% 2904/3255 [1:10:10<08:53,  1.52s/it]\u001b[A\n","Iteration:  89% 2905/3255 [1:10:11<08:42,  1.49s/it]\u001b[A\n","Iteration:  89% 2906/3255 [1:10:13<08:31,  1.46s/it]\u001b[A\n","Iteration:  89% 2907/3255 [1:10:14<08:26,  1.45s/it]\u001b[A\n","Iteration:  89% 2908/3255 [1:10:16<08:20,  1.44s/it]\u001b[A\n","Iteration:  89% 2909/3255 [1:10:17<08:17,  1.44s/it]\u001b[A\n","Iteration:  89% 2910/3255 [1:10:19<08:16,  1.44s/it]\u001b[A\n","Iteration:  89% 2911/3255 [1:10:20<08:13,  1.43s/it]\u001b[A\n","Iteration:  89% 2912/3255 [1:10:21<08:11,  1.43s/it]\u001b[A\n","Iteration:  89% 2913/3255 [1:10:23<08:07,  1.42s/it]\u001b[A\n","Iteration:  90% 2914/3255 [1:10:24<08:06,  1.43s/it]\u001b[A\n","Iteration:  90% 2915/3255 [1:10:26<08:04,  1.42s/it]\u001b[A\n","Iteration:  90% 2916/3255 [1:10:27<08:02,  1.42s/it]\u001b[A\n","Iteration:  90% 2917/3255 [1:10:29<08:01,  1.43s/it]\u001b[A\n","Iteration:  90% 2918/3255 [1:10:30<07:57,  1.42s/it]\u001b[A\n","Iteration:  90% 2919/3255 [1:10:31<07:58,  1.42s/it]\u001b[A\n","Iteration:  90% 2920/3255 [1:10:33<07:56,  1.42s/it]\u001b[A\n","Iteration:  90% 2921/3255 [1:10:34<07:56,  1.43s/it]\u001b[A\n","Iteration:  90% 2922/3255 [1:10:36<07:53,  1.42s/it]\u001b[A\n","Iteration:  90% 2923/3255 [1:10:37<07:52,  1.42s/it]\u001b[A\n","Iteration:  90% 2924/3255 [1:10:38<07:49,  1.42s/it]\u001b[A\n","Iteration:  90% 2925/3255 [1:10:40<07:50,  1.42s/it]\u001b[A\n","Iteration:  90% 2926/3255 [1:10:41<07:48,  1.42s/it]\u001b[A\n","Iteration:  90% 2927/3255 [1:10:43<07:45,  1.42s/it]\u001b[A\n","Iteration:  90% 2928/3255 [1:10:44<07:43,  1.42s/it]\u001b[A\n","Iteration:  90% 2929/3255 [1:10:46<07:43,  1.42s/it]\u001b[A\n","Iteration:  90% 2930/3255 [1:10:47<07:43,  1.43s/it]\u001b[A\n","Iteration:  90% 2931/3255 [1:10:48<07:42,  1.43s/it]\u001b[A\n","Iteration:  90% 2932/3255 [1:10:50<07:39,  1.42s/it]\u001b[A\n","Iteration:  90% 2933/3255 [1:10:51<07:39,  1.43s/it]\u001b[A\n","Iteration:  90% 2934/3255 [1:10:53<07:37,  1.42s/it]\u001b[A\n","Iteration:  90% 2935/3255 [1:10:54<07:36,  1.43s/it]\u001b[A\n","Iteration:  90% 2936/3255 [1:10:56<07:33,  1.42s/it]\u001b[A\n","Iteration:  90% 2937/3255 [1:10:57<07:31,  1.42s/it]\u001b[A\n","Iteration:  90% 2938/3255 [1:10:58<07:31,  1.43s/it]\u001b[A\n","Iteration:  90% 2939/3255 [1:11:00<07:28,  1.42s/it]\u001b[A\n","Iteration:  90% 2940/3255 [1:11:01<07:25,  1.42s/it]\u001b[A\n","Iteration:  90% 2941/3255 [1:11:03<07:24,  1.42s/it]\u001b[A\n","Iteration:  90% 2942/3255 [1:11:04<07:23,  1.42s/it]\u001b[A\n","Iteration:  90% 2943/3255 [1:11:05<07:22,  1.42s/it]\u001b[A\n","Iteration:  90% 2944/3255 [1:11:07<07:19,  1.41s/it]\u001b[A\n","Iteration:  90% 2945/3255 [1:11:08<07:19,  1.42s/it]\u001b[A\n","Iteration:  91% 2946/3255 [1:11:10<07:17,  1.42s/it]\u001b[A\n","Iteration:  91% 2947/3255 [1:11:11<07:16,  1.42s/it]\u001b[A\n","Iteration:  91% 2948/3255 [1:11:13<07:16,  1.42s/it]\u001b[A\n","Iteration:  91% 2949/3255 [1:11:14<07:15,  1.42s/it]\u001b[A11/26/2019 19:56:48 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-2950/config.json\n","11/26/2019 19:56:50 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-2950/pytorch_model.bin\n","11/26/2019 19:56:50 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-2950\n","\n","Iteration:  91% 2950/3255 [1:11:17<09:33,  1.88s/it]\u001b[A\n","Iteration:  91% 2951/3255 [1:11:18<08:44,  1.72s/it]\u001b[A\n","Iteration:  91% 2952/3255 [1:11:20<08:14,  1.63s/it]\u001b[A\n","Iteration:  91% 2953/3255 [1:11:21<07:54,  1.57s/it]\u001b[A\n","Iteration:  91% 2954/3255 [1:11:23<07:39,  1.53s/it]\u001b[A\n","Iteration:  91% 2955/3255 [1:11:24<07:29,  1.50s/it]\u001b[A\n","Iteration:  91% 2956/3255 [1:11:25<07:22,  1.48s/it]\u001b[A\n","Iteration:  91% 2957/3255 [1:11:27<07:16,  1.46s/it]\u001b[A\n","Iteration:  91% 2958/3255 [1:11:28<07:10,  1.45s/it]\u001b[A\n","Iteration:  91% 2959/3255 [1:11:30<07:07,  1.44s/it]\u001b[A\n","Iteration:  91% 2960/3255 [1:11:31<07:05,  1.44s/it]\u001b[A\n","Iteration:  91% 2961/3255 [1:11:33<07:01,  1.43s/it]\u001b[A\n","Iteration:  91% 2962/3255 [1:11:34<07:00,  1.43s/it]\u001b[A\n","Iteration:  91% 2963/3255 [1:11:35<06:58,  1.43s/it]\u001b[A\n","Iteration:  91% 2964/3255 [1:11:37<06:54,  1.43s/it]\u001b[A\n","Iteration:  91% 2965/3255 [1:11:38<06:52,  1.42s/it]\u001b[A\n","Iteration:  91% 2966/3255 [1:11:40<06:50,  1.42s/it]\u001b[A\n","Iteration:  91% 2967/3255 [1:11:41<06:48,  1.42s/it]\u001b[A\n","Iteration:  91% 2968/3255 [1:11:42<06:47,  1.42s/it]\u001b[A\n","Iteration:  91% 2969/3255 [1:11:44<06:46,  1.42s/it]\u001b[A\n","Iteration:  91% 2970/3255 [1:11:45<06:45,  1.42s/it]\u001b[A\n","Iteration:  91% 2971/3255 [1:11:47<06:43,  1.42s/it]\u001b[A\n","Iteration:  91% 2972/3255 [1:11:48<06:43,  1.42s/it]\u001b[A\n","Iteration:  91% 2973/3255 [1:11:50<06:41,  1.42s/it]\u001b[A\n","Iteration:  91% 2974/3255 [1:11:51<06:39,  1.42s/it]\u001b[A\n","Iteration:  91% 2975/3255 [1:11:52<06:38,  1.42s/it]\u001b[A\n","Iteration:  91% 2976/3255 [1:11:54<06:36,  1.42s/it]\u001b[A\n","Iteration:  91% 2977/3255 [1:11:55<06:34,  1.42s/it]\u001b[A\n","Iteration:  91% 2978/3255 [1:11:57<06:33,  1.42s/it]\u001b[A\n","Iteration:  92% 2979/3255 [1:11:58<06:31,  1.42s/it]\u001b[A\n","Iteration:  92% 2980/3255 [1:12:00<06:28,  1.41s/it]\u001b[A\n","Iteration:  92% 2981/3255 [1:12:01<06:30,  1.42s/it]\u001b[A\n","Iteration:  92% 2982/3255 [1:12:02<06:27,  1.42s/it]\u001b[A\n","Iteration:  92% 2983/3255 [1:12:04<06:26,  1.42s/it]\u001b[A\n","Iteration:  92% 2984/3255 [1:12:05<06:25,  1.42s/it]\u001b[A\n","Iteration:  92% 2985/3255 [1:12:07<06:22,  1.42s/it]\u001b[A\n","Iteration:  92% 2986/3255 [1:12:08<06:21,  1.42s/it]\u001b[A\n","Iteration:  92% 2987/3255 [1:12:09<06:19,  1.42s/it]\u001b[A\n","Iteration:  92% 2988/3255 [1:12:11<06:18,  1.42s/it]\u001b[A\n","Iteration:  92% 2989/3255 [1:12:12<06:17,  1.42s/it]\u001b[A\n","Iteration:  92% 2990/3255 [1:12:14<06:15,  1.42s/it]\u001b[A\n","Iteration:  92% 2991/3255 [1:12:15<06:14,  1.42s/it]\u001b[A\n","Iteration:  92% 2992/3255 [1:12:17<06:12,  1.42s/it]\u001b[A\n","Iteration:  92% 2993/3255 [1:12:18<06:11,  1.42s/it]\u001b[A\n","Iteration:  92% 2994/3255 [1:12:19<06:09,  1.42s/it]\u001b[A\n","Iteration:  92% 2995/3255 [1:12:21<06:08,  1.42s/it]\u001b[A\n","Iteration:  92% 2996/3255 [1:12:22<06:08,  1.42s/it]\u001b[A\n","Iteration:  92% 2997/3255 [1:12:24<06:07,  1.42s/it]\u001b[A\n","Iteration:  92% 2998/3255 [1:12:25<06:06,  1.43s/it]\u001b[A\n","Iteration:  92% 2999/3255 [1:12:27<06:05,  1.43s/it]\u001b[A11/26/2019 19:58:01 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-3000/config.json\n","11/26/2019 19:58:02 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-3000/pytorch_model.bin\n","11/26/2019 19:58:02 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-3000\n","\n","Iteration:  92% 3000/3255 [1:12:29<07:50,  1.84s/it]\u001b[A\n","Iteration:  92% 3001/3255 [1:12:31<07:12,  1.70s/it]\u001b[A\n","Iteration:  92% 3002/3255 [1:12:32<06:49,  1.62s/it]\u001b[A\n","Iteration:  92% 3003/3255 [1:12:34<06:33,  1.56s/it]\u001b[A\n","Iteration:  92% 3004/3255 [1:12:35<06:21,  1.52s/it]\u001b[A\n","Iteration:  92% 3005/3255 [1:12:36<06:12,  1.49s/it]\u001b[A\n","Iteration:  92% 3006/3255 [1:12:38<06:06,  1.47s/it]\u001b[A\n","Iteration:  92% 3007/3255 [1:12:39<06:00,  1.46s/it]\u001b[A\n","Iteration:  92% 3008/3255 [1:12:41<05:56,  1.44s/it]\u001b[A\n","Iteration:  92% 3009/3255 [1:12:42<05:54,  1.44s/it]\u001b[A\n","Iteration:  92% 3010/3255 [1:12:44<05:50,  1.43s/it]\u001b[A\n","Iteration:  93% 3011/3255 [1:12:45<05:48,  1.43s/it]\u001b[A\n","Iteration:  93% 3012/3255 [1:12:46<05:46,  1.43s/it]\u001b[A\n","Iteration:  93% 3013/3255 [1:12:48<05:45,  1.43s/it]\u001b[A\n","Iteration:  93% 3014/3255 [1:12:49<05:43,  1.42s/it]\u001b[A\n","Iteration:  93% 3015/3255 [1:12:51<05:41,  1.42s/it]\u001b[A\n","Iteration:  93% 3016/3255 [1:12:52<05:39,  1.42s/it]\u001b[A\n","Iteration:  93% 3017/3255 [1:12:53<05:38,  1.42s/it]\u001b[A\n","Iteration:  93% 3018/3255 [1:12:55<05:37,  1.42s/it]\u001b[A\n","Iteration:  93% 3019/3255 [1:12:56<05:36,  1.43s/it]\u001b[A\n","Iteration:  93% 3020/3255 [1:12:58<05:35,  1.43s/it]\u001b[A\n","Iteration:  93% 3021/3255 [1:12:59<05:33,  1.43s/it]\u001b[A\n","Iteration:  93% 3022/3255 [1:13:01<05:31,  1.42s/it]\u001b[A\n","Iteration:  93% 3023/3255 [1:13:02<05:30,  1.42s/it]\u001b[A\n","Iteration:  93% 3024/3255 [1:13:03<05:28,  1.42s/it]\u001b[A\n","Iteration:  93% 3025/3255 [1:13:05<05:26,  1.42s/it]\u001b[A\n","Iteration:  93% 3026/3255 [1:13:06<05:25,  1.42s/it]\u001b[A\n","Iteration:  93% 3027/3255 [1:13:08<05:22,  1.42s/it]\u001b[A\n","Iteration:  93% 3028/3255 [1:13:09<05:21,  1.41s/it]\u001b[A\n","Iteration:  93% 3029/3255 [1:13:11<05:19,  1.41s/it]\u001b[A\n","Iteration:  93% 3030/3255 [1:13:12<05:17,  1.41s/it]\u001b[A\n","Iteration:  93% 3031/3255 [1:13:13<05:17,  1.42s/it]\u001b[A\n","Iteration:  93% 3032/3255 [1:13:15<05:16,  1.42s/it]\u001b[A\n","Iteration:  93% 3033/3255 [1:13:16<05:15,  1.42s/it]\u001b[A\n","Iteration:  93% 3034/3255 [1:13:18<05:13,  1.42s/it]\u001b[A\n","Iteration:  93% 3035/3255 [1:13:19<05:13,  1.42s/it]\u001b[A\n","Iteration:  93% 3036/3255 [1:13:20<05:10,  1.42s/it]\u001b[A\n","Iteration:  93% 3037/3255 [1:13:22<05:08,  1.42s/it]\u001b[A\n","Iteration:  93% 3038/3255 [1:13:23<05:07,  1.42s/it]\u001b[A\n","Iteration:  93% 3039/3255 [1:13:25<05:05,  1.41s/it]\u001b[A\n","Iteration:  93% 3040/3255 [1:13:26<05:04,  1.42s/it]\u001b[A\n","Iteration:  93% 3041/3255 [1:13:28<05:02,  1.41s/it]\u001b[A\n","Iteration:  93% 3042/3255 [1:13:29<05:01,  1.42s/it]\u001b[A\n","Iteration:  93% 3043/3255 [1:13:30<05:01,  1.42s/it]\u001b[A\n","Iteration:  94% 3044/3255 [1:13:32<05:00,  1.42s/it]\u001b[A\n","Iteration:  94% 3045/3255 [1:13:33<04:58,  1.42s/it]\u001b[A\n","Iteration:  94% 3046/3255 [1:13:35<04:55,  1.42s/it]\u001b[A\n","Iteration:  94% 3047/3255 [1:13:36<04:55,  1.42s/it]\u001b[A\n","Iteration:  94% 3048/3255 [1:13:37<04:54,  1.42s/it]\u001b[A\n","Iteration:  94% 3049/3255 [1:13:39<04:51,  1.42s/it]\u001b[A11/26/2019 19:59:13 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-3050/config.json\n","11/26/2019 19:59:15 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-3050/pytorch_model.bin\n","11/26/2019 19:59:15 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-3050\n","\n","Iteration:  94% 3050/3255 [1:13:42<06:39,  1.95s/it]\u001b[A\n","Iteration:  94% 3051/3255 [1:13:43<06:02,  1.78s/it]\u001b[A\n","Iteration:  94% 3052/3255 [1:13:45<05:39,  1.67s/it]\u001b[A\n","Iteration:  94% 3053/3255 [1:13:46<05:22,  1.60s/it]\u001b[A\n","Iteration:  94% 3054/3255 [1:13:48<05:10,  1.54s/it]\u001b[A\n","Iteration:  94% 3055/3255 [1:13:49<05:00,  1.50s/it]\u001b[A\n","Iteration:  94% 3056/3255 [1:13:51<04:54,  1.48s/it]\u001b[A\n","Iteration:  94% 3057/3255 [1:13:52<04:48,  1.46s/it]\u001b[A\n","Iteration:  94% 3058/3255 [1:13:53<04:46,  1.45s/it]\u001b[A\n","Iteration:  94% 3059/3255 [1:13:55<04:42,  1.44s/it]\u001b[A\n","Iteration:  94% 3060/3255 [1:13:56<04:39,  1.43s/it]\u001b[A\n","Iteration:  94% 3061/3255 [1:13:58<04:36,  1.43s/it]\u001b[A\n","Iteration:  94% 3062/3255 [1:13:59<04:35,  1.42s/it]\u001b[A\n","Iteration:  94% 3063/3255 [1:14:00<04:33,  1.42s/it]\u001b[A\n","Iteration:  94% 3064/3255 [1:14:02<04:31,  1.42s/it]\u001b[A\n","Iteration:  94% 3065/3255 [1:14:03<04:29,  1.42s/it]\u001b[A\n","Iteration:  94% 3066/3255 [1:14:05<04:28,  1.42s/it]\u001b[A\n","Iteration:  94% 3067/3255 [1:14:06<04:28,  1.43s/it]\u001b[A\n","Iteration:  94% 3068/3255 [1:14:08<04:25,  1.42s/it]\u001b[A\n","Iteration:  94% 3069/3255 [1:14:09<04:23,  1.42s/it]\u001b[A\n","Iteration:  94% 3070/3255 [1:14:10<04:22,  1.42s/it]\u001b[A\n","Iteration:  94% 3071/3255 [1:14:12<04:21,  1.42s/it]\u001b[A\n","Iteration:  94% 3072/3255 [1:14:13<04:20,  1.42s/it]\u001b[A\n","Iteration:  94% 3073/3255 [1:14:15<04:18,  1.42s/it]\u001b[A\n","Iteration:  94% 3074/3255 [1:14:16<04:17,  1.42s/it]\u001b[A\n","Iteration:  94% 3075/3255 [1:14:18<04:15,  1.42s/it]\u001b[A\n","Iteration:  95% 3076/3255 [1:14:19<04:13,  1.42s/it]\u001b[A\n","Iteration:  95% 3077/3255 [1:14:20<04:12,  1.42s/it]\u001b[A\n","Iteration:  95% 3078/3255 [1:14:22<04:10,  1.41s/it]\u001b[A\n","Iteration:  95% 3079/3255 [1:14:23<04:09,  1.42s/it]\u001b[A\n","Iteration:  95% 3080/3255 [1:14:25<04:09,  1.43s/it]\u001b[A\n","Iteration:  95% 3081/3255 [1:14:26<04:07,  1.42s/it]\u001b[A\n","Iteration:  95% 3082/3255 [1:14:27<04:05,  1.42s/it]\u001b[A\n","Iteration:  95% 3083/3255 [1:14:29<04:05,  1.42s/it]\u001b[A\n","Iteration:  95% 3084/3255 [1:14:30<04:02,  1.42s/it]\u001b[A\n","Iteration:  95% 3085/3255 [1:14:32<04:01,  1.42s/it]\u001b[A\n","Iteration:  95% 3086/3255 [1:14:33<04:01,  1.43s/it]\u001b[A\n","Iteration:  95% 3087/3255 [1:14:35<03:58,  1.42s/it]\u001b[A\n","Iteration:  95% 3088/3255 [1:14:36<03:56,  1.42s/it]\u001b[A\n","Iteration:  95% 3089/3255 [1:14:37<03:55,  1.42s/it]\u001b[A\n","Iteration:  95% 3090/3255 [1:14:39<03:53,  1.42s/it]\u001b[A\n","Iteration:  95% 3091/3255 [1:14:40<03:52,  1.42s/it]\u001b[A\n","Iteration:  95% 3092/3255 [1:14:42<03:51,  1.42s/it]\u001b[A\n","Iteration:  95% 3093/3255 [1:14:43<03:49,  1.42s/it]\u001b[A\n","Iteration:  95% 3094/3255 [1:14:45<03:48,  1.42s/it]\u001b[A\n","Iteration:  95% 3095/3255 [1:14:46<03:47,  1.42s/it]\u001b[A\n","Iteration:  95% 3096/3255 [1:14:47<03:46,  1.42s/it]\u001b[A\n","Iteration:  95% 3097/3255 [1:14:49<03:44,  1.42s/it]\u001b[A\n","Iteration:  95% 3098/3255 [1:14:50<03:43,  1.42s/it]\u001b[A\n","Iteration:  95% 3099/3255 [1:14:52<03:41,  1.42s/it]\u001b[A11/26/2019 20:00:26 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-3100/config.json\n","11/26/2019 20:00:27 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-3100/pytorch_model.bin\n","11/26/2019 20:00:27 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-3100\n","\n","Iteration:  95% 3100/3255 [1:14:55<04:50,  1.88s/it]\u001b[A\n","Iteration:  95% 3101/3255 [1:14:56<04:25,  1.72s/it]\u001b[A\n","Iteration:  95% 3102/3255 [1:14:57<04:09,  1.63s/it]\u001b[A\n","Iteration:  95% 3103/3255 [1:14:59<03:57,  1.56s/it]\u001b[A\n","Iteration:  95% 3104/3255 [1:15:00<03:49,  1.52s/it]\u001b[A\n","Iteration:  95% 3105/3255 [1:15:02<03:43,  1.49s/it]\u001b[A\n","Iteration:  95% 3106/3255 [1:15:03<03:38,  1.47s/it]\u001b[A\n","Iteration:  95% 3107/3255 [1:15:04<03:35,  1.46s/it]\u001b[A\n","Iteration:  95% 3108/3255 [1:15:06<03:32,  1.45s/it]\u001b[A\n","Iteration:  96% 3109/3255 [1:15:07<03:29,  1.44s/it]\u001b[A\n","Iteration:  96% 3110/3255 [1:15:09<03:27,  1.43s/it]\u001b[A\n","Iteration:  96% 3111/3255 [1:15:10<03:25,  1.43s/it]\u001b[A\n","Iteration:  96% 3112/3255 [1:15:12<03:24,  1.43s/it]\u001b[A\n","Iteration:  96% 3113/3255 [1:15:13<03:22,  1.43s/it]\u001b[A\n","Iteration:  96% 3114/3255 [1:15:14<03:20,  1.42s/it]\u001b[A\n","Iteration:  96% 3115/3255 [1:15:16<03:19,  1.43s/it]\u001b[A\n","Iteration:  96% 3116/3255 [1:15:17<03:17,  1.42s/it]\u001b[A\n","Iteration:  96% 3117/3255 [1:15:19<03:15,  1.42s/it]\u001b[A\n","Iteration:  96% 3118/3255 [1:15:20<03:14,  1.42s/it]\u001b[A\n","Iteration:  96% 3119/3255 [1:15:21<03:13,  1.42s/it]\u001b[A\n","Iteration:  96% 3120/3255 [1:15:23<03:11,  1.42s/it]\u001b[A\n","Iteration:  96% 3121/3255 [1:15:24<03:10,  1.42s/it]\u001b[A\n","Iteration:  96% 3122/3255 [1:15:26<03:09,  1.43s/it]\u001b[A\n","Iteration:  96% 3123/3255 [1:15:27<03:08,  1.43s/it]\u001b[A\n","Iteration:  96% 3124/3255 [1:15:29<03:05,  1.42s/it]\u001b[A\n","Iteration:  96% 3125/3255 [1:15:30<03:04,  1.42s/it]\u001b[A\n","Iteration:  96% 3126/3255 [1:15:31<03:03,  1.42s/it]\u001b[A\n","Iteration:  96% 3127/3255 [1:15:33<03:01,  1.42s/it]\u001b[A\n","Iteration:  96% 3128/3255 [1:15:34<03:01,  1.43s/it]\u001b[A\n","Iteration:  96% 3129/3255 [1:15:36<02:58,  1.42s/it]\u001b[A\n","Iteration:  96% 3130/3255 [1:15:37<02:57,  1.42s/it]\u001b[A\n","Iteration:  96% 3131/3255 [1:15:39<02:56,  1.42s/it]\u001b[A\n","Iteration:  96% 3132/3255 [1:15:40<02:54,  1.42s/it]\u001b[A\n","Iteration:  96% 3133/3255 [1:15:41<02:52,  1.42s/it]\u001b[A\n","Iteration:  96% 3134/3255 [1:15:43<02:52,  1.42s/it]\u001b[A\n","Iteration:  96% 3135/3255 [1:15:44<02:50,  1.42s/it]\u001b[A\n","Iteration:  96% 3136/3255 [1:15:46<02:49,  1.42s/it]\u001b[A\n","Iteration:  96% 3137/3255 [1:15:47<02:48,  1.43s/it]\u001b[A\n","Iteration:  96% 3138/3255 [1:15:48<02:46,  1.43s/it]\u001b[A\n","Iteration:  96% 3139/3255 [1:15:50<02:45,  1.43s/it]\u001b[A\n","Iteration:  96% 3140/3255 [1:15:51<02:44,  1.43s/it]\u001b[A\n","Iteration:  96% 3141/3255 [1:15:53<02:42,  1.42s/it]\u001b[A\n","Iteration:  97% 3142/3255 [1:15:54<02:40,  1.42s/it]\u001b[A\n","Iteration:  97% 3143/3255 [1:15:56<02:39,  1.42s/it]\u001b[A\n","Iteration:  97% 3144/3255 [1:15:57<02:37,  1.42s/it]\u001b[A\n","Iteration:  97% 3145/3255 [1:15:58<02:36,  1.42s/it]\u001b[A\n","Iteration:  97% 3146/3255 [1:16:00<02:35,  1.43s/it]\u001b[A\n","Iteration:  97% 3147/3255 [1:16:01<02:34,  1.43s/it]\u001b[A\n","Iteration:  97% 3148/3255 [1:16:03<02:31,  1.42s/it]\u001b[A\n","Iteration:  97% 3149/3255 [1:16:04<02:30,  1.42s/it]\u001b[A11/26/2019 20:01:38 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-3150/config.json\n","11/26/2019 20:01:40 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-3150/pytorch_model.bin\n","11/26/2019 20:01:40 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-3150\n","\n","Iteration:  97% 3150/3255 [1:16:07<03:11,  1.83s/it]\u001b[A\n","Iteration:  97% 3151/3255 [1:16:08<02:56,  1.70s/it]\u001b[A\n","Iteration:  97% 3152/3255 [1:16:10<02:45,  1.61s/it]\u001b[A\n","Iteration:  97% 3153/3255 [1:16:11<02:37,  1.55s/it]\u001b[A\n","Iteration:  97% 3154/3255 [1:16:13<02:32,  1.51s/it]\u001b[A\n","Iteration:  97% 3155/3255 [1:16:14<02:28,  1.48s/it]\u001b[A\n","Iteration:  97% 3156/3255 [1:16:15<02:24,  1.46s/it]\u001b[A\n","Iteration:  97% 3157/3255 [1:16:17<02:21,  1.45s/it]\u001b[A\n","Iteration:  97% 3158/3255 [1:16:18<02:19,  1.43s/it]\u001b[A\n","Iteration:  97% 3159/3255 [1:16:20<02:17,  1.43s/it]\u001b[A\n","Iteration:  97% 3160/3255 [1:16:21<02:15,  1.43s/it]\u001b[A\n","Iteration:  97% 3161/3255 [1:16:22<02:14,  1.43s/it]\u001b[A\n","Iteration:  97% 3162/3255 [1:16:24<02:12,  1.43s/it]\u001b[A\n","Iteration:  97% 3163/3255 [1:16:25<02:10,  1.42s/it]\u001b[A\n","Iteration:  97% 3164/3255 [1:16:27<02:09,  1.42s/it]\u001b[A\n","Iteration:  97% 3165/3255 [1:16:28<02:07,  1.42s/it]\u001b[A\n","Iteration:  97% 3166/3255 [1:16:30<02:06,  1.42s/it]\u001b[A\n","Iteration:  97% 3167/3255 [1:16:31<02:04,  1.41s/it]\u001b[A\n","Iteration:  97% 3168/3255 [1:16:32<02:03,  1.42s/it]\u001b[A\n","Iteration:  97% 3169/3255 [1:16:34<02:01,  1.42s/it]\u001b[A\n","Iteration:  97% 3170/3255 [1:16:35<02:01,  1.43s/it]\u001b[A\n","Iteration:  97% 3171/3255 [1:16:37<01:59,  1.43s/it]\u001b[A\n","Iteration:  97% 3172/3255 [1:16:38<01:58,  1.43s/it]\u001b[A\n","Iteration:  97% 3173/3255 [1:16:40<01:56,  1.42s/it]\u001b[A\n","Iteration:  98% 3174/3255 [1:16:41<01:55,  1.42s/it]\u001b[A\n","Iteration:  98% 3175/3255 [1:16:42<01:54,  1.43s/it]\u001b[A\n","Iteration:  98% 3176/3255 [1:16:44<01:52,  1.42s/it]\u001b[A\n","Iteration:  98% 3177/3255 [1:16:45<01:51,  1.43s/it]\u001b[A\n","Iteration:  98% 3178/3255 [1:16:47<01:49,  1.42s/it]\u001b[A\n","Iteration:  98% 3179/3255 [1:16:48<01:48,  1.42s/it]\u001b[A\n","Iteration:  98% 3180/3255 [1:16:49<01:46,  1.42s/it]\u001b[A\n","Iteration:  98% 3181/3255 [1:16:51<01:45,  1.42s/it]\u001b[A\n","Iteration:  98% 3182/3255 [1:16:52<01:43,  1.42s/it]\u001b[A\n","Iteration:  98% 3183/3255 [1:16:54<01:42,  1.42s/it]\u001b[A\n","Iteration:  98% 3184/3255 [1:16:55<01:40,  1.42s/it]\u001b[A\n","Iteration:  98% 3185/3255 [1:16:57<01:39,  1.42s/it]\u001b[A\n","Iteration:  98% 3186/3255 [1:16:58<01:37,  1.42s/it]\u001b[A\n","Iteration:  98% 3187/3255 [1:16:59<01:36,  1.42s/it]\u001b[A\n","Iteration:  98% 3188/3255 [1:17:01<01:34,  1.41s/it]\u001b[A\n","Iteration:  98% 3189/3255 [1:17:02<01:33,  1.42s/it]\u001b[A\n","Iteration:  98% 3190/3255 [1:17:04<01:32,  1.42s/it]\u001b[A\n","Iteration:  98% 3191/3255 [1:17:05<01:30,  1.42s/it]\u001b[A\n","Iteration:  98% 3192/3255 [1:17:06<01:29,  1.42s/it]\u001b[A\n","Iteration:  98% 3193/3255 [1:17:08<01:27,  1.42s/it]\u001b[A\n","Iteration:  98% 3194/3255 [1:17:09<01:26,  1.42s/it]\u001b[A\n","Iteration:  98% 3195/3255 [1:17:11<01:25,  1.42s/it]\u001b[A\n","Iteration:  98% 3196/3255 [1:17:12<01:23,  1.42s/it]\u001b[A\n","Iteration:  98% 3197/3255 [1:17:14<01:22,  1.42s/it]\u001b[A\n","Iteration:  98% 3198/3255 [1:17:15<01:21,  1.43s/it]\u001b[A\n","Iteration:  98% 3199/3255 [1:17:16<01:19,  1.42s/it]\u001b[A11/26/2019 20:02:51 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-3200/config.json\n","11/26/2019 20:02:52 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-3200/pytorch_model.bin\n","11/26/2019 20:02:52 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-3200\n","\n","Iteration:  98% 3200/3255 [1:17:19<01:44,  1.91s/it]\u001b[A\n","Iteration:  98% 3201/3255 [1:17:21<01:34,  1.74s/it]\u001b[A\n","Iteration:  98% 3202/3255 [1:17:22<01:27,  1.65s/it]\u001b[A\n","Iteration:  98% 3203/3255 [1:17:24<01:22,  1.58s/it]\u001b[A\n","Iteration:  98% 3204/3255 [1:17:25<01:18,  1.53s/it]\u001b[A\n","Iteration:  98% 3205/3255 [1:17:27<01:15,  1.50s/it]\u001b[A\n","Iteration:  98% 3206/3255 [1:17:28<01:12,  1.48s/it]\u001b[A\n","Iteration:  99% 3207/3255 [1:17:29<01:09,  1.46s/it]\u001b[A\n","Iteration:  99% 3208/3255 [1:17:31<01:07,  1.45s/it]\u001b[A\n","Iteration:  99% 3209/3255 [1:17:32<01:06,  1.44s/it]\u001b[A\n","Iteration:  99% 3210/3255 [1:17:34<01:04,  1.43s/it]\u001b[A\n","Iteration:  99% 3211/3255 [1:17:35<01:02,  1.43s/it]\u001b[A\n","Iteration:  99% 3212/3255 [1:17:36<01:01,  1.43s/it]\u001b[A\n","Iteration:  99% 3213/3255 [1:17:38<01:00,  1.43s/it]\u001b[A\n","Iteration:  99% 3214/3255 [1:17:39<00:58,  1.43s/it]\u001b[A\n","Iteration:  99% 3215/3255 [1:17:41<00:56,  1.42s/it]\u001b[A\n","Iteration:  99% 3216/3255 [1:17:42<00:55,  1.42s/it]\u001b[A\n","Iteration:  99% 3217/3255 [1:17:44<00:53,  1.42s/it]\u001b[A\n","Iteration:  99% 3218/3255 [1:17:45<00:52,  1.42s/it]\u001b[A\n","Iteration:  99% 3219/3255 [1:17:46<00:51,  1.42s/it]\u001b[A\n","Iteration:  99% 3220/3255 [1:17:48<00:49,  1.42s/it]\u001b[A\n","Iteration:  99% 3221/3255 [1:17:49<00:48,  1.42s/it]\u001b[A\n","Iteration:  99% 3222/3255 [1:17:51<00:46,  1.42s/it]\u001b[A\n","Iteration:  99% 3223/3255 [1:17:52<00:45,  1.42s/it]\u001b[A\n","Iteration:  99% 3224/3255 [1:17:54<00:43,  1.42s/it]\u001b[A\n","Iteration:  99% 3225/3255 [1:17:55<00:42,  1.42s/it]\u001b[A\n","Iteration:  99% 3226/3255 [1:17:56<00:41,  1.42s/it]\u001b[A\n","Iteration:  99% 3227/3255 [1:17:58<00:39,  1.41s/it]\u001b[A\n","Iteration:  99% 3228/3255 [1:17:59<00:38,  1.42s/it]\u001b[A\n","Iteration:  99% 3229/3255 [1:18:01<00:36,  1.42s/it]\u001b[A\n","Iteration:  99% 3230/3255 [1:18:02<00:35,  1.42s/it]\u001b[A\n","Iteration:  99% 3231/3255 [1:18:03<00:34,  1.42s/it]\u001b[A\n","Iteration:  99% 3232/3255 [1:18:05<00:32,  1.42s/it]\u001b[A\n","Iteration:  99% 3233/3255 [1:18:06<00:31,  1.43s/it]\u001b[A\n","Iteration:  99% 3234/3255 [1:18:08<00:29,  1.43s/it]\u001b[A\n","Iteration:  99% 3235/3255 [1:18:09<00:28,  1.43s/it]\u001b[A\n","Iteration:  99% 3236/3255 [1:18:11<00:26,  1.42s/it]\u001b[A\n","Iteration:  99% 3237/3255 [1:18:12<00:25,  1.42s/it]\u001b[A\n","Iteration:  99% 3238/3255 [1:18:13<00:24,  1.42s/it]\u001b[A\n","Iteration: 100% 3239/3255 [1:18:15<00:22,  1.42s/it]\u001b[A\n","Iteration: 100% 3240/3255 [1:18:16<00:21,  1.42s/it]\u001b[A\n","Iteration: 100% 3241/3255 [1:18:18<00:19,  1.42s/it]\u001b[A\n","Iteration: 100% 3242/3255 [1:18:19<00:18,  1.42s/it]\u001b[A\n","Iteration: 100% 3243/3255 [1:18:21<00:17,  1.42s/it]\u001b[A\n","Iteration: 100% 3244/3255 [1:18:22<00:15,  1.42s/it]\u001b[A\n","Iteration: 100% 3245/3255 [1:18:23<00:14,  1.42s/it]\u001b[A\n","Iteration: 100% 3246/3255 [1:18:25<00:12,  1.42s/it]\u001b[A\n","Iteration: 100% 3247/3255 [1:18:26<00:11,  1.42s/it]\u001b[A\n","Iteration: 100% 3248/3255 [1:18:28<00:09,  1.42s/it]\u001b[A\n","Iteration: 100% 3249/3255 [1:18:29<00:08,  1.42s/it]\u001b[A11/26/2019 20:04:03 - INFO - transformers.configuration_utils -   Configuration saved in model/checkpoint-3250/config.json\n","11/26/2019 20:04:05 - INFO - transformers.modeling_utils -   Model weights saved in model/checkpoint-3250/pytorch_model.bin\n","11/26/2019 20:04:05 - INFO - __main__ -   Saving model checkpoint to model/checkpoint-3250\n","\n","Iteration: 100% 3250/3255 [1:18:32<00:09,  1.86s/it]\u001b[A\n","Iteration: 100% 3251/3255 [1:18:33<00:06,  1.72s/it]\u001b[A\n","Iteration: 100% 3252/3255 [1:18:35<00:04,  1.62s/it]\u001b[A\n","Iteration: 100% 3253/3255 [1:18:36<00:03,  1.57s/it]\u001b[A\n","Iteration: 100% 3254/3255 [1:18:38<00:01,  1.53s/it]\u001b[A\n","Iteration: 100% 3255/3255 [1:18:38<00:00,  1.30s/it]\u001b[A\n","Epoch: 100% 1/1 [1:18:38<00:00, 4718.86s/it]\n","11/26/2019 20:04:11 - INFO - __main__ -    global_step = 3255, average loss = 3.197778404253419\n","11/26/2019 20:04:11 - INFO - __main__ -   Saving model checkpoint to model\n","11/26/2019 20:04:11 - INFO - transformers.configuration_utils -   Configuration saved in model/config.json\n","11/26/2019 20:04:12 - INFO - transformers.modeling_utils -   Model weights saved in model/pytorch_model.bin\n","11/26/2019 20:04:13 - INFO - transformers.configuration_utils -   loading configuration file model/config.json\n","11/26/2019 20:04:13 - INFO - transformers.configuration_utils -   Model config {\n","  \"attn_pdrop\": 0.1,\n","  \"embd_pdrop\": 0.1,\n","  \"finetuning_task\": null,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"num_labels\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pruned_heads\": {},\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"torchscript\": false,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 50257\n","}\n","\n","11/26/2019 20:04:13 - INFO - transformers.modeling_utils -   loading weights file model/pytorch_model.bin\n","11/26/2019 20:04:17 - INFO - transformers.tokenization_utils -   Model name 'model' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, distilgpt2). Assuming 'model' is a path or url to a directory containing tokenizer files.\n","11/26/2019 20:04:17 - INFO - transformers.tokenization_utils -   loading file model/vocab.json\n","11/26/2019 20:04:17 - INFO - transformers.tokenization_utils -   loading file model/merges.txt\n","11/26/2019 20:04:17 - INFO - transformers.tokenization_utils -   loading file model/added_tokens.json\n","11/26/2019 20:04:17 - INFO - transformers.tokenization_utils -   loading file model/special_tokens_map.json\n","11/26/2019 20:04:17 - INFO - transformers.tokenization_utils -   loading file model/tokenizer_config.json\n","11/26/2019 20:04:17 - INFO - __main__ -   Evaluate the following checkpoints: ['model']\n","11/26/2019 20:04:17 - INFO - transformers.configuration_utils -   loading configuration file model/config.json\n","11/26/2019 20:04:17 - INFO - transformers.configuration_utils -   Model config {\n","  \"attn_pdrop\": 0.1,\n","  \"embd_pdrop\": 0.1,\n","  \"finetuning_task\": null,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"num_labels\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pruned_heads\": {},\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"torchscript\": false,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 50257\n","}\n","\n","11/26/2019 20:04:17 - INFO - transformers.modeling_utils -   loading weights file model/pytorch_model.bin\n","11/26/2019 20:04:22 - INFO - __main__ -   Creating features from dataset file at /content/CBTest/data/valid\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   Token indices sequence length is longer than the specified maximum sequence length for this model (288308 > 1024). Running this sequence through the model will result in indexing errors\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - WARNING - transformers.tokenization_utils -   This tokenizer does not make use of special tokens. Input is returned with no modification.\n","11/26/2019 20:04:23 - INFO - __main__ -   Saving features into cached file /content/CBTest/data/valid/cached_lm_1024_cbt_valid_cleaned.txt\n","11/26/2019 20:04:23 - INFO - __main__ -   ***** Running evaluation  *****\n","11/26/2019 20:04:23 - INFO - __main__ -     Num examples = 281\n","11/26/2019 20:04:23 - INFO - __main__ -     Batch size = 2\n","Evaluating: 100% 141/141 [01:05<00:00,  2.50it/s]\n","11/26/2019 20:05:29 - INFO - __main__ -   ***** Eval results  *****\n","11/26/2019 20:05:29 - INFO - __main__ -     perplexity = tensor(16.4550)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1Ims15QC2kkG","colab_type":"code","outputId":"aa3d0079-04aa-4f7c-b39d-76d92aa63dfc","executionInfo":{"status":"ok","timestamp":1574801504346,"user_tz":300,"elapsed":48476,"user":{"displayName":"Randy West","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDIuiLm_tLYhXcxAUMOdxogEndwhWVgfR12ND5xrw=s64","userId":"12093252501908892059"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import random\n","\n","seed = random.randint(1,50000)\n","length = 500\n","prompt = \"Once upon a time, Alice fell down a well, where she met a very curious rabbit.\"\n","! python transformers/examples/run_generation.py \\\n","  --model_type=gpt2 \\\n","  --model_name_or_path=\"./model\" \\\n","  --prompt=\"{prompt}\" \\\n","  --length={length} \\\n","  --seed={seed}"],"execution_count":0,"outputs":[{"output_type":"stream","text":["11/26/2019 20:51:03 - INFO - transformers.tokenization_utils -   Model name './model' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, distilgpt2). Assuming './model' is a path or url to a directory containing tokenizer files.\n","11/26/2019 20:51:03 - INFO - transformers.tokenization_utils -   loading file ./model/vocab.json\n","11/26/2019 20:51:03 - INFO - transformers.tokenization_utils -   loading file ./model/merges.txt\n","11/26/2019 20:51:03 - INFO - transformers.tokenization_utils -   loading file ./model/added_tokens.json\n","11/26/2019 20:51:03 - INFO - transformers.tokenization_utils -   loading file ./model/special_tokens_map.json\n","11/26/2019 20:51:03 - INFO - transformers.tokenization_utils -   loading file ./model/tokenizer_config.json\n","11/26/2019 20:51:03 - INFO - transformers.configuration_utils -   loading configuration file ./model/config.json\n","11/26/2019 20:51:03 - INFO - transformers.configuration_utils -   Model config {\n","  \"attn_pdrop\": 0.1,\n","  \"embd_pdrop\": 0.1,\n","  \"finetuning_task\": null,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"num_labels\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pruned_heads\": {},\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"torchscript\": false,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 50257\n","}\n","\n","11/26/2019 20:51:03 - INFO - transformers.modeling_utils -   loading weights file ./model/pytorch_model.bin\n","11/26/2019 20:51:10 - INFO - __main__ -   Namespace(device=device(type='cuda'), length=500, model_name_or_path='./model', model_type='gpt2', n_gpu=1, no_cuda=False, padding_text='', prompt='Once upon a time, Alice fell down a well, where she met a very curious rabbit.', repetition_penalty=1.0, seed=35075, stop_token=None, temperature=1.0, top_k=0, top_p=0.9, xlm_lang='')\n","100% 500/500 [00:33<00:00,  8.60it/s]\n","\n","One who just seemed to have fled from her home, but thought that she knew more about the rabbit than she did, and was looking for her in her own room.\n","`` What am I to do? ''\n","cried Alice, in fright.\n","`` How do you escape from my nightmare? ''\n","`` Yes, I 'll take you to the Rabbit House to see if I can find a place. ''\n","`` Oh, nae! ''\n","cried Alice, as she spread her legs.\n","Then she kissed the rabbit, and then sat down on a sofa by her sides.\n","Alice stood straight upright in her own bed for a moment, and then went to sleep.\n","When she woke she saw that it was dark, but the rabbit was far away.\n","Alice looked round and knew that a nest was standing in the open space.\n","She flew into the nest, but the rabbit clambered down on her and laid her face down on the table.\n","The rabbit dropped her on the floor, threw her on the sofa, and began to play with her.\n","It was an exciting moment, but Alice could not help dreaming.\n","She almost hoped that she might find another place to live.\n","But no!\n","She flew to another part of the forest, where she found a little tree growing on the ground.\n","` Never mind, you never forgot!\n","I hope it's some night's work, or something like that. '\n","She knew she would never forget.\n","Then she dreamed again.\n","It was beautiful, and the rabbit climbed up the tree in all its glory.\n","Alice almost fell asleep, but at last she decided to wake up.\n","So she began to climb up the tree, and it was really very beautiful.\n","Alice knew that there were other places to be, but she didn't want to go to the end of the forest!\n","So she climbed to the top of the tree, and it grew, and in just a few minutes she was at home again.\n","She sat down on the sofa, and leaned her head on the head of the rabbit.\n","`` What are you going to do? ''\n","asked Alice timidly.\n","` Oh, nae! ''\n","he repeated.\n","`` I do nae want to see what has happened to me! ''\n","`` I want you to have breakfast, '' said Alice, breathless.\n","``\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DQe-ZWot_JAn","colab_type":"code","outputId":"f3916cfd-ac34-4526-e7b2-50fba07611e1","executionInfo":{"status":"ok","timestamp":1574801561950,"user_tz":300,"elapsed":22726,"user":{"displayName":"Randy West","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDIuiLm_tLYhXcxAUMOdxogEndwhWVgfR12ND5xrw=s64","userId":"12093252501908892059"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sDeO3t21A9zf","colab_type":"code","colab":{}},"source":["drive_dir = \"/content/drive/My Drive/Colab Notebooks/models/childrens-stories_fine-tuned_gpt2\"\n","! rm -rf \"{drive_dir}\"\n","! mkdir \"{drive_dir}\"\n","! cp /content/model/*.json /content/model/*.txt /content/model/*.bin \"{drive_dir}\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u3pPir15-iqv","colab_type":"text"},"source":["#Inference from Drive"]},{"cell_type":"code","metadata":{"id":"EVEqG2zv-uuY","colab_type":"code","colab":{}},"source":["drive_dir = \"/content/drive/My Drive/Colab Notebooks/models/childrens-stories_fine-tuned_gpt2\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6xSOkDsz_Cga","colab_type":"code","outputId":"195313a1-a627-4200-dbb2-80015345055c","executionInfo":{"status":"ok","timestamp":1574618202722,"user_tz":300,"elapsed":22173,"user":{"displayName":"Randy West","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDIuiLm_tLYhXcxAUMOdxogEndwhWVgfR12ND5xrw=s64","userId":"12093252501908892059"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ChmUKrUbAgwL","colab_type":"code","outputId":"5d098c2a-3848-4859-8cdb-a089f09ea088","executionInfo":{"status":"ok","timestamp":1574618212737,"user_tz":300,"elapsed":8017,"user":{"displayName":"Randy West","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDIuiLm_tLYhXcxAUMOdxogEndwhWVgfR12ND5xrw=s64","userId":"12093252501908892059"}},"colab":{"base_uri":"https://localhost:8080/","height":632}},"source":["! pip install transformers"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/f9/51824e40f0a23a49eab4fcaa45c1c797cbf9761adedd0b558dab7c958b34/transformers-2.1.1-py3-none-any.whl (311kB)\n","\u001b[K     |████████████████████████████████| 317kB 3.5MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n","\u001b[K     |████████████████████████████████| 860kB 42.5MB/s \n","\u001b[?25hCollecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 31.2MB/s \n","\u001b[?25hCollecting regex\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/8e/cbf2295643d7265e7883326fb4654e643bfc93b3a8a8274d8010a39d8804/regex-2019.11.1-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n","\u001b[K     |████████████████████████████████| 645kB 36.2MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.18)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.0)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.9.11)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n","Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n","Requirement already satisfied: botocore<1.14.0,>=1.13.18 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.18)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.18->boto3->transformers) (0.15.2)\n","Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.18->boto3->transformers) (2.6.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=d03a8e5ea483a34aa58360ec46602cb28295e1a4a9fc8445fb1ceb979353d671\n","  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, sentencepiece, regex, transformers\n","Successfully installed regex-2019.11.1 sacremoses-0.0.35 sentencepiece-0.1.83 transformers-2.1.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mH24uyEtAdoi","colab_type":"code","outputId":"13839b3f-2926-49e6-81a5-0d1726b4569b","executionInfo":{"status":"ok","timestamp":1574618215718,"user_tz":300,"elapsed":3956,"user":{"displayName":"Randy West","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDIuiLm_tLYhXcxAUMOdxogEndwhWVgfR12ND5xrw=s64","userId":"12093252501908892059"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["! rm -rf transformers\n","# enhanced to use past with GPT-2\n","! git clone https://github.com/thisisrandy/transformers.git"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Cloning into 'transformers'...\n","remote: Enumerating objects: 70, done.\u001b[K\n","remote: Counting objects: 100% (70/70), done.\u001b[K\n","remote: Compressing objects: 100% (40/40), done.\u001b[K\n","remote: Total 12479 (delta 38), reused 52 (delta 30), pack-reused 12409\u001b[K\n","Receiving objects: 100% (12479/12479), 6.56 MiB | 20.47 MiB/s, done.\n","Resolving deltas: 100% (9130/9130), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VhvZeUtX_ERE","colab_type":"code","outputId":"95024ca5-4184-4278-9291-bbd8ccf53b46","executionInfo":{"status":"ok","timestamp":1574618281468,"user_tz":300,"elapsed":63233,"user":{"displayName":"Randy West","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDIuiLm_tLYhXcxAUMOdxogEndwhWVgfR12ND5xrw=s64","userId":"12093252501908892059"}},"colab":{"base_uri":"https://localhost:8080/","height":938}},"source":["import random\n","\n","seed = random.randint(1,50000)\n","length = 1000\n","prompt = \"Once upon a time, Alice fell down a well, where she met a very curious rabbit.\"\n","! python transformers/examples/run_generation.py \\\n","  --model_type=gpt2 \\\n","  --model_name_or_path=\"{drive_dir}\" \\\n","  --prompt=\"{prompt}\" \\\n","  --length={length} \\\n","  --seed={seed}"],"execution_count":0,"outputs":[{"output_type":"stream","text":["11/24/2019 17:57:02 - INFO - transformers.tokenization_utils -   Model name '/content/drive/My Drive/Colab Notebooks/models/childrens-stories_fine-tuned_gpt2_1000' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, distilgpt2). Assuming '/content/drive/My Drive/Colab Notebooks/models/childrens-stories_fine-tuned_gpt2_1000' is a path or url to a directory containing tokenizer files.\n","11/24/2019 17:57:03 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Colab Notebooks/models/childrens-stories_fine-tuned_gpt2_1000/vocab.json\n","11/24/2019 17:57:03 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Colab Notebooks/models/childrens-stories_fine-tuned_gpt2_1000/merges.txt\n","11/24/2019 17:57:03 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Colab Notebooks/models/childrens-stories_fine-tuned_gpt2_1000/added_tokens.json\n","11/24/2019 17:57:03 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Colab Notebooks/models/childrens-stories_fine-tuned_gpt2_1000/special_tokens_map.json\n","11/24/2019 17:57:03 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Colab Notebooks/models/childrens-stories_fine-tuned_gpt2_1000/tokenizer_config.json\n","11/24/2019 17:57:04 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/My Drive/Colab Notebooks/models/childrens-stories_fine-tuned_gpt2_1000/config.json\n","11/24/2019 17:57:05 - INFO - transformers.configuration_utils -   Model config {\n","  \"attn_pdrop\": 0.1,\n","  \"embd_pdrop\": 0.1,\n","  \"finetuning_task\": null,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"num_labels\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pruned_heads\": {},\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"torchscript\": false,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 50257\n","}\n","\n","11/24/2019 17:57:05 - INFO - transformers.modeling_utils -   loading weights file /content/drive/My Drive/Colab Notebooks/models/childrens-stories_fine-tuned_gpt2_1000/pytorch_model.bin\n","11/24/2019 17:57:19 - INFO - __main__ -   Namespace(device=device(type='cuda'), length=1000, model_name_or_path='/content/drive/My Drive/Colab Notebooks/models/childrens-stories_fine-tuned_gpt2_1000', model_type='gpt2', n_gpu=1, no_cuda=False, num_samples=1, padding_text='', prompt='Once upon a time, Alice fell down a well, where she met a very curious rabbit.', repetition_penalty=1.0, seed=47833, stop_token=None, temperature=1.0, top_k=0, top_p=0.9, xlm_lang='')\n","100% 1000/1000 [00:41<00:00, 24.21it/s]\n","\n","The rabbit looked at her with surprise and interest, but before he knew it he had come to her, and asked her if she had left any sort of mark on her neck, which Alice promptly gave him back.\n","She replied that she had not, and that she would not have minded him very much if he had only promised to carry the cake, if she hadn't.\n","Now she was very glad that she had sent him back the cake, and Alice felt very thankful indeed for that promise, when it came for a few minutes that the sight of the rabbit making her neck look so great that she could hardly stop to stare, and a certain reverence of respect for her was plainly apparent when he spoke, as usual.\n","` It's very good for you,'said Alice, who was very much impressed at what the rabbit said, as he certainly looked as though she had changed her mind about going to town. '\n","I am sure that's what he said, for I am sure there will be nobody who will take him as a friend. '\n","` Indeed, it is not likely that I will take any more,'said the rabbit, chuckling, ` but I certainly think the cake is very good for you, though I have always loved that darkly colored cake, and I'm glad to see you, Alice, you can't forget that cake. '\n","So she stopped before he began to tell her his story, and Alice went to give the cake to the woman, who was sitting beside him and wished him happy birthday.\n","` Now,'said she, and passed the cake to Alice, who found the cake, and ate it eagerly, and the mother brought back the crumb that had been hanging on the wall, though it was bare, and there was a plaster on it that was rather unusual, for she knew that the hole was never cleaned, and gave the baby a clean look, which was very good for him, because the way in which he ate so much did not seem as as bad as if he had not been very good to his mother.\n","The doctor, who was there also, listened attentively, and remarked on the child's curious appearance, and said that he was always so young and old that there was a natural desire to play up her beauty, and so did not look his best, but he behaved so pretty, and was just what the doctor wanted him to be.\n","The child, very rather changed for the worse, so she grew into a poor, grey-faced little housekeeper, and had nothing to do but read, and often listened to the children'tales, and the doctor hardly spoke.\n","When the parents left, Alice thought that they were going to go out to dinner, for the rabbit's whole way home was quite busy, and he wanted her to see him the whole time, and make sure he was ready before he went to bed.\n","` We would be quite delighted,'she thought, for the good teacher and the neighbours saw it and were very glad when they heard how Alice had got up with so much excitement, and how happy she felt, for the rabbit began to treat her like a brother, and very fond of her, and kept her company and company ever so much, till once he was caught again by a knight, and lay bleeding on the floor ; the youngest man came over to see him, and asked why he had been so fat, and said that he thought it would be better if Alice had gone out alone, and didn't mind to go alone as long as she was not sad.\n","Alice thought, and was quite pleased, when the knight brought his sword to her, and told her that she might carry her crumb down the well as best she could, but had to give in to her uncle, who could not take any more of her, and said that he would only do his best, and that he must be led into some little brook at least, because there was not enough water in it to feed all the little children.\n","The knight who was at the brook led Alice away as fast as he could, and they spent all the evening together, and gave her clothes out of their pocket, and then she was allowed to go into some little house, which, being well kept, she brought with her to a certain gentleman, who looked as though he liked her, who had a bad temper, and couldn't get out of his trousers, and told her that she should go, and look after her.\n","Alice felt quite tired and discouraged when she found out that the brook was full, and that he was coming for a glass of milk, which he had no chance of doing, for he went and sat down on the handrail, and could not reach the door, as he was quite frightened at seeing the rabbit galloping in the twilight\n"],"name":"stdout"}]}]}
